# 1. MySQL架构和基础

## 1.1 Mysql架构图

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504162744.png)

存储引擎负责对表中的数据进行读取和写入，常用的存储引擎由innoDB、MyISAM等，不同的存储引擎有自己的特性，数据在不同存储引擎中存放的格式也是不同的，比如Memory都不用磁盘来存储数据。

在InnoDb中，数据会存储到磁盘上，在真正处理数据时需要先将数据加载到内存，表中读取某些记录时，InnoDB存储引擎不需要一条一条的把记录从磁盘上读取出来，InnoDB采取的方式是：将数据划分为若干页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为16KB，也就是说，当需要从磁盘中读数据时每次最少将从磁盘读取一页内容到内存，每一次最少也会把内存中的16KB内容写到磁盘中。适用于**计算机局部性原理**，操作系统页的大小是4KB

MySQL 大体上可分为 Server 层和存储引擎层两部分

### 连接层

不是MySQL独有的，大多数基于网络的客户端/服务器的工具或者服务都有类似的架构。

每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只会轮流在某个CPU核心或者CPU中运行。服务器会负责缓存线程，因袭不需要为每一个新建的连接创建或者销毁线程。

### **Server 层**

1. 连接器：TCP 握手后服务器来验证登陆用户身份，A 用户创建连接后，管理员对 A 用户权限修改了也不会影响到已经创建的链接权限，必须重新登录。
2. 查询缓存：查询后的结果存储位置，MySQL8.0 版本以后已经取消，因为查询缓存失效太频繁，得不偿失。
3. 分析器：根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。
4. 优化器：多种执行策略可实现目标，系统自动选择最优进行执行。
5. 执行器：判断是否有权限，将最终任务提交到存储引擎。

### **存储引擎层**

**负责数据的存储和提取。**其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎(经常用的也是这个)。

![图片](https://mmbiz.qpic.cn/mmbiz_png/wJvXicD0z2dUQrRBUyxETV2RgzXuPqjscHYVe250B5pbSfZrbqeiatdwHkfBFbiaXibg8HicQqZD1ibaejYZnyg0jxEQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### **SQL执行顺序**

![图片](https://mmbiz.qpic.cn/mmbiz_png/wJvXicD0z2dUQrRBUyxETV2RgzXuPqjscvL02EdeR3b0PK0icwria3VTqC15hyics1iaicuuz2KKUlVCZm4tDbRX1JtA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 1.2 存储引擎

### 1.2.1 介绍

> https://www.cnblogs.com/yifanSJ/p/9168070.html

MyISAM： 拥有较高的插入、查找速度，但不支持事务 ，InnoDB更新、删除效率较高
InnoDB ：5.5版本后Mysql的默认数据库，InnoDB给MySQL的表提供了事务处理、回滚、崩溃修复能力和多版本并发控制的事务安全

### 1.2.2 InnoDB和Myisam区别

- InnoDB支持事物，而MyISAM不支持事物
- InnoDB支持行级锁(悲观锁)，而MyISAM支持表级锁
- InnoDB支持MVCC(多版本并发控制), 而MyISAM不支持 
- InnoDB支持外键，而MyISAM不支持 
- InnoDB不支持全文索引（搜索引擎用），而MyISAM支持
- InnoDB表必须有主键（用户没有指定的话会自己找或生成一个主键），而Myisam可以没有主键，如果没有显式指定,则 MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键,如果不存在这种列,则MySQL 自动为 InnoDB 表生成一个隐含字段作为主键,类型为长整形

### 1.2.3 innodb

#### 1.2.3.1 存储结构框架

#### 1.2.3.2 innodb存储引擎

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\innodb.png)

#### 1.2.3.3 innodb文件

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\innodb文件.png)

##### 日志文件

MySQL中有六种日志文件，分别是：

- 重做日志（redo log）
- 回滚日志（undo log）
- 二进制日志（binlog）
- 错误日志（errorlog）
- 慢查询日志（slow query log）
- 一般查询日志（general log）
- 中继日志（relay log）

**其中重做日志和回滚日志与事务操作息息相关，二进制日志也与事务操作有一定的关系，这三种日志，对理解MySQL中的事务操作有着重要的意义。**
**这里简单总结一下这三者具有一定相关性的日志。**

###### 重做日志（redo log）

**作用：**

确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

**内容：**

物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。

**什么时候产生：**

事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。

**什么时候释放：**

当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

**对应的物理文件：**

默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&ib_logfile2

- innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。
- innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2

**关于文件的大小和数量，由以下两个参数配置：**

- innodb_log_file_size 重做日志文件的大小。
- innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1

**其他：**

很重要一点，redo log是什么时候写盘的？前面说了是在事务开始之后逐步写盘的。

之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\redo_log.png)

**然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘**

- Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件
- 每个事务提交时会将重做日志刷新到重做日志文件
- 当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件

由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。

因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。

另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：

即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。

这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。

###### 回滚日志（undo log）

参考MVCC的实现原理

**作用：**

保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

**内容：**

逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

**什么时候产生：**

事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性

**什么时候释放：**

当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

**对应的物理文件：**

MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。

MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数
如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。

**关于MySQL5.7之后的独立undo 表空间配置参数如下：**

- innodb_undo_directory = /data/undospace/ –undo独立表空间的存放目录
- innodb_undo_logs = 128 –回滚段为128KB
- innodb_undo_tablespaces = 4 –指定有4个undo log文件

如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\undo_log.png)

**其他：**

undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。

默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。

因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。

因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。

###### 二进制日志（binlog）

**作用：**

用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
用于数据库的基于时间点的还原。

**内容：**

逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。

但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。

在使用mysqlbinlog解析binlog之后一些都会真相大白。

因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。

**什么时候产生：**

事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。

这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。

因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。

这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。

**什么时候释放：**

binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\bin_log1.png)

**对应的物理文件：**

配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。

对于每个binlog日志文件，通过一个统一的index文件来组织。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\bin_log2.png)

**其他：**

二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同

作用不同：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。
内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句
另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。
恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog

关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。

#### 1.2.3.4 innodb事务

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\innodb事务.png)



#### 1.2.3.5 innodb表

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\inndb表.png)



#### 1.2.3.6 innodb索引和算法

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\innodb索引.png)

#### 1.2.3.7 innodb锁

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\innodb锁.png)

#### 1.2.3.8 innodb引擎的4大特性

1. 插入缓冲（insert buffer) 
2. 二次写(double write)
3. 自适应哈希索引(ahi) 
4. 预读(read ahead)

## 1.3 数据的存储格式（InnoDB为例）

### 1.3.1 InnoDB的逻辑存储结构（整体）

- 表空间

表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所以的数据都存放在表空间里面。

在默认情况下，InnoDB存储引擎有一个共享表空间ibdata1，即所有数据都存放在这个表空间里面。当然也可以在my.ini参数文件中启用innodb_file_per_table，则每张表的数据就可以单独放在一个表空间中。

```
注意：即使启用innodb_file_per_table参数，一些回滚信息，系统事务信息等还是在共享的表空间中，其随着时间的变化大小还是会不断增大的。单独的表空间只会存放一些数据及索引信息。
```

- 段

在InnoDB存储引擎中，对段的管理都是由引擎自身所完成的，DBA不能也没必要对其进行控制。

- 区

区是由连续页组成的空间，在任何情况下每个区的大小都是1MB，页的大小为16kb，所以一个区一共有64个连续的页。

- 页

下面详细描述。

- 行

下面详细描述。

### 1.3.2 InnoDB数据页结构

页是InnoDB管理存储空间的基本单位，一个页的大小默认为16KB。

| 名称             | 中文名             | 占用空间 | 简单描述                 |
| ---------------- | ------------------ | -------- | ------------------------ |
| File Header      | 文件头部           | 38字节   | 页的一些通用信息         |
| PageHeader       | 页面头部           | 56字节   | 数据页专有的一些信息     |
| Infimum+Supremum | 最小记录和最大记录 | 26字节   | 两个虚拟的行记录         |
| User Records     | 用户记录           | 不确定   | **实际存储的行记录内容** |
| Free Space       | 空闲空间           | 不确定   | 页中尚未使用的空间       |
| Page Directory   | **页面目录**       | 不确定   | 页中的某些记录的相对位置 |
| File Trailer     | 文件尾部           | 8字节    | 校验页是否完整           |

### 1.3.3 InnoDB行格式

一行记录可以以不同的格式存在InnoDB中，行格式分别是Compact、Redundant、Dynamic和Compressed行格式。

我们可以在创建或者修改表的语句中指定行格式

```mysql
CREATE TABLE 表名（列的信息） ROW_FORMAT=行格式名称
ALTER TABLE 表名 ROW_FORMAT=行格式名称
```

#### COMPACT行格式

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504172033.png)

**记录的额外信息**

这部分信息是服务器为了描述这条记录而不得不额外添加的一些信息，这些额外信息分为3类，分别

是：

- 变长字段长度列表
- NULL值列表
- 记录头信息

top：一行最多可以存65535个字节，而一页可以存16384个字节，所以会出现行溢出，把一行数据分到不同的页上

**变长字段长度列表**

MySQL支持一些变长的数据类型，比如VARCHAR（M）、VARBINARY（M）、TEXT类型、BLOB类型，这些数据类型修饰列成为变长字段，变长字段中存储多少字节的数据不是固定的，所以我们在存储真实数据的时候需要顺便把这些数据占用的字节数存起来。在Compact行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表。

> CHAR是一个固定长度的类型，VARCHAR则是一种可变的类型。
>
> VARCHAR(M),M代表最大能存多少个字符。（MySQL5.0.3以前是字节，以后是字符）

**NULL值列表**

Compact行格式会把可以为NULL的列统一管理起来，存一个标记位在NULL值列表中，如果表中没有允许存储NULL的列，则NULL值列表也不存在了。

- 二进制位的值为1，代表该列的值为NULL
- 二进制位的值为0，代表该列的值不为NULL

**记录头信息**

除了变长字段长度列表，NULL值列表之外，还有一个用于描述记录的记录头信息，它是由固定的5个字节组成。5个字节也就是40个二进制位，不同的位代表不同的意思，如图：

| 名称         | 大小（单位bit） | 描述                                                         |
| ------------ | --------------- | ------------------------------------------------------------ |
| 预留位1      | 1               | 没有使用                                                     |
| 预留位2      | 1               | 没有使用                                                     |
| delete_mask  | 1               | 标记该记录是否被删除                                         |
| min_rec_mask | 1               | B+树的每层非叶子节点中的最小记录都会添加该标记               |
| n_owned      | 4               | 表示当前记录拥有的记录数                                     |
| heap_no      | 13              | 表示当前记录在记录堆的位置信息                               |
| record_type  | 3               | 表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录 |
| next_record  | 16              | 表示下一条记录的相对位置                                     |

**记录的真实数据**

记录的真实数据除了我们自己定义的列的数据外，还有三个隐藏列：用于MVCC多版本并发控制

| 列名           | 是否必须 | 占用空间 | 描述                   |
| -------------- | -------- | -------- | ---------------------- |
| row_id         | 否       | 6个字节  | 行ID，唯一标识一条记录 |
| transaction_id | 是       | 6个字节  | 事务ID                 |
| roll_pointer   | 是       | 7个字节  | 回滚指针               |

> 实际上这几个列的真实名称是：DB_ROW_ID、DB_TRX_ID、DB_ROLL_PTR
>
> 一个表没有手动定义主键，则会选取一个Unique键作为主键，如果连Unique键都没有定义的话，则会为表默认添加一个名为row_id的隐藏列作为主键。所以row_id是在没自定义主键及Unique键的情况下才会存在的。

### 1.3.4 索引底层原理

见下面索引

## 1.4 并发控制

### 1.4.1 mysql锁

> https://zhuanlan.zhihu.com/p/29150809

锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。锁是Mysql在服务器层和存储引擎层的的并发控制。

### 1.4.2 **锁机制**

#### **共享锁与排他锁**

- 共享锁（读锁）：其他事务可以读，但不能写。
- 排他锁（写锁） ：其他事务不能读取，也不能写。

#### **粒度锁**

MySQL 不同的存储引擎支持不同的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现：

- MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking）
- BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁
- InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。

默认情况下，表锁和行锁都是自动获得的， 不需要额外的命令。

但是在有的情况下， 用户需要明确地进行锁表或者进行事务的控制， 以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。

#### **不同粒度锁的比较**

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。

- - 这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁。
  - 表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如Web 应用

- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

- - 最大程度的支持并发，同时也带来了最大的锁开销。
  - 在 InnoDB 中，除单个 SQL 组成的事务外，
    锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的。
  - 行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统

- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

### **1.4.3 MyISAM 表锁**

#### **MyISAM表级锁模式**

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。

默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。 

这也正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。同时，一些需要长时间运行的查询操作，也会使写线程“饿死” ，应用中应尽量避免出现长时间运行的查询操作（在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解” ，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行）。

可以设置改变读锁和写锁的优先级：

- 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。
- 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。
- 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。
- 给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。

#### **MyISAM加表锁方法**

MyISAM 在执行查询语句（SELECT）前，会自动给涉及的表加读锁，在执行更新操作
（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。

在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。



MyISAM存储引擎支持并发插入，以减少给定表的读和写操作之间的争用：

如果MyISAM表在数据文件中间没有空闲块，则行始终插入数据文件的末尾。 在这种情况下，你可以自由混合并发使用MyISAM表的INSERT和SELECT语句而不需要加锁——你可以在其他线程进行读操作的时候，同时将行插入到MyISAM表中。 文件中间的空闲块可能是从表格中间删除或更新的行而产生的。 如果文件中间有空闲快，则并发插入会被禁用，但是当所有空闲块都填充有新数据时，它又会自动重新启用。 要控制此行为，可以使用MySQL的concurrent_insert系统变量。

如果你使用LOCK TABLES显式获取表锁，则可以请求READ LOCAL锁而不是READ锁，以便在锁定表时，其他会话可以使用并发插入。

- 当concurrent_insert设置为0时，不允许并发插入。
- 当concurrent_insert设置为1时，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个线程读表的同时，另一个线程从表尾插入记录。这也是MySQL的默认设置。
- 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。

#### **查询表级锁争用情况**

可以通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况：

```sql
mysql> SHOW STATUS LIKE 'Table%';
+-----------------------+---------+
| Variable_name | Value |
+-----------------------+---------+
| Table_locks_immediate | 1151552 |
| Table_locks_waited | 15324 |
+-----------------------+---------+
```

### **1.4.4 InnoDB行级锁和表级锁**

#### 1.4.4.1 InnoDB锁的分类

##### 行锁

###### 行锁类型

- 普通行锁（Record Lock）：键值在条件范围内,记录存在
- 间隙锁（Gap Lock）: 键值不在条件范围内,叫间隙
- 行&间隙（Next-Key Lock）:键值部分在范围内

###### 行锁两种实现

共享锁（S锁)：其他事务可以读，但不能写

排它锁（X锁）：其他事务不能读取，也不能写

> 注意点:某个事务获取数据的排他锁,其他事务不能获取该数据的任何锁,并不能代表其他事务无锁读取该数据

##### 表锁

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**

###### 表锁分类

- 意向锁(升级机制)

​         当一个事务带着表锁取访问一个被加了行锁的资源,那么这个行锁会升级为意向锁,将表锁住

- 自增锁:如果一个事务正在往表里插入自增锁,其他事务都必须等待

###### 意向锁分类

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

#### **1.4.4.2 锁模式的兼容情况**

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\锁的兼容.png)

（如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务； 反之， 如果两者不兼容，该事务就要等待锁释放。）

#### 1.4.4.3 InnoDB加锁方法

1. 意向锁是 InnoDB 自动加的,不需用户干预。

2. 对于 **UPDATE、 DELETE 和 INSERT** 语句， InnoDB会自动给涉及数据集加**排他锁**（X)；

3. 对于普通 SELECT 语句，InnoDB 不会加任何锁；

      事务可以通过以下语句显式给记录集加共享锁或排他锁：

   **共享锁（S）**：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查    

    询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很

    有可能造成死锁。
   **排他锁（X)**：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不

     能对该记录加共享锁或排他锁，而是等待获得锁

4. 隐式锁定
   
   InnoDB在事务执行过程中，使用两阶段锁协议：
   

随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；

   锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在**同一时刻**被释放。           

5. 显式锁定 ：

      ```sql
          select ... lock in share mode //共享锁 
          select ... for update //排他锁 
      ```

#### **1.4.4.4 select for update**

在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。

select *** for update 的使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。

**select lock in share mode ：**in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。select *** lock in share mode 使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。

**性能影响：**
select for update 语句，相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。
select lock in share mode 语句是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。

**for update 和 lock in share mode 的区别：**

前一个上的是排他锁（X 锁），一旦一个事务获取了这个锁，其他的事务是没法在这些数据上执行 for update ；后一个是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。

#### **1.4.4.5 InnoDB 行锁实现方式**

- InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！**
- 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。
- 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，
  别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。（更多阅读：[MySQL索引总结](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s/h4B84UmzAUJ81iBY_FXNOg)）
- 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。

#### **1.4.4.6 InnoDB的间隙锁**

当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。

**InnoDB使用间隙锁的目的：**

1. 防止幻读，以满足相关隔离级别的要求；
2. 满足恢复和复制的需要：

MySQL 通过 BINLOG 录入执行成功的 INSERT、UPDATE、DELETE 等更新数据的 SQL 语句，并由此实现 MySQL 数据库的恢复和主从复制。MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点：

一是 MySQL 的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中的 SQL 语句。

二是 MySQL 的 Binlog 是按照事务提交的先后顺序记录的， 恢复也是按这个顺序进行的。

由此可见，MySQL 的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。

**Innodb自动使用间隙锁的条件**

（1）必须在Repeatable Read级别下

（2）检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加） 

#### **1.4.4.7 InnoDB 在不同隔离级别下的一致性读及锁的差异**

锁和多版本数据（MVCC）是 InnoDB 实现一致性读和 ISO/ANSI SQL92 隔离级别的手段。

因此，在不同的隔离级别下，InnoDB 处理 SQL 时采用的一致性读策略和需要的锁是不同的

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\隔离级别下锁1.png)

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\隔离级别下锁2.jpg)

对于许多 SQL，隔离级别越高，InnoDB 给记录集加的锁就越严格（尤其是使用范围条件的时候），产生锁冲突的可能性也就越高，从而对并发性事务处理性能的 影响也就越大。

因此， 我们在应用中， 应该尽量使用较低的隔离级别， 以减少锁争用的机率。实际上，通过优化事务逻辑，大部分应用使用 Read Commited 隔离级别就足够了。对于一些确实需要更高隔离级别的事务， 可以通过在程序中执行 SET SESSION TRANSACTION ISOLATION

LEVEL REPEATABLE READ 或 SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE 动态改变隔离级别的方式满足需求。

#### **1.4.4.8 获取 InnoDB 行锁争用情况**

可以通过检查 InnoDB_row_lock 状态变量来分析系统上的行锁的争夺情况：

```sql
mysql> show status like 'innodb_row_lock%'; 
+-------------------------------+-------+ 
| Variable_name | Value | 
+-------------------------------+-------+ 
| InnoDB_row_lock_current_waits | 0 | 
| InnoDB_row_lock_time | 0 | 
| InnoDB_row_lock_time_avg | 0 | 
| InnoDB_row_lock_time_max | 0 | 
| InnoDB_row_lock_waits | 0 | 
+-------------------------------+-------+ 
5 rows in set (0.01 sec)
```

#### **1.4.4.9 LOCK TABLES 和 UNLOCK TABLES**

Mysql也支持lock tables和unlock tables，这都是在服务器层（MySQL Server层）实现的，和存储引擎无关，它们有自己的用途，并不能替代事务处理。 （除了禁用了autocommint后可以使用，其他情况不建议使用）：

- LOCK TABLES 可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。
- UNLOCK TABLES 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES 时，
  或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁

##### **LOCK TABLES语法**

- 在用 LOCK TABLES 对 InnoDB 表加锁时要注意，要将 AUTOCOMMIT 设为 0，否则MySQL 不会给表加锁；
- 事务结束前，不要用 UNLOCK TABLES 释放表锁，因为 UNLOCK TABLES会隐含地提交事务；
- COMMIT 或 ROLLBACK 并不能释放用 LOCK TABLES 加的表级锁，必须用UNLOCK TABLES 释放表锁。

正确的方式见如下语句：
例如，如果需要写表 t1 并从表 t 读，可以按如下做：

```sql
SET AUTOCOMMIT=0; 
LOCK TABLES t1 WRITE, t2 READ, ...; 
[do something with tables t1 and t2 here]; 
COMMIT; 
UNLOCK TABLES;
```

##### **使用LOCK TABLES的场景**

给表显示加表级锁（InnoDB表和MyISAM都可以），一般是为了在一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。（与MyISAM默认的表锁行为类似）

在用 LOCK TABLES 给表显式加表锁时，必须同时取得所有涉及到表的锁，并且 MySQL 不支持锁升级。也就是说，在执行 LOCK TABLES 后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。

其实，在MyISAM自动加锁（表锁）的情况下也大致如此，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。

例如，有一个订单表 orders，其中记录有各订单的总金额 total，同时还有一个 订单明细表 order_detail，其中记录有各订单每一产品的金额小计 subtotal，假设我们需要检 查这两个表的金额合计是否相符，可能就需要执行如下两条 SQL：

```sql
Select sum(total) from orders; 
Select sum(subtotal) from order_detail; 
```

这时，如果不先给两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，
order_detail 表可能已经发生了改变。因此，正确的方法应该是：

```sql
Lock tables orders read local, order_detail read local; 
Select sum(total) from orders; 
Select sum(subtotal) from order_detail; 
Unlock tables;
```

（在 LOCK TABLES 时加了“local”选项，其作用就是允许当你持有表的读锁时，其他用户可以在满足 MyISAM 表并发插入条件的情况下，在表尾并发插入记录（MyISAM 存储引擎支持“并发插入”））

### **1.4.5 死锁（Deadlock Free）**

mysql是如何死锁的

http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247514960&idx=2&sn=4a2e01f8e8286eb290c214551cb6726b&chksm=eb503e66dc27b77042b9514133dce4bd2b6e85b1c7a65e951d5d14682b97e2299e08532547e5&mpshare=1&scene=24&srcid=11221kAg91QgTPwOMkevKVuH&sharer_sharetime=1606015015468&sharer_shareid=d616a9566f629f38fe8f96977701a168#rd

- **死锁产生：**

- - 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。
  - 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。
  - 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

- **检测死锁：**数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。
- **死锁恢复：**死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。
- **外部锁的死锁检测：**发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决
- **死锁影响性能：**死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。

#### **MyISAM避免死锁**

- 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

#### **InnoDB避免死锁**

- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁
- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。
- 改变事务隔离级别

如果出现死锁，可以用 SHOW INNODB STATUS 命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

#### **一些优化锁性能的建议**

- 尽量使用较低的隔离级别；
- 精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会
- 选择合理的事务大小，小事务发生锁冲突的几率也更小
- 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁
- 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会
- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- 除非必须，查询时不要显示加锁。 MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能；MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作
- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能

### 1.4.6 悲观锁和乐观锁

#### 1.4.6.1 悲观锁

数据被并发修改的几率比较大，需要在修改之前借助于数据库锁机制,先对数据进行加锁的思想被称为悲观锁，传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

#### 1.4.6.2 乐观锁

数据一般是不会造成冲突的。只有在提交数据的时候，才会对数据的冲突进行检测。当发现冲突的时候，返回错误的信息，让用户决定如何去做。乐观锁并不是真正的加锁，优点是效率高，缺点是更新失败的概率比较高。数据库

一般的实现方式就是记录数据版本(**MVCC多版本并发控制**)。

##### 实现原理

步骤--->冲突检测和数据更新---->ABA问题-->版本号或者redis的watch

CAS实现：CAS是一种乐观锁实现方式，顾名思义就是先比较后更新。在对一个数据进行更新前，先持有对这个数据原有值的备份。比如，要将a=2更新为a=3，在进行更新前会比较此刻a是否为2.如果是2，才会进行更新操作。当多个线程尝试使用CAS同时更新一个变量时，只有一个线程能够成功，其余都是失败。失败的线程不会被挂起，而是被告知这次竞争失败，并且可以再次尝试。                             

#### 应用场景

## 1.5 事务

> 在MySQL数据库中查看当前事务的隔离级别：
> select @@tx_isolation;

### 1.5.1 ACID理论

原子性（atomicity）、一致性（consistency）、隔离性（isolation）、持久性（durability）

### 1.5.2 隔离级别

> https://www.cnblogs.com/xrq730/p/5087378.html

为什么要有事务隔离级别，因为**事务隔离级别越高，在并发下会产生的问题就越少，但同时付出的性能消耗也将越大**，因此很多时候必须在并发性和性能之间做一个权衡。

**读未提交**：能够读取到没有被提交的数据，所以很明显这个级别的隔离机制无法解决脏读、不可重复读、幻读中的任何一种，因此很少使用。

[^]: 如果一个事务开始写数据时，则另一个事务是不可以同时进行写操作，但可以进行读操作。这样可以避免更新丢失。

**读已提交**：能够读到那些已经提交的数据，自然能够防止脏读，但是无法限制不可重复读和幻读。

[^]: 如果事务只进行读操作，那么允许其他事务的读/写操作（会出现不可重复读）。但当前事务是写操作时，则不允许其他事务访问该数据（不能读/写）

**可重复读取（mysql默认隔离级别）**：即在数据读出来之后加锁，类似"select * from XXX for update"，明确数据读取出来就是为了更新用的，所以要加一把锁，防止别人修改它，但不防止插入，所以存在幻读

[^]: 一个事务在进行读操作时，其他事务不能对当前事务进行写操作，但可以进行读操作。一个事务在进行写操作时，其他事务是不能对其访问的。

**串行化**：提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，不能并发执行。只有读-读可以共享，其余的都阻塞（表级共享锁、表级排他锁）

### 1.5.3 事务的不同隔离级别下，会发生的几种问题

**脏读：**

是指在一个事务处理过程里读取了另一个未提交的事务中的数据；银行取钱，事务A开启事务，此时切换到事务B，事务B开启事务-->取走100元，此时切换回事务A，事务A读取的肯定是数据库里面的原始数据-100，但事务B取走了100块钱，并没有提交
**不可重复读：**
一个事务里面读取了两次某个数据，读出来的数据不一致。还是以银行取钱为例，事务A开启事务-->查出银行卡余额为1000元，此时切换到事务B事务B开启事务-->事务B取走100元-->提交，数据库里面余额变为900元，此时切换回事务A，事务A再查一次查出账户余额为900元，这样对事务A而言，在**同一个事务内**两次读取账户余额数据不一致，这就是不可重复读 

**幻读：**

在一个事务里面的操作中发现了未被操作的数据；例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。

### 1.5.4 隔离级别的实现原理

初步理解mysql四种隔离级别及底层实现原理：https://my.oschina.net/jikeh/blog/2961450

四个隔离级别只是一个标准，不同的厂商实现方式不一样，以下以**InnoDB为例**

**读未提交**：只有写操作加排他锁
**读已提交**：读MVCC最新版本，写排他锁
                   RC级别下，读取的是最新提交的记录，未提交的事务数据不读，能避免脏读。

​                   RR级别下，只读取事务开始时的快照，所以能够避免不可重复读
**可重复读**：MVCC快照读
**串行化**：读加表级共享锁，写加表级排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并 

​               发能力非常差

### 1.5.5 数据库事务隔离级别的两种实现方式及其关系

1.基于锁：阻止其他事务堆数据的操作，各个隔离级别主要体现在读取数据时加的锁和释放的时机

​       锁实现：https://blog.csdn.net/qq_37960007/article/details/90644635

2.MVCC：生成数据快照，多版本并发控制

​        MVCC：多版本并发控制是MySQL中基于乐观锁理论实现隔离级别的方式，用于实现**读已提交和可重**

​        **复读**隔离级别的实现

### 1.5.6 事务和锁的关系

1. 事务与锁是不同的。事务具有ACID（原子性、一致性、隔离性和持久性），锁是用于解决隔离性的一种机制

2. 事务的隔离级别可以通过锁的机制实现（另一种是版本号）。另外锁有不同的粒度，同时事务也是有不同的隔离级别的

3. 开启事务就自动加锁

   a.事务隔离级别是并发控制的整体解决方案，其实际上是综合利用各种类型的锁和行版本控制，来解决并发问题

   b.锁是数据库并发控制的内部机制，是基础。当然，数据库同时还会利用行版本控制来进行并发控制；在数据库内部还使用闩（latch），互斥（mutex）等机制处理内部资源（如，缓存）的并发访问

### 1.5.7 幻读的解决

采用RR隔离级别，结合MVCC特性，可以避免脏读、非重复读，有些文章说MVCC用来避免幻读，其实这是不准确的，MVCC通过多版本并发控制来避免非重复读，像幻读定义所说的情况即使有MVCC还是会存在。RR隔离级别是通过禁用innodb_locks_unsafe_for_binlog，在搜索和扫描索引的时候使用next-key locks来避免幻读（下面有对锁说明）。也就是为什么RR隔离级别下，非主键索引DML的操作并发性能会下降的原因了。

为了减少Next-key lock影响，可以设置innodb_locks_unsafe_for_binlog=1，就是disable Next-Key lock，但是并不建议。

想要真正避免幻读只能采取serializable串行化隔离级别，因为都要加表级共享锁或排他锁，所以性能会很差，一般不会采用。

> Mysql的Innodb可重复读的隔离级别中并不是完全解决了幻读的问题，而是解决了读数据情况下的幻读问题（因为读的是历史快照，而修改数据需要当前读）。而对于修改的操作依旧存在幻读问题，就是说MVCC对于幻读的解决时不彻底的。与下文矛盾。

解决幻读的两个办法:
       1.使用串行化读的隔离级别
       2.MVCC+next-key locks：next-key locks由record locks(行锁【索引加锁】) 和 gap locks(间隙锁)组成

```
  RR级别下Innodb使用MVVC和next-key locks解决幻读，MVVC解决的是快照读（不加锁的读）的幻读，           next-key locks解决的是当前读（加锁的读）情况下的幻读
```

### 1.5.8 事务开启与数据库连接

MySQL 默认开启事务自动提交模式，即除非显式的开启事务（BEGIN 或 START TRANSACTION），否则每条 SOL 语句都会被当做一个单独的事务自动执行。但有些情况下，我们需要关闭事务自动提交来保证数据的一致性。下面主要介绍如何设置事务自动提交模式。

在 MySQL 中，可以通过  SHOW VARIABLES 语句查看当前事务自动提交模式，如下所示：

```
mysql> SHOW VARIABLES LIKE 'autocommit';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| autocommit    | ON    |
+---------------+-------+
1 row in set, 1 warning (0.04 sec)
```

结果显示，autocommit 的值是 ON，表示系统开启自动提交模式。

在 MySQL 中，可以使用 SET autocommit 语句设置事务的自动提交模式，语法格式如下：

SET autocommit = 0|1|ON|OFF;

对取值的说明：

- 值为 0 和值为 OFF：关闭事务自动提交。如果关闭自动提交，用户将会一直处于某个事务中，只有提交或回滚后才会结束当前事务，重新开始一个新事务。
- 值为 1 和值为 ON：开启事务自动提交。如果开启自动提交，则每执行一条 SQL 语句，事务都会提交一次。

## 1.6 多版本并发控制

### 原理

如果没有MVCC，当想要读取的数据被其他事务用**排它锁**锁住时，只能互斥等待；而这时MVCC可以通过提供**历史版本**从而实现读取被锁的数据的历史版本，从而避免了互斥等待。

​             初步了解MVCC：https://www.cnblogs.com/myseries/p/10930910.html
​             深入了解MVCC：https://www.jianshu.com/p/8845ddca3b23

### 快照读和当前读

通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，不是数据库最新的数据这种读取历史数据的方式，我们叫它快照读，而读取数据库最新版本数据的方式，叫当前读        

# 2.基准测试

# 3.服务器性能剖析



# 4.Schema与数据类型优化

## 范式  

第一范式 属性的原子性
第二范式 属性完全依赖于主键
第三范式 要求一个数据库表中不包含已在其他表中的非主关键字信息
BCNF 范式:
                a.所有非主属性对每一个码都是完全函数依赖；
                b.所有主属性对每一个不包含它的码也是完全函数依赖；
                c.没有任何属性完全函数依赖于非码的任何一组属性;

第四范式  限制关系模式的属性之间不允许有非平凡且非函数依赖的多值依赖;处理的是相互独立的多值情况;
第五范式  表必须可以分解为较小的表，除非那些表在逻辑上拥有与原始表相同的主键;处理相互依赖的多值情况; 

### 优点



## 反范式



### 优点



# 5. 高性能索引

> https://www.cxyxiaowu.com/7584.html

## 5.1  索引的数据结构

>       二叉搜索树、平衡二叉树、红黑树、B树、B+树的选择 https://blog.csdn.net/qq_41765712/article/details/104228938
>       什么是B树？为啥文件索引要用B树而不用二叉查找树？  https://www.cxyxiaowu.com/2543.html
>       为什么 MySQL 数据库要用B+树存储索引？  https://www.cxyxiaowu.com/2440.html

## 5.2 B+树图解

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\B+树.jpeg)

## 5.3 InnoDB底层索引结构

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\Innodb和MyIsam底层.png)

## 5.4 分类

普通索引:查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录

唯一索引:由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索.可以为null

复合索引:MySQL可以使用多个字段同时建立一个索引,叫做联合索引

聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据

全文索引：

>  聚簇索引和非聚簇索引区别：
>
>  1. 聚簇索引的顺序就是数据的物理存储顺序，所以一个表最多只能有一个聚簇索引。如InnoDB主索引。
>  2. 非聚集索引中的逻辑顺序并不等同于表中行的物理顺序,索引是指向表中行的位置的指针。如MyISAM 主索引与辅索引

> 索引是越多越好吗?
>  1.创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。
>  2.索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
>  3.当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。

> MongoDB为什么使用B-树而不是B+树？
>
> 可以从它的设计角度来考虑，它并不是传统的关系性数据库，而是以Json格式作为存储的nosql，目的就是高性能，高可用，易扩展。首先它摆脱了关系模型，其次Mysql由于使用B+树，数据都在叶节点上，每次查询都需要访问到叶节点，而MongoDB使用B-树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于Mysql（但侧面来看Mysql至少平均查询耗时差不多）.

## 5.5 聚簇索引与非聚簇索引的区别

> https://www.cnblogs.com/yumingxing/p/9591638.html

1. 聚簇索引的顺序就是数据的物理存储顺序，所以一个表最多只能有一个聚簇索引。如InnoDB主索引。

2. 非聚集索引中的逻辑顺序并不等同于表中行的物理顺序,索引是指向表中行的位置的指针。如MyISAM 主索引与辅索引

   InnoDB辅助索引的叶子结点保存的是辅助索引key+主键（关联主键索引），主键索引是聚簇索引；MyISAM则辅助索引和主键索引叶子节点均保存文件内容地址，非聚簇索引。这就是MyISAM和InnoDB最大的不同；
   InnoDB的数据文件本身就是索引文件。从上文知道,MyISAM 索引文件和数据文件是分离的,索引文件仅保存数据记录的地址

   InnoDB行锁是通过给索引上的索引项加锁来实现的，意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁

   

## 5.6 InnoDB插入数据时建立主键索引分解（聚簇索引）

执行SQL语句

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504175304.png)

InnoDB自动排序建立**主键索引**

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\TIM图片20200504190907.jpg)

也就是所说的**B+树**

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504180230.png)

## 5.7 页分裂步骤

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504182243.png)

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504182317.png)

这样第一页不需要改变，可以缓存起来方便查找

> 为什么官方建议使用自增长主键作为索引？
>
> 结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率



## 5.8 辅助索引

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\20200504184115.png)

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\辅助索引.png)

> 为什么会有辅助索引？
>
> where后面需要写主键之外的其他字段名称来进行查询，比如说是where name=xx，没法用到主键索引的效率，怎么办，就需要我们添加辅助索引了，给name添加一个辅助索引，辅助索引的叶子节点不包含行记录的全部数据

> 覆盖索引
>
> 覆盖索引指的是在一次查询中，如果一个索引包含或者说覆盖所有需要查询的字段的值，我们就称之为覆盖索引，而不再需要回表查询。而要确定一个查询是否是覆盖索引，我们只需要explain sql语句看Extra的结果是否是“Using index”即可。
>
> ```
> explain select * from user where age=1; //查询的name无法从索引数据获取
> explain select id,age from user where age=1; //可以直接从索引获取
> ```

## 5.9 回表查询

先定位主键值，再定位行记录，它的性能较扫一遍索引树更低

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\回表查询.png)

## 5.10 覆盖索引

与回表查询相对的是覆盖索引

InnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作

- 非聚集索引上直接可以拿到所需数据，不需要再回表查，比如 select id from table where name = xxx;(**id为主键、name为索引列**)
- 在统计操作中也会使用覆盖索引。比如(a,b)联合索引，select * from table where b = xxx语句按最左前缀原则是不会走索引的，但如果是统计语句select count(*) from table where b = xxx;就会使用覆盖索引。

## 5.11 复合索引

当我们的where查询存在多个条件查询的时候，我们需要对查询的列创建组合索引

### 组合索引最左匹配原则

原则：https://blog.csdn.net/u013164931/article/details/82386555

**为什么需要注意联合索引中的顺序?**

在联合索引中,如果想要命中索引,需要按照建立索引时的字段顺序挨个使用,否则无法命中索引.

具体原因为:

MySQL使用索引时需要索引有序,假设现在建立了"name,age,school"的联合索引

那么索引的排序为: 先按照name排序,如果name相同,则按照age排序,如果age的值也相等,则按照school进行排序.

当进行查询时,此时索引仅仅按照name严格有序,因此必须首先使用name字段进行等值查询,之后对于匹配到的列而言,其按照age字段严格有序,此时可以使用age字段用做索引查找,以此类推.

因此在建立联合索引的时候应该注意索引列的顺序,一般情况下,将查询需求频繁或者字段选择性高的列放在前面.此外可以根据特例的查询或者表结构进行单独的调整.

## 5.12 全文索引

https://blog.csdn.net/csdnnhb2014/article/details/104466891

### 概述

在一堆文字中找到含有关键字的应用。当然也可以用以下语句实现：
SELECT * FROM <表名> WHERE <字段名> like ‘%ABC%’
但是它的效率太低，是全盘扫描。
Mysql 提供了更高效的方法全文索引（FULLTEXT）

### 重要

1. Mysql 5.6之前版本，只有myisam支持全文索引，5.6之后，Innodb和myisam均支持全文索引。
2. 只有char、varchar、text类型字段能创建全文索引。
3. 当大量写入数据时，建议先写入数据，后再建立全文索引，提高效率。
4. Mysql内置ngram 解析器，可以解析中日韩三国文字。有汉字的一定要启用它。
5. 英文分词用空格，逗号；中文分词用 ngram_token_size 设定，后面有讲解。

## 5.13 如何修改索引

```sql
ALTER TABLE <表名> ADD INDEX (<字段>);
```

##  5.14 如何创建索引

```sql
creat index 
```

## 5.15 查看是否用了索引

```
explain
```

https://blog.csdn.net/zhujuntiankong/article/details/88118037

## 5.16 什么时候不需要创建索引

-  频繁更新的字段不适合创建索引，因为每次更新不单单是更新记录，还会更新索引，保存索引文件
-  where条件里用不到的字段，不创建索引
-  表记录太少，不需要创建索引
-  经常增删改的表
-  数据重复且分布平均的字段，因此为经常查询的和经常排序的字段建立索引。注意某些数据包含大量重复数据，因此他建立索引就没有太大的效果，例如性别字段，只有男女，不适合建立索引

## 5.17 索引查询慢原因

- 硬件问题。如网络速度慢，内存不足，I/O吞吐量小，磁盘空间满了等。
- 没有索引或者索引失效。（半夜把表锁了，重新建立一遍索引，因为当你删除某个数据的时候，索引的树结构就不完整了。所以互联网公司的数据做的是假删除.一是为了做数据分析,二是为了不破坏索引 ）
- 数据过多（分库分表）

## 5.18 索引和主键的区别 

1. 主键用于标识数据库记录的唯一性，不允许记录重复，且主键不能为空。主键也是一个特殊索引；
2. 索引可以提高查询速度，通过它可以快速查询到结果，不需要进行全表扫描；
3. 使用主键，数据库会自动创建主索引，也可以在非主键上创建索引，提高查询速度；
4. 数据表中只允许有一个主键，但是可以有多个索引；

# 6. 查询性能优化



# 7. 高级特性

## 7.1 分区表



## 7.2 视图

视图本身是一个虚拟表，不存在任何数据。在使用SQL语句返回视图的时候，它返回的数据是MySQL从其他表生成的。视图和表

## 7.3 全文索引



# 8. 优化服务器设置



# 9. 操作系统和硬件优化

见操作系统课本和IO总结

# 10. 复制

参考《高性能MySQL》

这类应用使用所谓的"水平扩展"的架构。我们可以通过为服务器配置一个或多个备库*'的方式来进行数据同步。复制功能不仅有利于构建高性能的应用，同时也是高可用性、可扩展性、灾难恢复、备份以及数据仓库等工作的基础。事实上，可扩展性和高可用性通常是相关联的话题，我们会在接下来的三章详细阐述。

本章将阐述所有与复制相关的内容，首先简要介绍复制如何工作，然后讨论基本的复制服务搭建，包括与复制相关的配置以及如何管理和优化复制服务器。虽然本书的主题是高性能，但对于复制来说，我们同样需要关注其准确性和可靠性，因此我们也会讲述复制在什么情况下会失败，以及如何使其更好地工作。

## 10.1 复制概述

复制解决的基本问题是让一台服务器的数据与其他服务器保持同步。一台主库的数据可以同步到多台备库上，备库本身也可以被配置成另外一台服务器的主库。主库和备库之间可以有多种不同的组合方式。 MySQL支持两种复制方式∶**基于行的复制和基于语句的复制**。基于语句的复制（也称为逻辑复制）早在 MySQL 3.23版本中就存在，而基于行的复制方式在5.1版本中才被加进来。这两种方式都是通过在主库上记录二进制日志、在备库重放日志的方式来实现异步的数据复制。这意味着，在同一时间点备库上的数据可能与主库存在不一致，并 <且无法保证主备之间的延迟。一些大的语句可能导致备库产生几秒、几分钟甚至几个小时的延迟。 

MySQL复制大部分是向后兼容的，新版本的服务器可以作为老版本服务器的备库，但反过来，将老版本作为新版本服务器的备库通常是不可行的，因为它可能无法解析新版本所采用的新的特性或语法，另外所使用的二进制文件的格式也可能不相同。例如，不能从MySQL5.1复制到MySQL 4.0。在进行大的版本升级前，例如从4.1升级到5.0，或从5.1升级到5.5，最好先对复制的设置进行测试。但对于小版本号升级，如从5.1.51升级到5.1.58，则通常是兼容的。通过阅读每次版本更新的ChangeLog可以找到不同版本间做了什么修改。

复制通常不会增加主库的开销，主要是启用二进制日志带来的开销，但出于备份或及时从崩溃中恢复的目的，这点开销也是必要的。除此之外，每个备库也会对主库增加一些负载（例如网络I/O 开销），尤其当备库请求从主库读取旧的二进制日志文件时，可能会造成更高的I/O开销。另外锁竞争也可能阻碍事务的提交。最后，如果是从一个高吞吐量（例如5 000 或更高的TPS）的主库上复制到多个备库，唤醒多个复制线程发送事件的开销将会累加。

通过复制可以将读操作指向备库来获得更好的读扩展，但对于写操作，除非设计得当，否则并不适合通过复制来扩展写操作。在一主库多备库的架构中，写操作会被执行多次，这时候整个系统的性能取决于写入最慢的那部分。

当使用一主库多备库的架构时，可能会造成一些浪费，因为本质上它会复制大量不必要的重复数据。例如，对于一台主库和10台备库，会有11份数据拷贝，并且这11台服务器的缓存中存储了大部分相同的数据。这和在服务器上有11路RAID1类似。这不是一种经济的硬件使用方式，但这种复制架构却很常见，本章我们将讨论解决这个问题的方法。

### 10.1.1 复制解决的问题

下面是复制比较常见的用途∶

#### 数据分布

MySQL复制通常不会对带宽造成很大的压力，但在 5.1版本引入的基于行的复制会比传统的基于语句的复制模式的带宽压力更大。你可以随意地停止或开始复制，并在不同的地理位置来分布数据备份，例如不同的数据中心。即使在不稳定的网络环境下，远程复制也可以工作。但如果为了保持很低的复制延迟，最好有一个稳定的、低延迟连接。

#### 负载均衡

通过 MySQL复制可以将读操作分布到多个服务器上，实现对读密集型应用的优化，并且实现很方便，通过简单的代码修改就能实现基本的负载均衡。对于小规模的应用，可以简单地对机器名做硬编码或使用 DNS 轮询（将一个机器名指向多个IP地址）。当然也可以使用更复杂的方法，例如网络负载均衡这一类的标准负载均衡解决方案，能够很好地将负载分配到不同的 MySQL服务器上。Linux虚拟服务器（Linux Virtual Server，LVS）也能够很好地工作，第 11 章将详细地讨论负载均衡。

#### 备份 

对于备份来说，复制是一项很有意义的技术补充，但复制既不是备份也不能够取代备份。

#### 高可用性和故障切换

复制能够帮助应用程序避免 MySQL单点失败，一个包含复制的设计良好的故障切换系统能够显著地缩短宕机时间，我们将在第 12 章讨论故障切换。

#### MySQL 升级测试

这种做法比较普遍，使用一个更高版本的 MySQL作为备库，保证在升级全部实例前，查询能够在备库按照预期执行。

### 10.1.2 复制如何工作

在详细介绍如何设置复制之前，让我们先看看 MySQL实际上是如何复制数据的。总的来说，复制有三个步骤 ∶

 1. 在主库上把数据更改记录到二进制日志（Binary Log）中（这些记录被称为二进制 日志事件）。

2. 备库将主库上的日志复制到自己的中继日志（Relay Log）中。
3.  备库读取中继日志中的事件，将其重放到备库数据之上。

以上只是概述，实际上每一步都很复杂，图 10-1更详细地描述了复制的细节。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\主从复制.png" style="zoom:50%;" />

1.在主库上记录二进制日志（稍后介绍如何设置）。在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了。

2.备库将主库的二进制日志复制到其本地的中继日志中。首先，备库会启动一个工作线程，称为**I/O 线程**，I/O线程跟主库建立一个普通的客户端连接，然后在主库上启动一个特殊的**二进制转储（binlog dump）线程**（该线程没有对应的SQL命令），这个二进制转储线程会读取主库上二进制日志中的事件。它不会对事件进行轮询。如果该线程追赶上了主库，它将进入睡眠状态，直到主库发送信号量通知其有新的事件产生时才会被唤醒，备库 I/O 线程会将接收到的事件记录到中继日志中。

3.备库的 **SQL线程**执行最后一步，该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当 SQL线程追赶上I/O 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL线程执行的事件也可以通过配置选项来决定是否写入其自己的二进制日志中，它对于我们稍后提到的场景非常有用。



图10-1 显示了在备库有两个运行的线程，在主库上也有一个运行的线程∶和其他普通连接一样，由备库发起的连接，在主库上同样拥有一个线程。 这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行。也就是说 I/O 线程能够独立于 SQL线程之外工作。但这种架构也限制了复制的过程，其中最重要的一点是在主库上并发运行的查询在备库只能串行化执行，因为只有一个 SQL线程来重放中继日志中的事件。后面我们将会看到，这是很多工作负载的性能瓶颈所在。虽然有一些针对该问题的解决方案，但大多数用户仍然受制于单线程。

## 10.2 配置复制 

为MySQL服务器配置复制非常简单。但由于场景不同，基本的步骤还是有所差异。最基本的场景是新安装的主库和备库，总的来说分为以下几步∶

1. 在每台服务器上创建复制账号。 
2. 配置主库和备库。
3. 知备库连接到主库并从主库复制数据。 这里我们假定大部分配置采用默认值即可，在主库和备库都是全新安装并且拥有同样的数据（默认MySQL数据库）时这样的假设是合理的。接下来我们将展示如何一步步配置复制∶假设有服务器server1（IP地址192.168.0.1）和服务器server2（IP地址 192.168.0.2），我们将解释如何给一个已经运行的服务器配置备库，并探讨推荐的复制配置。

### 10.2.1 创建复制账号

MySQL会赋予一些特殊的权限给复制线程。在备库运行的I/O线程会建立一个到主库的 TCP/IP连接，这意味着必须在主库创建一个用户，并赋予其合适的权限。备库I/O线程以该用户名连接到主库并读取其二进制日志。通过如下语句创建用户账号∶

```
mysql> GRANT REPLICATITON SLAVE,REPLICATION CLIENT ON *.*->T0 repl@'192.168.0.%'IDENTIFIED BY'p4ssword',;
```

我们在主库和备库都创建该账号。注意我们把这个账户限制在本地网络，因为这是一个特权账号（尽管该账号无法执行 select或修改数据，但仍然能从二进制日志中获得一些数据）。

`复制账户事实上只需要有主库上的 REPLICATTON SLAVE权限，并不一定需要每一端服务器都有 REPLICATION CLIENT权限，那为什么我们要把这两种权限给主/备库都赋予呢?这有两个原因 ∶ `

`1.用来监控和管理复制的账号需要 REPLICATITON CLIENT权限，并且针对这两种目 的使用同一个账号更加容易（而不是为某个目的单独创建一个账号）。`

` 2.如果在主库上建立了账号，然后从主库将数据克隆到备库上时，备库也就设置好 了——变成主库所需要的配置。这样后续有需要可以方便地交换主备库的角色。`

### 10.2.2 配置主库和备库 

下一步需要在主库上开启一些设置，假设主库是服务器 serverl，需要打开二进制日志并指定一个独一无二的服务器 ID（server ID），在主库的my.cnf文件中增加或修改如下内容∶

```
log_bin = mysql-bin
server_id = 10'
```

实际取值由你决定，这里只是为了简单起见，当然也可以设置更多需要的配置。必须明确地指定一个唯一的服务器ID，默认服务器ID通常为1（这和版本相关，一些 MySQL版本根本不允许使用这个值）。使用默认值可能会导致和其他服务器的ID冲突，因此这里我们选择 10来作为服务器 ID。一种通用的做法是使用服务器IP地址的末8位，但要保证它是不变且唯一的（例如，服务器都在一个子网里）。最好选择一些有意义的约定并遵循。 如果之前没有在 MySQL的配置文件中指定 log-bin选项，就需要重新启动 MySQL。为了确认二进制日志文件是否已经在主库上创建，使用 SHOW MASTER STATUS命令，检查输出是否与如下的一致。MySQL会为文件名增加一些数字，所以这里看到的文件名和你定义的会有点不一样。

备库上也需要在 my.cnf中增加类似的配置，并且同样需要重启服务器。

```
log_bin = mysql-bin 
server_id = 2
relay_log = /var/lib/mysql/mysql-relay-bin
log_slave_updates = 1 
read_only= 1
```

从技术上来说，这些选项并不总是必要的。其中一些选项我们只是显式地列出了默认值。事实上只有 server_id是必需的。这里我们同样也使用了log_bin，并赋予了一个明确的名字。默认情况下，它是根据机器名来命名的，但如果机器名变化了可能会导致问题。为了简便起见，我们将主库和备库上的 Log-bin设置为相同的值。当然如果你愿意的话，也可以设置成别的值。 另外我们还增加了两个配置选项∶relay_Log（指定中继日志的位置和命名）和log_ sLave_updates（允许备库将其重放的事件也记录到自身的二进制日志中），后一个选项会给备库增加额外的工作，但正如后面将会看到的，我们有理由为每个备库设置该选项。有时候只开启了二进制日志，但却没有开启log_sLave_updates，可能会碰到一些奇怪的现象，例如，当配置错误时可能会导致备库数据被修改。如果可能的话，最好使用read_onLy配置选项，该选项会阻止任何没有特权权限的线程修改数据（所以最好不要给予用户超出需要的权限）。但 read_only选项常常不是很实用，特别是对于那些需要在备库建表的应用。

### 10.2.3 启动复制

下一步是告诉备库如何连接到主库并重放其二进制日志。这一步不要通过修改 my.cnf来配置，而是使用 CHANGE MASTER TO 语句，该语句完全替代了my.cnf中相应的设置，并且允许以后指向别的主库时无须重启备库。下面是开始复制的基本命令∶

```shell
mysql> CHANGE NASTER TO MASTER_HOST='server1',
->MASTER_USER='repl'
->MASTER_PASSWORD='p4ssword',
->MASTER_LOG_FILE='mysql-bin.00001',
->MASTER_LOG_POS=0;
```

MASTER_LOG_POS参数被设置为0，因为要从日志的开头读起。当执行完这条语句后，可以通过 SHOW SLAVE STATUS 语句来检查复制是否正确执行。

运行下面的命令开始复制∶

```shell
 mysql>START SLAVE;
```

执行该命令没有显示错误，现在我们再用 SHOW SLAVE STATUS命令检查∶

```shell
mysql> SHO SLAVE STATUS\G
************** 1.rOW*************
Slave_IO_State: Waiting for master to send event
Master_Host: server1 Master_User: repl Master_Port: 3306 
Connect_Retry: 60
Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 164
Relay_Log_File: mysql-relay-bin.0001
Relay_Log_Pos: 16
Relay_Master Log_File: mysql-bin.0001
Slave_IO_Running: Yes 
Slave_SQL_Running: Yes 
...omitted...
Seconds_Behind Master: 0
```

从输出可以看出I/O线程和SQL线程都已经开始运行，Seconds_Behind_Master的值也不再为NULL（稍后再解释 Seconds_Behind_Master的含义）。I/O线程正在等待从主库传递过来的事件，这意味着I/O线程已经读取了主库所有的事件。日志位置发生了变化，>表明已经从主库获取和执行了一些事件（你的结果可能会有所不同）。如果在主库上做一些数据更新，就会看到备库的文件或者日志位置都可能会增加。备库中的数据同样会随之更新。 

我们还可以从线程列表中看到复制线程。在主库上可以看到由备库I/O线程向主库发起的连接。

```shell
mysql> SHOW PROCESSLIST\G
*********************** 1.row**********************
Id: 55
User: repl
Host: replica1.webcluster_1:54813 
db: NULL
Command: Binlog Dump
Time: 610237
State: Has sent all binlog to slave; waiting for binlog to be updated 
Info: NULl
```

同样，在备库也可以看到两个线程，一个是 I/O 线程，一个是SQL线程∶

```
mysql> SHOW PROCESSLIST\G
************************* 1.row***************************
Id: 1
User: system user 
Host: 
db: NULL 
Command: Connect
Time: 61116
State: Waiting for master to send event 
Info: NULL
********************* 2.row*******************
Id: 2
User: system user 
Host:db: NULL 
Command: Connect
Time: 33
State: Has read all relay log;waiting for the slave I/0 thread to update it 
Info: NULL
```

这些简单的输出来自一台已经运行了一段时间的服务器，所以I/O线程在主库和备库上的Time列的值较大。SQL线程在备库已经空闲了33秒。这意味着33秒内没有重放任何事件。 这些线程总是运行在"system user"账号下，其他列的值则不相同。例如，当SQL线程回放事件时，Info 列可能显示正在执行的查询。 

### 10.2.4 从另一个服务器开始复制 

前面的设置都是假定主备库均为刚刚安装好且都是默认的数据，也就是说两台服务器上数据相同，并且知道当前主库的二进制日志。这不是典型的案例。大多数情况下有一个已经运行了一段时间的主库，然后用一台新安装的备库与之同步，此时这台备库还没有数据。 

有几种办法来初始化备库或者从其他服务器克隆数据到备库。包括从主库复制数据、从另外一台备库克隆数据，以及使用最近的一次备份来启动备库，需要三个条件来让主库和备库保持同步 ：

- 在某个时间点的主库的数据快照。 
- 主库当前的二进制日志文件，和获得数据快照时在该二进制日志文件中的偏移量，我们把这两个值称为日志文件坐标（logfle coordinates）。通过这两个值可以确定二进制日志的位置。可以通过 SHOW MASTER STATUS 命令来获取这些值。 
- 从快照时间到现在的二进制日志。

下面是一些从别的服务器克隆备库的方法∶

**使用冷备份**

最基本的方法是关闭主库，把数据复制到备库（高效复制文件的方法参考附录 C）。重启主库后，会使用一个新的二进制日志文件，我们在备库通过执行CHANGE MASTER TO指向这个文件的起始处。这个方法的缺点很明显∶在复制数据时需要关闭主库。

**使用热备份**

如果仅使用了MyISAM表，可以在主库运行时使用mysqlhotcopy或rsync来复制数据，更多细节参阅第 15 章。

**使用mysqldump**

如果只包含InnoDB表，那么可以使用以下命令来转储主库数据并将其加载到备库，然后设置相应的二进制日志坐标 ∶

```
$ mysqldump--single-transaction -all-databases--master-data=1--host=server1\ mysql --host=server2
```

选项--single-transaction使得转储的数据为事务开始前的数据。如果使用的是非事 务型表，可以使用--lock-all-tables 选项来获得所有表的一致性转储。

**使用快照或备份**

只要知道对应的二进制日志坐标，就可以使用主库的快照或者备份来初始化备库（如果使用备份，需要确保从备份的时间点开始的主库二进制日志都要存在）。只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER T0指定二进制日志的坐标。第 15 章会介绍更多的细节，也可以使用LVM快照、SAN快照、EBS快照——任何快照都可以。

**使用 Percona Xtrabackup**

Percona的Xtrabackup是一款开源的热备份工具，多年前我们就介绍过。它能够在备份时不阻塞服务器的操作，因此可以在不影响主库的情况下设置备库。可以通过克隆主库或另一个已存在的备库的方式来建立备库。 在 15章会介绍更多使用Percona Xtrabackup 的细节。这里会介绍一些相关的功能。创建一个备份（不管是从主库还是从别的备库），并将其转储到目标机器，然后根据备份获得正确的开始复制的位置。 

- 如果是从主库获得备份，可以从xtrabackup_binlog_pos_innodb文件中获得复 制开始的位置。 
- 如果是从另外的备库获得备份，可以从xtrabackup_sLave_info文件中获得复 制开始的位置。 

另外，在第 15章提到的InnoDB热备份和MySQL企业版的备份，也是比较好的初始化备库方式。

**使用另外的备库**

可以使用任何一种提及的克隆或者拷贝技术来从任意一台备库上将数据克隆到另外一台服务器。但是如果使用的是mysqldump，--master-data选项就会不起作用。此外，不能使用 SHOW MASTER STATUS来获得主库的二进制日志坐标，而是在获取快照时使用 SHOW SLAVE STATUS 来获取备库在主库上的执行位置。 使用另外的备库进行数据克隆最大的缺点是，如果这台备库的数据已经和主库不同步，克隆得到的就是脏数据。

### 10.2.5 推荐的复制配置 

有许多参数来控制复制，其中一些会对数据安全和性能产生影响。稍后我们会解释何种规则在何时会失效。本小节推荐的一种"安全"的配置，可以最小化问题发生的概率。

在主库上二进制日志最重要的选项是 sync_binLog ∶ 

```
sync_binlog=1
```

如果开启该选项，MySQL每次在提交事务前会将二进制日志同步到磁盘上，保证在服务器崩溃时不会丢失事件。如果禁止该选项，服务器会少做一些工作，但二进制日志文件可能在服务器崩溃时损坏或丢失信息。在一个不需要作为主库的备库上，该选项带来了不必要的开销。它只适用于二进制日志，而非中继日志。 

如果无法容忍服务器崩溃导致表损坏，推荐使用 InnoDB。在表损坏无关紧要时， MyISAM 是可以接受的，但在一次备库服务器崩溃重启后，MyISAM表可能已经处于不一致状态。一种可能是语句没有完全应用到一个或多个表上，那么即使修复了表，数据也可能是不一致的。

如果使用InnoDB，我们强烈推荐设置如下选项∶ 

```
innodb_flush_logs_at_trxcommit  # Flush every log write
innodb_support_xa=1             # MySQL 5.0 and newer only 
innodb_safe_binlog              #MySQL 4.1 only,roughly equivalent to
                                # innodb_support_xa
```

这些是 MySQL5.0 及最新版本中的默认配置，我们推荐明确指定二进制日志的名字，以保证二进制日志名在所有服务器上是一致的，避免因为服务器名的变化导致的日志文件名变化。你可能认为以服务器名来命名二进制日志无关紧要，但经验表明，当在服务器间转移文件、克隆新的备库、转储备份或者其他一些你想象不到的场景下，可能会导致很多问题。为了避免这些问题，需要给 log_bin选项指定一个参数。可以随意地给一个绝对路径，但必须明确地指定基本的命名（正如本章之前讨论的）。

```
log_bin=/var/lib/mysql/mysql-bin # Good; specifies a path and base name
#log_bin                         # Bad; base name will be server's hostname
```

在备库上，我们同样推荐开启如下配置选项，为中继日志指定绝对路径∶

```
relay_log=/path/to/logs/relay-bin 
skip slave start 
read only
```

通过设置 relay_log可以避免中继日志文件基于机器名来命名，防止之前提到的可能在主库发生的问题。指定绝对路径可以避免多个MySQL版本中存在的 Bug，这些Bug可能会导致中继日志在一个意料外的位置创建。skip_slave_start选项能够阻止备库在崩溃后自动启动复制。这可以给你一些机会来修复可能发生的问题。如果备库在崩溃后自动启动并且处于不一致的状态，就可能会导致更多的损坏，最后将不得不把所有数据丢弃，并重新开始配置备库。

 read_only选项可以阻止大部分用户更改非临时表，除了复制SQL线程和其他拥有超级权限的用户之外，这也是要尽量避免给正常账号授予超级权限的原因之一。

 即使开启了所有我们建议的选项，备库仍然可能在崩溃后被中断，因为masterinfo和中继日志文件都不是崩溃安全的。默认情况下甚至不会刷新到磁盘，直到 MySQL5.5版本才有选项来控制这种行为。如果正在使用MySQL5.5 并且不介意额外的fsync（）导致的性能开销，最好设置以下选项 ∶

```
sync_master_info = 1
sync_relay_log = 1
sync_relay_log_info = 1
```

如果备库与主库的延迟很大，备库的I/O线程可能会写很多中继日志文件，SQL线程在重放完一个中继日志中的事件后会尽快将其删除（通过 relay_log_purge选项来控制）。

但如果延迟非常严重，I/O线程可能会把整个磁盘撑满。解决办法是配置reLay_log_ Space_Limit变量。如果所有中继日志的大小之和超过这个值，I/O线程会停止，等待 SQL 线程释放磁盘空间。  

尽管听起来很美好，但有一个隐藏的问题。如果备库没有从主库上获取所有的中继日志，这些日志可能在主库崩溃时丢失。早先这个选项存在一些 Bug，使用率也不高，所以用到这个选项遇到Bug 的风险会更高。除非磁盘空间真的非常紧张，否则最好让中继日志使用其需要的磁盘空间，这也是为什么我们没有将 relay_log_space_Limit列入推荐的配置选项的原因。

## 10.3 复制的原理 

### 10.3.1 基于语句的复制 

在 MySQL 5.0 及之前的版本中只支持基于语句的复制（也称为逻辑复制），这在数据库领域是很少见的。基于语句的复制模式下，主库会记录那些造成数据更改的查询，当备库读取并重放这些事件时，实际上只是把主库上执行过的 SQL再执行一遍。这种方式既有好处，也有缺点。

最明显的好处是实现相当简单。理论上讲，简单地记录和执行这些语句，能够让主备保持同步。另一个好处是二进制日志里的事件更加紧凑，所以相对而言，基于语句的模式不会使用太多带宽。一条更新好几兆数据的语句在二进制日志里可能只占几十个字节。另外 mysqglbinlog 工具（本章多处会提到）是使用基于语句的日志的最佳工具。

但事实上基于语句的方式可能并不如其看起来那么便利。因为主库上的数据更新除了执行的语句外，可能还依赖于其他因素。例如，同一条 SQL在主库和备库上执行的时间可能稍微或很不相同，因此在传输的二进制日志中，除了查询语句，还包括了一些元数据信息，如当前的时间戳。即便如此，还存在着一些无法被正确复制的SQL。例如，使用 CURRENT_USER（）函数的语句。存储过程和触发器在使用基于语句的复制模式时也可能存在问题。

另外一个问题是更新必须是串行的。这需要更多的锁——有时候要特别关注这一点。另外不是所有的存储引擎都支持这种复制模式。尽管这些存储引擎是包括在 MySQL5.5及之前版本中发行的。

### 10.3.2 基于行的复制

MySQL 5.1开始支持基于行的复制，这种方式会将实际数据记录在二进制日志中，跟其他数据库的实现比较相像。它有其自身的一些优点和缺点。最大的好处是可以正确地复制每一行。一些语句可以被更加有效地复制。

```
基于行的复制没有向后兼容性，和MySQL5.1一起发布的mysqglbinlog 工具可以读取基于行的复制的事件格式（它对人是不可读的，但 MySQL可以解释），但是早期版本的 mysqglbinlog 无法识别这类事件，在遇到错误时会退出。
```

由于无须重放更新主库数据的查询，使用基于行的复制模式能够更高效地复制数据。重放一些查询的代价可能会很高。例如，下面有一个查询将数据从一个大表中汇总到小表∶

```sql
mysql>INSERT INTO summary_table(col1,col2,sum_col3)
    -> SELECT col1,col2,sum(col3)
    -> FROM enormous_table-> GROUP BY col1,col2;
```

想象一下，如果表enormous_table的列 col1和 coL2有三种组合，这个查询可能在源表上扫描多次，但最终只在目标表上产生三行数据。但使用基于行的复制方式，在备库上开销会小很多。这种情况下，基于行的复制模式更加高效。

但在另一方面，下面这条语句使用基于语句的复制方式代价会小很多∶ 

```
mysql>UPDATE enormous_table SET col1 = 0;
```

由于这条语句做了全表更新，使用基于行的复制开销会很大，因为每一行的数据都会被记录到二进制日志中，这使得二进制日志事件非常庞大。并且会给主库上记录日志和复制增加额外的负载，更慢的日志记录则会降低并发度。

由于没有哪种模式对所有情况都是完美的，MySQL能够在这两种复制模式间动态切换。默认情况下使用的是基于语句的复制方式，但如果发现语句无法被正确地复制，就切换到基于行的复制模式。还可以根据需要来设置会话级别的变量 binlog_format，控制二进制日志格式。 

对于基于行的复制模式，很难进行时间点恢复，但这并非不可能。稍后讲到的日志服务器对此会有帮助。

### 10.3.3 基于行或基于语句∶哪种更优 

**基于语句的复制模式的优点**

当主备的模式不同时，逻辑复制能够在多种情况下工作。例如，在主备上的表的定义不同但数据类型相兼容、列的顺序不同等情况。这样就很容易先在备库上修改 schema，然后将其提升为主库，减少停机时间。基于语句的复制方式一般允许更灵活的操作。

基于语句的方式执行复制的过程基本上就是执行 SQL语句。这意味着所有在服务器上发生的变更都以一种容易理解的方式运行。这样当出现问题时可以很好地去定位。

**基于语句的复制模式的缺点**

很多情况下通过基于语句的模式无法正确复制，几乎每一个安装的备库都会至少碰到一次。事实上对于存储过程，触发器以及其他的一些语句的复制在 5.0和5.1的一系列版本中存在大量的Bug。这些语句的复制的方式已经被修改了很多次，以使其更好地工作。简单地说∶如果正在使用触发器或者存储过程，就不要使用基于语句的复制模式，除非能够清楚地确定不会碰到复制问题。 

**基于行的复制模式的优点** 

几乎没有基于行的复制模式无法处理的场景。对于所有的 SQL构造、触发器、存储过程等都能正确执行。只是当你试图做一些诸如在备库修改表的schema这样的事情时才可能导致复制失败。

这种方式同样可能减少锁的使用，因为它并不要求这种强串行化是可重复的。

基于行的复制模式会记录数据变更，因此在二进制日志中记录的都是实际上在主库上发生了变化的数据。你不需要查看一条语句去猜测它到底修改了哪些数据。在某种程度上，该模式能够更加清楚地知道服务器上发生了哪些更改，并且有一个更好的数据变更记录。另外在一些情况下基于行的二进制日志还会记录发生改变之前的数据，因此这可能有利于某些数据恢复。

在很多情况下，由于无须像基于语句的复制那样需要为查询建立执行计划并执行查询，因此基于行的复制占用更少的 CPU。

最后，在某些情况下，基于行的复制能够帮助更快地找到并解决数据不一致的情况。举个例子，如果是使用基于语句的复制模式，在备库更新一个不存在的记录时不会失败，但在基于行的复制模式下则会报错并停止复制。 

**基于行的复制模式的缺点**

由于语句并没有在日志里记录，因此无法判断执行了哪些 SQL，除了需要知道行的变化外，这在很多情况下也很重要（这可能在未来的 MySQL 版本中被修复）。

使用一种完全不同的方式在备库进行数据变更——而不是执行 SQL。事实上，执行基于行的变化的过程就像一个黑盒子，你无法知道服务器正在做什么。并且没有很好的文档和解释。因此当出现问题时，可能很难找到问题所在。例如，若备库使用一个效率低下的方式去寻找行记录并更新，你无法观察到这一点。

如果有多层的复制服务器，并且所有的都被配置成基于行的复制模式，当会话级别的变量 @abinlog_format被设置成 STATEMENT时，所执行的语句在源服务器上被记录为基于语句的模式，但第一层的备库可能将其记录成行模式，并传递给其他层的备库。也就是说你期望的基于语句的日志在复制拓扑中将会被切换到基于行的模式。基于行的日志无法处理诸如在备库修改表的 schema 这样的情况，而基于语句的日志可以。

在某些情况下，例如找不到要修改的行时，基于行的复制可能会导致复制停止，而基于语句的复制则不会。这也可以认为是基于行的复制的一个优点。该行为可以通过 slave_exec_mode 来进行配置。 这些缺点正在被慢慢解决，但直到写作本书时，它们在大多数生产环境中依然存在。

### 10.3.4 复制文件

让我们来看看复制会使用到的一些文件。前面已经介绍了二进制日志文件和中继日志文件，其实还有其他的文件会被用到。不同版本的 MySQL 默认情况下可能将这些文件放到不同的目录里，大多取决具体的配置选项。可能在 data 目录或者包含服务器.pid文件的目录下（对于类 UNIX 系统可能是/var/run/mysqgld）。它们的详细介绍如下。

**mysql-bin.index**

当在服务器上开启二进制日志时，同时会生成一个和二进制日志同名的但以.index作为后缀的文件，该文件用于记录磁盘上的二进制日志文件。这里的"index"并不是指表的索引，而是说这个文件的每一行包含了二进制文件的文件名。 你可能认为这个文件是多余的，可以被删除（毕竟 MySQL可以在磁盘上找到它需要的文件）。事实上并非如此，MySQL依赖于这个文件，除非在这个文件里有记录，否则 MySQL 识别不了二进制日志文件。

**mysql-relay-bin-index**

这个文件是中继日志的索引文件，和 mysgl-bin.index 的作用类似。

**master.info**

这个文件用于保存备库连接到主库所需要的信息，格式为纯文本（每行一个值），不同的MySQL版本，其记录的信息也可能不同。此文件不能删除，否则备库在重启后无法连接到主库。这个文件以文本的方式记录了复制用户的密码，所以要注意此文件的权限控制。 

**relay-log.info** 

这个文件包含了当前备库复制的二进制日志和中继日志坐标（例如，备库复制在主库上的位置），同样也不要删除这个文件，否则在备库重启后将无法获知从哪个位置开始复制，可能会导致重放已经执行过的语句。



使用这些文件来记录 MySQL复制和日志状态是一种非常粗糙的方式。更不幸的是，它们不是同步写的。如果服务器断电并且文件数据没有被刷新到磁盘，在重启服务器后，文件中记录的数据可能是错误的。正如之前提到的，这些问题在 MySQL5.5 里做了改进。

以.index作为后缀的文件也与设置 expire_Logs_days存在交互，该参数定义了MySQL清理过期日志的方式，如果文件mysqgl-bin.index在磁盘上不存在，在某些 MySQL版本自动清理就会不起作用，甚至执行 PURGE MASTER LOGS语句也没有用。这个问题的解决方法通常是使用MySQL服务器管理二进制日志，这样就不会产生误解（这意味着不应该使用 rm 来自己清理日志）

最好能显式地执行一些日志清理策略，比如设置 expire_Logs_days参数或者其他方式，否则MySQL的二进制日志可能会将磁盘撑满。当做这些事情时，还需要考虑到备份策略。 

### 10.3.5 发送复制事件到其他备库

log_sLave_updates 选项可以让备库变成其他服务器的主库。在设置该选项后，MySQL会将其执行过的事件记录到它自己的二进制日志中。这样它的备库就可以从其日志中检索并执行事件。图 10-2 阐述了这一过程。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\备库复制.png" style="zoom:50%;" />

在这种场景下，主库将数据更新事件写入二进制日志，第一个备库提取并执行这个事件。这时候一个事件的生命周期应该已经结束了，但由于设置了log_slave_updates，备库会将这个事件写到它自己的二进制日志中。这样第二个备库就可以将事件提取到它的中继日志中并执行。这意味着作为源服务器的主库可以将其数据变化传递给没有与其直接相连的备库上。默认情况下这个选项是被打开的，这样在连接到备库时就不需要重启服务器。 

当第一个备库将从主库获得的事件写入到其二进制日志中时，这个事件在备库二进制日志中的位置与其在主库二进制日志中的位置几乎肯定是不相同的，可能在不同的日志文件或文件内不同的位置。这意味着你不能假定所有拥有同一逻辑复制点的服务器拥有相同的日志坐标。稍后我们会提到，这种情况会使某些任务更加复杂，例如，修改一个备库的主库或将备库提升为主库。

除非你已经注意到要给每个服务器分配一个唯一的服务器ID，否则按照这种方式配置备库会导致一些奇怪的错误，甚至还会导致复制停止。一个更常见的问题是∶为什么要指定服务器 ID，难道 MySQL在不知道复制命令来源的情况下不能执行吗?为什么 MySQL要在意服务器 ID是全局唯一的。问题的答案在于 MySQL在复制过程中如何防止无限循环。当复制SQL线程读中继日志时，会丢弃事件中记录的服务器ID和该服务器本身 ID 相同的事件，从而打破了复制过程中的无限循环。在某些复制拓扑结构下打破无限循环非常重要，例如主 -主复制结构。

```
如果在设置复制的时候碰到问题，服务器 ID 应该是需要检查的因素之一。当然只检查 @@server_id是不够的，它有一个默认值，除非在 my.cnf文件或通过 SET命令明确指定它的值，复制才会工作。如果使用 SET命令，确保同时也更新了配置文件，否则 SET 命令的设定可能在服务器重启后丢失。
```

### 10.3.6 复制过滤器

复制过滤选项允许你仅复制服务器上一部分数据，不过这可能没有想象中那么好用。有两种复制过滤方式∶在主库上过滤记录到二进制日志中的事件，以及在备库上过滤记录到中继日志的事件。图 10-3 显示了这两种类型。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\复制过滤.png" style="zoom:50%;" />

使用选项 binlog_do_db和 binlog_ignore_db来控制过滤，稍后我们会解释为什么通常不需要开启它们，除非你乐于向老板解释为什么数据会永久丢失并且无法恢复。

在备库上，可以通过设置 replicate_*选项，在从中继日志中读取事件时进行过滤。你可以复制或忽略一个或多个数据库，把一个数据库重写到另外一个数据库，或使用类似 LIKE 的模式复制或忽略数据库表。

要理解这些选项，最重要是弄清楚*_do_db和*_ignore_db在主库和备库上的意义，它们可能不会按照你所设想的那样工作。你可能会认为它会根据目标数据库名过滤，但实际上过滤的是当前的默认数据库。也就是说，如果在主库上执行如下语句 ∶

```
mysql> USE test;
mysql>DELETE FROM sakila.film;
```

*_do_db和*_ignore_db都会在数据库test上过滤DELETE语句，而不是在 sakila上。这通常不是想要的结果，可能会导致执行或忽略错误的语句。*_do_db和*_ignore_db有一些作用，但非常有限。必须要很小心地去使用这些参数，否则很容易造成主备不同步或复制出错。 

总地来说，复制过滤随时可能会发生问题。举个例子，假如要阻止赋权限操作传递给备库，这种需求是很普遍的。（提醒一下，这样做可能是错误的，有别的更好的方式来达成真正的目的）。过滤系统表的复制当然能够阻止 GRANT语句的复制，但同样也会阻止事件和定时任务的复制。正是这些不可预知的后果，使用复制过滤要非常慎重。更好的办法是阻止一些特殊的语句被复制，通常是设置 SQLLOG_BIN=0，虽然这种方法也有它的缺点。总地来说，除非万不得已，不要使用复制过滤，因为它很容易中断复制并导致问题，在需要灾难恢复时也会带来极大的不方便。

## 10.4 复制拓扑

可以在任意个主库和备库之间建立复制，只有一个限制∶每一个备库只能有一个主库。有很多复杂的拓扑结构，但即使是最简单的也可能会非常灵活。一种拓扑可以有多种用途。关于使用复制的不同方式可以很轻易地写一本书。 

我们已经讨论了如何为主库设置一个备库，本节我们讨论其他比较普遍的拓扑结构以及它们的优缺点。记住下面的基本原则 ∶

- 一个 MySQL 备库实例只能有一个主库。
-  每个备库必须有一个唯一的服务器 ID。 
-  一个主库可以有多个备库（或者相应的，一个备库可以有多个兄弟备库）。
- 如果打开了log_sLave_updates选项，一个备库可以把其主库上的数据变化传播到 其他备库。

### 10.4.1 一主库多备库

除了我们已经提过的两台服务器的主备结构外，这是最简单的拓扑结构。事实上一主多备的结构和基本配置差不多简单，因为备库之间根本没有交互*'，它们仅仅是连接到同一个主库上。图 10-4 显示了这种结构。 

在有少量写和大量读时，这种配置是非常有用的。可以把读分摊到多个备库上，直到备库给主库造成了太大的负担，或者主备之间的带宽成为瓶颈为止。你可以按照之前介绍的方法一次性设置多个备库，或者根据需要增加备库。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\一主多备.png" style="zoom:50%;" />

尽管这是非常简单的拓扑结构，但它非常灵活，能满足多种需求。下面是它的一些用途∶

- 为不同的角色使用不同的备库（例如添加不同的索引或使用不同的存储引擎）。
-  把一台备库当作待用的主库，除了复制没有其他数据传输。
- 将一台备库放到远程数据中心，用作灾难恢复。
- 延迟一个或多个备库，以备灾难恢复。 
- 使用其中一个备库，作为备份、培训、开发或者测试使用服务器。 

### 10.4.2 主动-主动模式下的主-主复制

主-主复制（也叫双主复制或双向复制）包含两台服务器，每一个都被配置成对方的主库和备库，换句话说，它们是一对主库。图 10-5 显示了该结构。 

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\双主.png" style="zoom:50%;" />

主动-主动模式下主-主复制有一些应用场景，但通常用于特殊的目的。一个可能的应用场景是两个处于不同地理位置的办公室，并且都需要一份可写的数据拷贝。

这种配置最大的问题是如何解决冲突，两个可写的互主服务器导致的问题非常多。这通常发生在两台服务器同时修改一行记录，或同时在两台服务器上向一个包含 AUT0_ INCREMENT 列的表里插入数据。

MySQL5.0 增加了一些特性，使得这种配置稍微安全了点，就是设置 auto_increment_ increment和auto_increment_offset。通过这两个选项可以让MySQL自动为INSERT语句选择不互相冲突的值。然而允许向两台主库上写入仍然很危险。在两台机器上根据不同的顺序更新，可能会导致数据不同步。例如，一个只有一列的表，只有一行值为1的记录，假设同时执行下面两条语句 ∶

- 在第一台主库上∶

  ```
  mysql> UPDATE tbl SET col=col+1;
  ```

- 在第二台主库上 ∶ 

  ```
  mysql> UPDATE tbl SET col=col *2;
  ```

那么结果呢?一台服务器上值为4，另一台的值为3，并且没有报告任何复制错误。

数据不同步还仅仅是开始。当正常的复制发生错误停止了，但应用仍在同时向两台服务器写入数据，这时候会发生什么呢?你不能简单地把数据从一台服务器复制到另外一台，因为这两台机器上需要复制的数据都可能发生了变化。解决这个问题将会非常困难。

如果足够仔细地配置这种架构，例如很好地划分数据和权限，并且你很清楚自己在做什么，可以避免一些问题。然而这通常很难做好，并且有更好的办法来实现你所需要的。

总地来说，允许向两个服务器上写入所带来的麻烦远远大于其带来的好处，但下一节描述的主动 -被动模式则会非常有用。

### 10.4.3 主动-被动模式下的主-主复制

这是前面描述的主-主结构的变体，它能够避免我们之前讨论的问题。这也是构建容错性和高可用性系统的非常强大的方式，主要区别在于其中的一台服务器是只读的被动服务器，如图 10-7所示。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\主被动主主复制.png)

这种方式使得反复切换主动和被动服务器非常方便，因为服务器的配置是对称的。这使得故障转移和故障恢复很容易。它也可以让你在不关闭服务器的情况下执行维护、优化表、升级操作系统（或者应用程序、硬件等）或其他任务。 

例如，执行 ALTER TABLE操作可能会锁住整个表，阻塞对表的读和写，这可能会花费很长时间并导致服务中断。然而在主-主配置下，可以先停止主动服务器上的备库复制线程（这样就不会在被动服务器上执行任何更新），然后在被动服务器上执行 ALTER操作，交换角色，最后在先前的主动服务器上启动复制线程。这个服务器将会读取中继日志并执行相同的 ALTER语句。这可能花费很长时间，但不要紧，因为该服务器没有为任何活跃查询提供服务。

主动-被动模式的主-主结构能够帮助回避许多MySQL的问题和限制，此外还有一些工具可以完成这种类型的操作。

让我们看看如何配置主-主服务器对，在两台服务器上执行如下设置后，会使其拥有对称的设置∶

1. 确保两台服务器上有相同的数据。
2. 启用二进制日志，选择唯一的服务器 ID，并创建复制账号。
3. 启用备库更新的日志记录，后面将会看到，这是故障转移和故障恢复的关键。
4. 把被动服务器配置成只读，防止可能与主动服务器上的更新产生冲突，这一点是可 选的。
5. 启动每个服务器的 MySQL 实例。
6. 将每个主库设置为对方的备库，使用新创建的二进制日志开始工作。

让我们看看主动服务器上更新时会发生什么事情。更新被记录到二进制日志中，通过复制传递给被动服务器的中继日志中。被动服务器执行查询并将其记录到自己的二进制日志中（因为开启了log_sLave_updates选项）。由于事件的服务器ID与主动服务器的相同，因此主动服务器将忽略这些事件。在后面的"修改主库"可了解更多的角色切换相关内容。

设置主动-被动的主-主拓扑结构在某种意义上类似于创建一个热备份，但是可以使用这个"备份"来提高性能，例如，用它来执行读操作、备份、"离线"维护以及升级等。真正的热备份做不了这些事情。然而，你不会获得比单台服务器更好的写性能（稍后会提到）。

当我们讨论使用复制的场景和用途时，还会提到这种复制方式。它是一种非常常见并且重要的拓扑结构。

### 10.4.4 拥有备库的主-主结构 

另外一种相关的配置是为每个主库增加一个备库，如图 10-8 所示。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\拥有备库主主.png" style="zoom:50%;" />

这种配置的优点是增加了冗余，对于不同地理位置的复制拓扑，能够消除站点单点失效的问题。你也可以像平常一样，将读查询分配到备库上。

 如果在本地为了故障转移使用主-主结构，这种配置同样有用。当主库失效时，用备库来代替主库还是可行的，虽然这有点复杂。同样也可以把备库指向一个不同的主库，但需要考虑增加的复杂度。

### 10.4.5 环形复制 

如图 10-9 所示，双主结构实际上是环形结构的一种特例】。环形结构可以有三个或更多的主库。每个服务器都是在它之前的服务器的备库，是在它之后的服务器的主库。这种结构也称为环形复制（circular replication）。

环形结构没有双主结构的一些优点，例如对称配置和简单的故障转移，并且完全依赖于环上的每一个可用节点，这大大增加了整个系统失效的几率。如果从环中移除一个节点，这个节点发起的事件就会陷入无限循环∶它们将永远绕着服务器链循环。因为唯一可以根据服务器 ID 将其过滤的服务器是创建这个事件的服务器。总地来说，环形结构非常脆弱，应该尽量避免。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\环形复制.png" style="zoom:50%;" />

可以通过为每个节点增加备库的方式来减少环形复制的风险，如图 10-10所示。但这仅仅防范了服务器失效的危险，断电或者其他一些影响到网络连接的问题都可能破坏整个环。 

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\拥有备库的环形复制.png" style="zoom:50%;" />

### 10.4.6 主库、分发主库以及备库

我们之前提到当备库足够多时，会对主库造成很大的负载。每个备库会在主库上创建一个线程，并执行binlog dump命令。该命令会读取二进制日志文件中的数据并将其发送给备库。每个备库都会重复这样的工作，它们不会共享 binlog dump 的资源。

如果有很多备库，并且有大的事件时，例如一次很大的 LOAD DATA INFILE操作，主库上的负载会显著上升，甚至可能由于备库同时请求同样的事件而耗尽内存并崩溃。另一方面，如果备库请求的数据不在文件系统的缓存中，可能会导致大量的磁盘检索，这同样会影响主库的性能并增加锁的竞争。 

因此，如果需要多个备库，一个好办法是从主库移除负载并使用分发主库。分发主库事实上也是一个备库，它的唯一目的就是提取和提供主库的二进制日志。多个备库连接到分发主库，这使原来的主库摆脱了负担。为了避免在分发主库上做实际的查询，可以将它的表修改为 blackhole 存储引擎，如图 10-11 所示。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\分发主库.png" style="zoom:50%;" />

很难说当备库数据达到多少时需要一个分发主库。按照通用准则，如果主库接近满负载，不应该为其建立 10个以上的备库。如果有少量的写操作，或者只复制其中一部分表，主库就可以提供更多的复制。另外，也不一定只使用一个分发主库。如果需要的话，可以使用多个分发主库向大量的备库进行复制，或者使用金字塔状的分发主库。在某些情况下，可以通过设置slave_compressed_protocol来节约一些主库带宽。这对跨数据中心复制很有好处。

还可以通过分发主库实现其他目的，例如，对二进制日志事件执行过滤和重写规则。这比在每个备库上重复进行日志记录、重写和过滤要高效得多。 

如果在分发主库上使用blackhole表，可以支持更多的备库。虽然会在分发主库执行查询，但其代价非常小，因为 blackhole表中没有任何数据。blockhole表的缺点是其存在Bug，例如在某些情况下会忘记将自增ID写入到二进制日志中。所以要小心使用 blackhole表。

一个比较常见的问题是如何确保分发服务器上的每个表都是 blackhole存储引擎。如果有人在主库创建了一个表并指定了不同的存储引擎呢?确实，不管什么时候，在备库上使用不同的存储引擎总会导致同样的问题。常见的解决方案是设置服务器的storage_ engine 选项∶

```
storage_engine= blackhole
```

这只会影响那些没有指定存储引擎的 CREATE TABLE的语句。如果有一个无法控制的应用，这种拓扑结构可能会非常脆弱。可以通过skip_innodb选项禁止InnoDB，将表退化为 MyISAM。但你无法禁止 MyISAM或者 Memory 引擎。 

使用分发主库另外一个主要的缺点是无法使用一个备库来代替主库。因为由于分发主库的存在，导致各个备库与原始主库的二进制日志坐标已经不相同。

### 10.4.7 树或金字塔形

如果正在将主库复制到大量的备库中。不管是把数据分发到不同的地方，还是提供更高的读性能，使用金字塔结构都能够更好地管理，如图 10-12 所示。

这种设计的好处是减轻了主库的负担，就像前一节提到的分发主库一样。它的缺点是中间层出现的任何错误都会影响到多个服务器。如果每个备库和主库直接相连就不会存在这样的问题。同样，中间层次越多，处理故障会更困难、更复杂。 

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\金字塔.png" style="zoom:50%;" />

### 10.4.8 定制的复制方案

MySQL的复制非常灵活，可以根据需要定制解决方案。典型的定制方案包括组合过滤、分发和向不同的存储引擎复制。也可以使用"黑客手段"，例如，从一个使用 blackhole存储引擎的服务器上复制或复制到这样的服务器上（本章已讨论过）。可以根据需要任意设计。这其中最大的限制是合理地监控和管理，以及所拥有资源的约束（网络带宽、 CPU 能力等）。

#### 选择性复制 

为了利用访问局部性原理（locality of reference），并将需要读的工作集驻留在内存中，可以复制少量数据到备库中。如果每个备库只拥有主库的一部分数据，并且将读分配给备库，就可以更好地利用备库的内存。并且每个备库也只有主库一部分的写入负载，这样主库的能力更强并能保证备库延迟。 

这个方案有点类似下一章我们会讨论到的水平数据划分，但它的优势在于主库包含了所有的数据集，这意味着无须为了一条写入查询去访问多个服务器。如果读操作无法在备库上找到数据，还可以通过主库来查询。即使不能从备库上读取所有数据，也可以移除大量的主库读负担。 

最简单的方法是在主库上将数据划分到不同的数据库里。然后将每个数据库复制到不同的备库上。例如，若需要将公司的每一个部门的数据复制到不同的备库，可以创建名为 sales、marketing、procurement等的数据库，每个备库通过选项 repLicate_wild_do table 选项来限制给定数据库的数据。下面是 sales 数据库的配置 ∶

```
replicate wild do table= sales.%
```

也可以通过一台分发主库进行分发。举个例子，如果想通过一个很慢或者非常昂贵的网络，从一台负载很高的数据库上复制一部分数据，就可以使用一个包含 blackhole表和过滤规则的本地分发主库，分发主库可以通过复制过滤移除不需要的日志。这可以避免在主库上进行不安全的日志选项设定，并且无须传输所有的数据到远程备库。

#### 分离功能 

许多应用都混合了在线事务处理（OLTP）和在线数据分析（OLAP）的查询。OLTP查询比较短并且是事务型的，OLAP查询则通常很大，也很慢，并且不要求绝对最新的数据。这两种查询给服务器带来的负担完全不同，因此它们需要不同的配置，甚至可能使用不同的存储引擎或者硬件。 

一个常见的办法是将 OLTP服务器的数据复制到专门为 OLAP工作负载准备的备库上。这些备库可以有不同的硬件、配置、索引或者不同的存储引擎。如果决定在备库上执行 OLAP查询，就可能需要忍受更大的复制延迟或降低备库的服务质量。这意味着在一个非专用的备库上执行一些任务时，可能会导致不可接受的性能，例如执行一条长时间运行的查询。

无须做一些特殊的配置，除了需要选择忽略主库上的一些数据，前提是能获得明显的提升。即使通过复制过滤器过滤掉一小部分的数据也会减少I/O 和缓存活动。  

#### 数据归档 

可以在备库上实现数据归档，也就是说可以在备库上保留主库上删除过的数据，在主库上通过delete 语句删除数据时确保 delete语句不传递到备库就可以实现。有两种通常的办法∶一种是在主库上选择性地禁止二进制日志，另一种是在备库上使用 repLicate_ ignore_db 规则（是的，两种方法都很危险）。 

第一种方法需要先将 SQL_L0G_BIN设置为0，然后再进行数据清理。这种方法的好处是不需要在备库进行任何配置，由于 SQL 语句根本没有记录到二进制日志中，效率会稍微有所提升。最大缺点也正因为没有将在主库的修改记录下来，因此无法使用二进制日志来进行审计或者做按时间点的数据恢复。另外还需要 SUPER 权限。

第二种方法是在清理数据之前对主库上特定的数据库使用 USE语句。例如，可以创建一个名为 purge的数据库，然后在备库的my.cnf文件里设置 repLicate_ignore_db=purge并重启服务器。备库将会忽略使用了USE语句指定的数据库。这种方法没有第一种方法的缺点，但有另一个小小的缺点∶备库需要去读取它不需要的事件。另外，也可能有人在 purge 数据库上执行非清理查询，从而导致备库无法重放该事件。

#### 将备库用作全文检索 

许多应用要求合并事务和全文检索。然而在写作本书时，仅有 MyISAM支持全文检索，但是MyISAM不支持事务（在 MySQL5.6有一个实验室预览版本实现了InnoDB的全文检索，但尚未 GA）。一个普遍的做法是配置一台备库，将某些表设置为 MyISAM存储引擎，然后创建全文索引并执行全文检索查询。这避免了在主库上同时使用事务型和非事务型存储引擎所带来的复制问题，减轻了主库维护全文索引的负担。

#### 只读备库

许多机构选择将备库设置为只读，以防止在备库进行的无意识修改导致复制中断。可以通过设置 read_only选项来实现。它会禁止大部分写操作，除了复制线程和拥有超级权 限的用户以及临时表操作。只要不给也不应该给普通用户超级权限，这应该是很完美的方法。

#### 模拟多主库复制

当前 MySQL不支持多主库复制（一个备库拥有多个主库）。但是可以通过把一台备库轮流指向多台主库的方式来模拟这种结构。例如，可以先将备库指向主库 A，运行片刻，再将其指向主库 B并运行片刻，然后再次切换回主库 A。这种办法的效果取决于数据以及两台主库导致备库所需完成的工作量。如果主库的负载很低，并且主库之间不会产生更新冲突，就会工作得很好。

需要做一些额外的工作来为每个主库跟踪二进制日志坐标。可能还需要保证备库的I/O线程在每一次循环提取超过需要的数据，否则可能会因为每次循环反复地提取和抛弃大量数据导致主库的网络流量和开销明显增大。

还可以使用主-主（或者环形）复制结构以及使用blackhole存储引擎表的备库来进行模拟，如图 10-13所示。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\模拟多主复制.png" style="zoom:50%;" />

在这种配置中，两台主库拥有自己的数据，但也包含了对方的表，但是对方的表使用 blackhole存储引擎以避免在其中存储实际数据。备库和其中任意一个主库相连都可以。备库不使用 blackhole 存储引擎，因此其对两个主库而言都是有效的。

事实上并不一定需要主-主拓扑结构来实现，可以简单地将server1复制到server2，再从 server2复制到备库。如果在 server2上为从server1上复制的数据使用blackhole存储引擎，就不会包含任何 server1的数据，如图 10-14 所示。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\模拟多主复制1.png" style="zoom:50%;" />

这些配置方法常常会碰到一些常见的问题，例如，更新冲突或者建表时明确指定存储引擎。 另外一个选择是使用 Continuent 的 Tungsten Replicator，我们会在本章稍后部分讨论。 

#### 创建日志服务器

使用 MySQL复制的另一种用途就是创建没有数据的日志服务器。它唯一的目的就是更加容易重放并且/或者过滤二进制日志事件。就如本章稍后所述，它对崩溃后重启复制很有帮助。同时对基于时间点的恢复也很有帮助，在第 15 章我们会讨论。 

假设有一组二进制日志或中继日志——可能从备份或者一台崩溃的服务器上获取——希望能够重放这些日志中的事件，可以通过 mysglbinlog 工具从其中提取出事件，但更加方便和高效的方法是配置一个没有任何数据的 MySQL实例并使其认为这些二进制日志是它拥有的。如果只是临时需要，可以从http∶/mysqlsandbox.net 上获得一个MySQL沙箱脚本来创建日志服务器。因为无须执行二进制日志，日志服务器也就不需要任何数据。它的目的仅仅是将数据提供给别的服务器 （但复制账户还是需要的）。 

我们来看看该策略是如何工作的（稍后会展示一些相关应用）。假设日志被命名为 somelog-bin.000001、somelog-bin.000002，等等，将这些日志放到日志服务器的日志文件求中，假设为/ar/og/mysql。然后在启动服务器前编辑my.cnf文件，如下所示∶

```
log_bin= /var/log/mysql/somelog-bin
log_bin_index= /var/log/mysql/somelog-bin.index
```

服务器不会自动发现日志文件，因此还需要更新日志的索引文件。下面这个命令可以在 类 UNIX系统上完成 

```
#/bin/ls-1 /var/log/mysql/somelog-bin.[0-9]*>/var/log/mysql/somelog-bin.index
```

确保运行 MySQL 的账户能够读写日志索引文件。现在可以启动日志服务器并通过 SHOw MASTER LOGS 命令来确保其找到日志文件。

为什么使用日志服务器比用mysqglbinlog来实现恢复更好呢?有以下几个原因∶ 

- 复制作为应用二进制日志的方法已经被大量的用户所测试，能够证明是可行的。 mysglbinlog并不能确保像复制那样工作，并且可能无法正确生成二进制日志中的数据更新。 
- 复制的速度更快，因为无须将语句从日志导出来并传送给 MySQL。
- 可以很容易观察到复制过程。
-  能够更方便处理错误。例如，可以跳过执行失败的语句。
- 更方便过滤复制事件。
-  有时候 mysqlbinlog 会因为日志记录格式更改而无法读取二进制日志。

## 10.5 复制和容量规划

写操作通常是复制的瓶颈，并且很难使用复制来扩展写操作。当计划为系统增加复制容量时，需要确保进行了正确的计算，否则很容易犯一些复制相关的错误。

例如，假设工作负载为20%的写以及80%的读。为了计算简单，假设有以下前提∶ 

- 读和写查询包含同样的工作量。 
- 所有的服务器是等同的，每秒能进行1000次查询。
- 备库和主库有同样的性能特征。
- 可以把所有的读操作转移到备库。

如果当前有一个服务器能支持每秒1000 次查询，那么应该增加多少备库才能处理当前两倍的负载，并将所有的读查询分配给备库?

看上去应该增加两个备库并将1600 次读操作平分给它们。但是不要忘记，写入负载同样增加到了400 次每秒，并且无法在主备服务器之间进行分摊。每个备库每秒必须处理 400次写入，这意味着每个备库写入占了40%，只能每秒为 600次查询提供服务。因此，需要三台而不是两台备库来处理双倍负载。 

如果负载再增加一倍呢?将有每秒800次写入，这时候主库还能处理，但备库的写入同样也提升到 80%，这样就需要16台备库来处理每秒3200次读查询。并且如果再增加一点负载，主库也会无法承担。

这远远不是线性扩展，查询数量增加4倍，却需要增加17倍的服务器。这说明当为单台主库增加备库时，将很快达到投入远高于回报的地步。这仅仅是基于上面的假设，还忽略了一些事情，例如，单线程的基于语句的复制常常导致备库容量小于主库。真实的复制配置比我们的理论计算还要更差。

### 10.5.1 为什么复制无法扩展写操作

糟糕的服务容量比例的根本原因是不能像分发读操作那样把写操作等同地分发到更多服务器上。换句话说，复制只能扩展读操作，无法扩展写操作。

你可能想知道到底有没有办法使用复制来增加写入能力。答案是否定的，根本不行。**对数据进行分区是唯一可以扩展写入的方法，我们在下一章会讲到。**

一些读者可能会想到使用主-主拓扑结构（参阅前面介绍的"主动-主动模式下的主-主复制"）并为两个服务器执行写操作。这种配置比主备结构能支持稍微多一点的写入，因为可以在两台服务器之间共享串行化带来的开销。如果每台服务器上执行 50%的写入，那复制的执行量也只有 50%需要串行化。理论上讲，这比在一台机器上（主库）对 100%的写入并发执行，而在另外一台机器（备库）上对 100%的写入做串行化要更优。

这可能看起来很吸引人，然而这种配置还比不上单台服务器能支持的写入。一个有 50%的写入被串行化的服务器性能比一台全部写入都并行化的服务器性能要低。 

这是这种策略不能扩展写入的原因。它只能在两台服务器间共享串行化写入的缺点。所以"链中最弱的一环"并不是那么弱，它只提供了比主动-被动复制稍微好点的性能，但是增加了很大的风险，通常不能带来任何好处，具体原因见下一节。 

### 10.5.2 备库什么时候开始延迟

一个关于备库比较普遍的问题是如何预测备库会在何时跟不上主库。很难去描述备库使用的复制容量为 5%与95%的区别，但是至少能够在接近饱和前预警并估计复制容量。

首先应该观察复制延迟的尖刺。如果有复制延迟的曲线图，需要注意到图上的一些短暂的延迟骤升，这时候可能负载加大，备库短时间内无法跟上主库。当负载接近耗尽备库的容量时，会发现曲线上的凸起会更高更宽。前面曲线的上升角度不变，但随后当备库在产生延迟后开始追赶主库时，将会产生一个平缓的斜坡。这些突起的出现和增长是一个警告信息，意味着已经接近容量限制。 

为了预测在将来的某个时间点会发生什么，可以人为地制造延迟，然后看多久备库能赶上主库。目的是为了明确地说明曲线上的斜坡的陡度。如果将备库停止一个小时，然后开启并在1小时内追赶上，说明正常情况下只消耗了一半的容量。也就是说，如果中午 12∶00停止备库复制，在1∶00开启，并且在2∶00追赶上，备库在一小时内完成了两个小时内所有的变更，说明复制可以在双倍速度下运行。

### 10.5.3 规划冗余容量

在构建一个大型应用时，有意让服务器不被充分使用，这应该是一种聪明并且划算的方式，尤其在使用复制的时候。有多余容量的服务器可以更好地处理负载尖峰，也有更多能力处理慢速查询和维护工作（如 OPTIMIZE TABLE操作），并且能够更好地跟上复制。 

试图同时向主-主拓扑结构的两个节点写入来减少复制问题通常是不划算的。分配给每台机器的读负载应该低于50%，否则，如果某台服务器失效，就没有足够的容量了。如果两台服务器都能够独立处理负载，就用不着担心复制的问题了。

构建冗余容量也是实现高可用性的最佳方式之一，当然还有别的方式，例如，当错误发生时让应用在降级模式下运行，第 12 章会介绍更多的细节。

## 10.6 复制管理和维护 

配置复制一般来说不会是需要经常做的工作，除非有很多服务器。但是一旦配置了复制，监控和管理复制拓扑应该成为一项日常工作，不管有多少服务器。 

这些工作应该尽量自动化，但不一定需要自己写工具来实现∶在 16章我们讨论了几个 MySQL 工具，其中许多都拥有内建的监控复制的能力或插件。

### 10.6.1 监控复制

复制增加了MySQL监控的复杂性。尽管复制发生在主库和备库上，但大多数工作是在备库上完成的，这也正是最常出问题的地方。是否所有的备库都在工作?最慢的备库延迟是多大?MySQL本身提供了大量可以回答上述问题的信息，但要实现自动化监控过程以及使复制更健壮还是需要用户做更多的工作。

在主库上，可以使用 SHOW MASTER STATUS 命令来查看当前主库的二进制日志位置和配置（详细参阅前面介绍的"配置主库和备库"部分）。还可以查看主库当前有哪些二进制日志是在磁盘上的

另外还可以通过 SHOW BINLOG EVENTS来查看复制事件。例如，在运行前一个命令后，我们在另一个不曾使用过的服务器上创建一个表，因为知道这是唯一改变数据的语句，而且也知道语句在二进制日志中的偏移量是 13634，所以我们可以看到如下内容 ∶

```
mysql> SHON BINLOG EVENTS IN'mysql-bin.00223'FROM 13634\G
```

### 10.6.2 测量备库延迟 

一个比较普遍的问题是如何监控备库落后主库的延迟有多大。虽然 SHOW SLAVE STATUS输出的 Seconds_behind_master列理论上显示了备库的延时，但由于各种各样的原因，并不总是准确的∶

- 备库 Seconds_behind_master值是通过将服务器当前的时间戳与二进制日志中的事件的时间戳相对比得到的，所以只有在执行事件时才能报告延迟。
- 如果备库复制线程没有运行，就会报延迟为 NULL。
- 一些错误（例如主备的 max allowed_packet不匹配，或者网络不稳定）可能中断复制并且/或者停止复制线程，但 Seconds_behind_master将显示为0而不是显示错误。
-  即使备库线程正在运行，备库有时候可能无法计算延时。如果发生这种情况，备库 会报0或者 NULL。
- 一个大事务可能会导致延迟波动，例如，有一个事务更新数据长达一个小时，最后 提交。这条更新将比它实际发生时间要晚一个小时才记录到二进制日志中。当备库执行这条语句时，会临时地报告备库延迟为一个小时，然后又很快变成0。
- 如果分发主库落后了，并且其本身也有已经追赶上它的备库，备库的延迟将显示为0，而事实上和源主库之间是有延迟的。

解决这些问题的办法是忽略Seconds_behind_master的值，并使用一些可以直接观察和衡量的方式来监控备库延迟。最好的解决办法是使用heartbeat record，这是一个在主库上会每秒更新一次的时间戳。为了计算延时，可以直接用备库当前的时间戳减去心跳记录的值。这个方法能够解决刚刚我们提到的所有问题，另外一个额外的好处是我们还可以通过时间戳知道备库当前的复制状况。包含在Percona Tookit里的pt-heartbeat脚本是"复制心跳"最流行的一种实现。

心跳还有其他好处，记录在二进制日志中的心跳记录拥有许多用途，例如在一些很难解决的场景下可以用于灾难恢复。

我们刚刚所描述的几种延迟指标都不能表明备库需要多长时间才能赶上主库。这依赖于许多因素，例如备库的写入能力以及主库持续写入的次数。关于这个话题，详细参阅前面介绍的"何时备库开始延迟"。

### 10.6.3 确定主备是否一致 

在理想情况下，备库和主库的数据应该是完全一样的。但事实上备库可能发生错误并导致数据不一致。即使没有明显的错误，备库同样可能因为 MySQL自身的特性导致数据不一致，例如 MySQL的 Bug、网络中断、服务器崩溃，非正常关闭或者其他一些错误。

按照我们的经验来看，主备一致应该是一种规范，而不是例外，也就是说，检查你的主备一致性应该是一个日常工作，特别是当使用备库来做备份时尤为重要，因为你肯定不希望从一个已经损坏的备库里获得备份数据。 

MySQL并没有内建的方法来比较一台服务器与别的服务器的数据是否相同。它提供了一些组件来为表和数据生成校验值，例如 CHECKSUM TABLE。但当复制正在进行时，这种方法是不可行的。

Percona Toolkit 里的pt-table-checksum能够解决上述几个问题。其主要特性是用于确认备库与主库的数据是否一致。工作方式是通过在主库上执行 INSERT...SELECT查询。

这些查询对数据进行校验并将结果插入到一个表中。这些语句通过复制传递到备库，并在备库执行一遍，然后可以比较主备上的结果是否一样。由于该方法是通过复制工作的，它能够给出一致的结果而无须同时把主备上的表都锁上。

通常情况下可以在主库上运行该工具，参数如下∶

```
$pt-table-checksum --replicate=test.checksum<master_host>
```

该命令将检查所有的表，并将结果插入到test.checksum表中。当查询在备库执行完后，就可以简单地比较主备之间的不同了。pt-table-checksum 能够发现服务器所有的备库，在每台备库上运行查询，并自动地输出结果。在写作本书时，pt-table-checksum是唯一能够有效地比较主备一致性的工具。 

### 10.6.4 从主库重新同步备库

在你的职业生涯中，也许会不止一次需要去处理未被同步的备库。可能是使用校验工具发现了数据不一致，或是因为已经知道是备库忽略了某条查询或者有人在备库上修改了数据。

传统的修复不一致的办法是关闭备库，然后重新从主库复制一份数据。当备库数据不一致的问题可能导致严重后果时，一旦发现就应该将备库停止并从生产环境移除，然后再从一个备份中克隆或恢复备库。

这种方法的缺点是不太方便，特别是数据量很大时。如果能够找出并修复不一致的数据，要比从其他服务器上重新克隆数据要有效得多。如果发现的不一致并不严重，就可以保持备库在线，并重新同步受影响的数据。

### 10.6.5 改变主库

迟早会有把备库指向一个新的主库的需求。也许是为了更迭升级服务器，或者是主库出现问题时需要把一台备库转换成主库，或者只是希望重新分配容量。不管出于什么原因，都需要告诉其他的备库新主库的信息。

## 10.7 复制的问题和解决方案

中断 MySQL的复制并不是件难事。因为实现简单，配置相当容易，但也意味着有很多方式会导致复制停止，陷入混乱并中断。本章描述了一些比较普遍的问题，讨论如何重现这些问题，以及当遇到这些问题时如何解决或者阻止其发生。

### 10.7.1 数据损坏或丢失的错误 

由于各种各样的原因，MySQL的复制并不能很好地从服务器崩溃、掉电、磁盘损坏、内存或网络错误中恢复。遇到这些问题时几乎可以肯定都需要从某个点开始重启复制。大部分由于非正常关机后导致的复制问题都是由于没有把数据及时地刷到磁盘。下面是意外关闭服务器时可能会碰到的情况。

**主库意外关闭** 

如果没有设置主库的 sync_binlog选项，就可能在崩溃前没有将最后的几个二进制日志事件刷新到磁盘中。备库 I/O 线程因此也可一直处于读不到尚未写入磁盘的事件的状态中。当主库重新启动时，备库将重连到主库并再次尝试去读该事件，但主库会告诉备库没有这个二进制日志偏移量。二进制日志转储线程通常很快，因此这种情况并不经常发生。

解决这个问题的方法是指定备库从下一个二进制日志的开头读日志。但是一些日志事件将永久地丢失，建议使用Percona Toolkit中的pt-table-checksum工具来检查主备一致性，以便于修复。可以通过在主库开启 sync_binlog来避免事件丢失。即使开启了 sync_binlog，MyISAM表的数据仍然可能在崩溃的时候损坏，对于 InnoDB事务，如果innodb_flush_Log_at_trx_commit没有设为1，也可能丢失数据（但数据不会损坏）。

**备库意外关闭** 

如果没有设置主库的 sync_binLog 选项，就可能在崩溃前没有将最后的几个二进制日志事件刷新到磁盘中。备库I/O 线程因此也可一直处于读不到尚未写入磁盘的事件的状态中。当主库重新启动时，备库将重连到主库并再次尝试去读该事件，但主库会告诉备库没有这个二进制日志偏移量。二进制日志转储线程通常很快，因此这种情况并不经常发生。

Percona Toolkit 中的 pt-slave-restart 工具可以帮助完成这一点。 

如果使用的都是 InnoDB表，可以在重启后观察 MySQL错误日志。InnoDB在恢复过程中会打印出它的恢复点的二进制日志坐标。可以使用这个值来决定备库指向主库的偏移量。Percona Server 提供了一个新的特性，可以在恢复的过程中自动将这些信息提取出来，并更新masterinfo文件，从根本上使得复制能够协调好备库上的事务。

MySQL 5.5 也提供了一些选项来控制如何将masterinfo 和其他文件刷新到磁盘，这有助于减少这些问题。

除了由于MySQL非正常关闭导致的数据丢失外，磁盘上的二进制日志或中继日志文件损坏并不罕见。下面是一些更普遍的场景 ∶ 

**主库上的二进制日志损坏** 

如果主库上的二进制日志损坏，除了忽略损坏的位置外你别无选择。可以在主库上执行 FLUSH L0GS命令，这样主库会开始一个新的日志文件，然后将备库指向该文件的开始位置。也可以试着去发现损坏区域的结束位置。某些情况下可以通过 SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1来忽略一个损坏的事件。如果有多个损坏的事件，就需要重复该步骤，直到跳过所有损坏的事件。但如果有太多的损坏事件，这么做可能就没有意义了。损坏的事件头会阻止服务器找到下一个事件。这种情况下，可能不得不手动地去找到下一个完好的事件。

**备库上的中继日志损坏** 

如果主库上的日志是完好的，就可以通过 CHANGE MASTER T0命令丢弃并重新获取损坏的事件。只需要将备库指向它当前正在复制的位置（Relay_Master_Log_File/ Exec Master_Log_Pos）。这会导致备库丢弃所有在磁盘上的中继日志。就这一点而言， MySQL 5.5 做了一些改进，它能够在崩溃后自动重新获取中继日志。

**二进制日志与InnoDB 事务日志不同步** 

当主库崩溃时，InnoDB可能将一个事务标记为已提交，此时该事务可能还没有记录到二进制日志中。除非是某个备库的中继日志已经保存，否则没有任何办法恢复丢失的事务。在 MySQL5.0版本可以设置 sync_binlog选项来防止该问题，对于更早的 MySQL 4.1可以设置 sync_binlog 和 safe_binlog 选项。

当一个二进制日志损坏时，能恢复多少数据取决于损坏的类型，有几种比较常见的类型∶

**数据改变，但事件仍是有效的 SQL** 

**数据改变，并且事件是无效的 SQL**

### 10.7.2 使用非事务型表

如果一切正常，基于语句的复制通常能够很好地处理非事务型表。但是当对非事务型表的更新发生错误时，例如查询在完成前被 kill，就可能导致主库和备库的数据不一致。

例如，假设更新一个 MyISAM表的100行数据，若查询更新到了其中50条时有人kill该查询，会发生什么呢?一半的数据改变了，而另一半则没有，结果是复制必然不同步，因为该查询会在备库重放并更新完100行数据（MySQL随后会在主库上发现查询引起的错误，而备库上则没有报错，此后复制将会发生错误并中断）。 

如果使用的是 MyISAM表，在关闭MySQL之前需要确保已经运行了STOPSLAVE，否则服务器在关闭时会kill所有正在运行的查询（包括没有完成的更新）。事务型存储引擎则没有这个问题。如果使用的是事务型表，失败的更新会在主库上回滚并且不会记录到二进制日志中。

### 10.7.3 混合事务型和非事务型表 

如果使用的是事务型存储引擎，只有在事务提交后才会将查询记录到二进制日志中。因此如果事务回滚，MySQL 就不会记录这条查询，也就不会在备库上重放。

但是如果混合使用事务型和非事务型表，并且发生了一次回滚，MySQL能够回滚事务型表的更新，但非事务型表则被永久地更新了。只要不发生类似查询中途被kill这样的错误，这就不是问题∶MySQL此时会记录该查询并记录一条 ROLLBACK语句到日志中。结果是同样的语句也在备库执行，所有的都很正常。这样效率会低一点，因为备库需要做一些工作并且最后再把它们丢弃掉。但理论上能够保证主备的数据一致。 

目前看来一切很正常。但是如果备库发生死锁而主库没有也可能会导致问题。事务型表的更新会被回滚，而非事务型表则无法回滚，此时备库和主库的数据是不一致的。

防止该问题的唯一办法是避免混合使用事务型和非事务型表。如果遇到这个问题，唯一的解决办法是忽略错误，并重新同步相关的表。

基于行的复制不会受这个问题的影响。因为它记录的是数据的更改，而不是SQL语句。如果一条语句改变了一个 MyISAM表和一个InnoDB表的某些行，然后主库上发生了一次死锁，InnoDB表的更新会被回滚，而 MyISAM表的更新仍会被记录到日志中并在备库重放。

### 10.7.4 不确定语句

当使用基于语句的复制模式时，如果通过不确定的方式更改数据可能会导致主备不一致。例如，一条带 LIMTT的 UPDATE语句更改的数据取决于查找行的顺序，除非能保证主库和备库上的顺序相同。例如，若行根据主键排序，一条查询可能在主库和备库上更新不同的行，这些问题非常微妙并且很难注意到。所以一些人禁止对那些会更新数据的语句使用LIMIT。另外一种不确定的行为是在一个拥有多个唯一索引的表上使用REPLACE或者 INSERT IGNORE 语句——MySQL 在主库和备库上可能会选择不同的索引。

### 10.7.5 主库和备库使用不同的存储引擎 

正如本章之前提到的，在备库上使用不同的存储引擎，有时候可以带来好处。但是在一些场景下，当使用基于语句的复制方式时，如果备库使用了不同的存储引擎，则可能造成一条查询在主库和备库上的执行结果不同，例如不确定语句（如前一小节提到的）在主备库使用不同的存储引擎时更容易导致问题。

如果发现主库和备库的某些表已经不同步，除了检查更新这些表的查询外，还需要检查两台服务器上使用的存储引擎是否相同。

### 10.7.6 备库发生数据改变 

基于语句的复制方式前提是确保备库上有和主库相同的数据，因此不应该允许对备库数据的任何更改（比较好的办法是设置 read_only选项）。假设有如下语句 ∶

```
mysql> INSERT INTO table1 SELECT * FROW table2;
```

如果备库上 table2的数据和主库上不同，该语句会导致 tablel的数据也会不一致。换句话说，数据不一致可能会在表之间传播。不仅仅是 INSERT....SELECT查询，所有类型的查询都可能发生。有两种可能的结果∶备库上发生重复索引键冲突错误或者根本不提示任何错误。如果能报告错误还好，起码能够提示你主备数据已经不一致。无法察觉的不一致可能会悄无声息地导致各种严重的问题。

唯一的解决办法就是重新从主库同步数据。

### 10.7.7 不唯一的服务器ID 

### 10.7.8 未定义的服务器ID 

### 10.7.9 对未复制数据的依赖性 

如果在主库上有备库不存在的数据库或表，复制会很容易意外中断，反之亦然。假设主库上有一个备库不存在的数据库，命名为 scratch。如果在主库上发生对该数据库中表的更新，备库会在尝试重放这些更新时中断。同样的，如果在主库上创建一个备库上已存在的表，复制也可能中断。

没有什么好的解决办法，唯一的办法就是避免在主库上创建备库上没有的表。

### 10.7.10 丢失的临时表 

### 10.7.11 不复制所有的更新

### 10.7.12 InnoDB加锁读引起的锁争用

### 10.7.13 在主-主复制结构中写入两台主库

### 10.7.14 过大的复制延迟 

复制延迟是一个很普遍的问题。不管怎么样，最好在设计应用程序时能够让其容忍备库出现延迟。如果系统在备库出现延迟时就无法很好地工作，那么应用程序也许就不应该用到复制。但是也有一些办法可以让备库跟上主库。

MySQL单线程复制的设计导致备库的效率相当低下。即使备库有很多磁盘、CPU或者内存，也会很容易落后于主库。因为备库的单线程通常只会有效地使用一个CPU和磁盘。而事实上，备库通常都会和主库使用相同配置的机器。

备库上的锁同样也是问题。其他在备库运行的查询可能会阻塞住复制线程。因为复制是单线程的，复制线程在等待时将无法做别的事情。

复制一般有两种产生延迟的方式∶突然产生延迟然后再跟上，或者稳定的延迟增大。前一种通常是由于一条运行很长时间的查询导致的，而后者即使在没有长时间运行的查询时也会出现。

解决办法

**不要重复写操作中代价较高的部分**

重构应用程序并且/或者优化查询通常是最好的保持备库同步的办法。尝试去最小化系统中重复的工作。任何主库上昂贵的写操作都会在每一个备库上重放。如果可以把工作转移到备库，那么就只有一台备库需要执行，然后我们可以把写的结果回传到主库

**在复制之外并行写入**

另一种避免备库严重延迟的办法是绕过复制。任何在主库的写入操作必须在备库串行化。因此有理由认为"串行化写入"不能充分利用资源。所有写操作都应该从主库传递到备库吗?如何把备库有限的串行写入容量留给那些真正需要通过复制进行的写入?

这种考虑有助于对写入进行区分。特别是，如果能确定一些写入可以轻易地在复制之外执行，就可以并行化这些操作以利用备库的写入容量。 

一个很好的例子是之前讨论过的数据归档。OLTP 归档需求通常是简单的单行操作。如果只是把不需要的记录从一个表移到另一个表，就没有必要将这些写入复制到备库。可以禁止归档查询记录到二进制日志中，然后分别在主库和备库上单独执行这些归档查询。

自己复制数据到另外一台服务器，而不是通过复制，这听起来有些疯狂，但却对一些应用有意义，特别是如果应用是某些表的唯一更新源。复制的瓶颈通常集中在小部分表上。如果能在复制之外单独处理这些表，就能够显著地加快复制。

**为复制线程预取缓存**

如果有正确的工作负载，就能通过预先将数据读入内存中，以受益于在备库上的并行 I/O所带来的好处。这种方式并不广为人知。大多数人不会使用，因为除非有正确的工作负载特性和硬件配置，否则可能没有任何用处。我们刚刚讨论过的其他几种变通方式通常是更好的选择，并且有更多的方法来应用它们。但是我们知道也有小部分应用会受益于数据预取。

有两种可行的实现方法。一种是通过程序实现，略微比备库 SQL线程提前读取中继日志并将其转换为 SELECT语句执行。这会使得服务器将数据从磁盘加载到内存中，这样当 SQL线程执行到相应的语句时，就无须从磁盘读取数据。事实上，SELECT语句可以并行地执行，所以可以加速 SQL线程的串行I/O。当一条语句正在执行时，下一条语句需要的数据也正在从磁盘加载到内存中。

如果满足下面这些条件，预取可能会有效∶

- 复制SQL线程是 I/O密集型的，但备库服务器并不是 I/O密集型的。一个完全的I/O密集型服务器不会受益于预取，因为它没有多余的磁盘性能来提供预取。
- 备库有多个硬盘驱动器，也许 8 个或者更多。
- 使用的是 InnoDB 引擎，并且工作集远不能完全加载到内存中。

一个受益于预读取的例子是随机单行 UPDATE语句，这些语句通常在主库上高并发执行。 DELETE语句也可能受益于这种方法，但 INSERT语句则不太可能会——尤其是当顺序插入时———因为前一次插入已经使索引"预热"了。

如果表上有很多索引，同样无法预取所有将要被修改的数据。UPDATE语句可能需要更新所有索引，但 SELECT语句通常只会读取主键和一个二级索引。UPDATE语句依然需要去读取其他索引的数据以进行更新。在多索引表上这种方法的效率会降低。 

### 10.7.15 来自主库的过大的包

另一个难以追踪的问题是主库的max_allowed_packet值和备库的不匹配。在这种情况下，主库可能会记录一个备库认为过大的包。当备库获取到该二进制日志事件时，可能会碰到各种各样的问题，包括无限报错和重试，或者中继日志损坏。

### 10.7.16 受限制的复制带宽 

如果使用受限的带宽进行复制，可以开启备库上的slave_compressed_protocoL选项（在 MySQL 4.0 及新版本中可用）。当备库连接主库时，会请求一个被压缩的连接——和 MySQL客户端使用的压缩连接一样。使用的压缩引擎是 zlib，我们的测试表明它能将文本类型的数据压缩到大约其原始大小的三分之一。其代价是需要额外的 CPU时间，包括在主库上压缩数据和在备库上解压数据。

如果主库和其备库间的连接是慢速连接，可能需要将分发主库和备库分布在同一地点。这样就只有一台服务器通过慢速连接和主库相连，可以减少链路上的带宽负载以及主库的 CPU负载。

### 10.7.17 磁盘空间不足 

复制有可能因为二进制日志、中继日志或临时文件将磁盘撑满。特别是在主库上执行了 LOAD DATA INFTLE查询并在备库开启了log_slave_updates选项。延迟越严重，接收到但尚未执行的中继日志会占用越多的磁盘空间。可以通过监控磁盘并设置relay_log_ space 选项来避免这个问题。

### 10.7.18 复制的局限性 

MySQL复制可能失败或者不同步，不管有没有报错，这是因为其内部的限制导致的。大量的 SQL 函数和编程实践不能被可靠地复制（本章我们已经讨论了许多这样的例子）。很难确保应用代码里不会出现这样或那样的问题，特别是应用或者团队非常庞大的时候。

另外一个问题是服务器的 Bug，虽然听起来很消极，但大多数 MySQL的主版本都存在着历史遗留的复制Bug。特别是每个主版本的第一个版本。诸如存储过程这样的新特性常常会导致更多的问题。

MySQL复制非常复杂。应用程序越复杂，你就需要越小心。但是如果学会了如何使用，复制会工作得很好。

## 10.8 复制有多快

关于复制的一个比较普遍的问题是复制到底有多快?简单来讲，它与 MySQL从主库复制事件并在备库重放的速度一样快。如果网络很慢并且二进制日志事件很大，记录二进制日志和在备库上执行的延迟可能会非常明显。如果查询需要执行很长时间而网络很快，通常可以认为查询时间占据了更多的复制时间开销。 

更完整的答案是计算每一步花费的时间，并找到应用中耗时最多的那一部分。一些读者可能只关注**主库上记录事件和将事件复制到中继日志的时间间隔**。

实验：略

结果显示大多数小查询在主库上的执行时间和备库上的执行时间间隔大多数小于0.3 毫秒。

复制过程中没有计算的部分是事件在主库上记录到二进制日志后需要多长时间传递到备库。有必要知道这一点，因为备库越快接收到日志事件越好。如果备库已经接收到了事件，它就能在主库崩溃时提供一个拷贝。

尽管我们的测量结果没有精确地显示这部分需要多长时间，但理论上非常快（例如，仅仅受限于网络速度）。MySQL二进制日志转储线程并没有通过轮询的方式从主库请求事件，而是由主库来通知备库新的事件，因为前者低效且缓慢。从主库读取一个二进制日志事件是一个阻塞型网络调用，当主库记录事件后，马上就开始发送。因此可以说，只要复制线程被唤醒并且能够通过网络传输数据，事件就会很快到达备库。 

## 10.9 MySQL 复制的高级特性

一些改进使得复制更加强健，例如，增加了多线程（并行）复制以减少当前单线程复制的瓶颈。另外，还有一些改进增加了一些高级特性，使得复制更加灵活并可控制 。

### 半同步复制

#### 异步复制

MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。

#### 全同步复制

指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

#### 半同步复制

第一个是半同步复制，基于Google多年前所做的工作。这是自MySQL5.1引入行复制后最大的改进。它可以帮助你确保备库拥有主库数据的拷贝，减少了潜在的数据丢失危险。

 半同步复制在提交过程中增加了一个延迟∶当提交事务时，在客户端接收到查询结束反馈前必须保证二进制日志已经传输到至少一台备库上。主库将事务提交到磁盘上之后会增加一些延迟。同样的，这也增加了客户端的延迟，因此其执行大量事务的速度不会比将这些事务传递给备库的速度更快。

关于半同步，有一些普遍的误解，下面是它不会去做的∶

- 在备库提示其已经收到事件前，会阻塞主库上的事务提交。事实上在主库上已经完成事务提交，只有通知客户端被延迟了。
- 直到备库执行完事务后，才不会阻塞客户端。备库在接收到事务后发送反馈而非完成事务后发送。
- 半同步不总是能够工作。如果备库一直没有回应已收到事件，会超时并转化为正常的异步复制模式。

尽管如此，这仍然是一个很好用的工具，有助于确保备库提供更好的冗余度和持久性。

在性能方面，从客户端的角度来看，增加了事务提交的延时，延时的多少取决于网络传输，数据写入和刷新到备库磁盘的时间（如果开启了配置）以及备库反馈的网络时间。听起来似乎这是累加的，但测试证明这些几乎是不重要的，也许延迟是由其他原因引起的。GiuseppeMaxia发现每次提交大约延时200微秒准2。对于小事务开销可能会比较明显，这也是预期中的。

事实上半同步复制在某些场景下确实能够提供足够的灵活性以改善性能，在主库关闭 sync_binlog的情况下保证更加安全。写入远程的内存（一台备库反馈）比写入本地的磁盘（写入并刷新）要更快。Henrik Ingo运行了一些性能测试表明，使用半同步复制相比在主库上进行强持久化的性能有两倍的改善年2。在任何系统上都没有绝对的持久化——只有更加高的持久化层次——并且看起来半同步复制应该是一种比其他替代方案开销更小的系统数据持久化方法。

### 复制心跳

除了半同步复制，MySQL 5.5 还提供了复制心跳，保证备库一直与主库相联系，避免悄无声息地断开连接。如果出现断开的网络连接，备库会注意到丢失的心跳数据。当使用基于行的复制时，还提供了一种改进的能力来处理主库和备库上不同的数据类型。有几个选项可以用于配置复制元数据文件是如何刷新到磁盘以及在一次崩溃后如何处理中继日志，减少了备库崩溃恢复后出现问题的概率。

除了上面提到的，这里简要地列出其他一些改进，包括MySQL以及第三方分支，例如 Percona Server 以及 MariaDB ∶

1. 事务复制状态，即使崩溃也不会导致元数据失去同步（Percona Server和 MariaDB 已经以别的形式实现了）。
2. 二进制日志的 checksum 值，用于检测中继日志中损坏的事件。
3. 备库延迟复制，用于替代 Percona Toolkit 中的pt-slave-delay工具。
4. 允许基于行的二进制日志事件也包含在主库执行的 SQL。
5. 实现多线程复制（并行复制）。

## 10.10 总结

MySQL复制是其内建功能中的"瑞士军刀"，显著增加了MySQL的功能和可用性。事实上这也是 MySQL 这么快就如此流行的关键原因之一。

尽管复制有许多限制和风险，但大多数相对不重要或者对大多数用户而言是可以避免的。许多缺点只在一些高级特性的特殊行为中，这些特性对少数需要的人而言是有帮助的，但大多数人并不会用到。

正因为复制提供了如此重要和复杂的功能，服务器本身不提供所有其他你需要的功能，例如，配置、监控、管理和优化。第三方工具可以很好地帮助你。虽然可能有失偏颇，但我们认为最值得关注的工具一定是 Percona Tookit和Percona XtraBackup，它们能够很好地改进你对复制的使用。在使用别的工具前，建议你先检查它们的测试集合，如果没有正式的、自动化的测试集合，在将其应用到你的数据之前请认真考虑。

对于复制，应该铭记K.I.S.S注2原则。不要按照想象做事，例如，使用环形复制、黑洞表或者复制过滤，除非确实有需要。使用复制简单地去镜像一份完整的数据拷贝，包括所有的权限。在各方面保持你的主备库相同可以帮助你避免很多问题。

谈到保持主库和备库相同，这里有一个简短但很重要的列表告诉你在使用复制的时候需要做什么∶

- 使用 Percona Toolkit 中的pt-table-checksum以确定备库是主库的真实拷贝。
- 监控复制以确定其正在运行并且没有落后于主库。
- 理解复制的异步本质，并且设计你的应用以避免或容忍从备库读取脏的数据。
- 在一个复制拓扑中不要写入超过一个服务器，把备库配置为只读，并降低权限以阻止对数据的改变。
- 打开本章所讨论的那些明智并且安全的设置。

# 11.可扩展的MySQL

## 11.1 什么是可扩展性

可扩展性表明了当需要增加资源以执行更多工作时系统能够获得划算的等同提升（equal bang for thebuck）的能力。缺乏扩展能力的系统在达到收益递减的转折点后，将无法进一步增长。

容量是一个和可扩展性相关的概念。系统容量表示在一定时间内能够完成的工作量注1，但容量必须是可以有效利用的。系统的最大吞吐量并不等同于容量。大多数基准测试能够衡量一个系统的最大吞吐量，但真实的系统一般不会使用到极限。如果达到最大吞吐量，则性能会下降，并且响应时间会变得不可接受地大且非常不稳定。我们将系统的真实容量定义为在保证可接受的性能的情况下能够达到的吞吐量。这就是为什么基准测试的结果通常不应该简化为一个单独的数字。 

容量和可扩展性并不依赖于性能。以高速公路上的汽车来类比的话 ∶

- 性能是汽车的时速。
- 容量是车道数乘以最大安全时速。
- 可扩展性就是在不减慢交通的情况下，能增加更多车和车道的程度。

从较高层次看，可扩展性就是能够通过增加资源来提升容量的能力。

即使 MySQL架构是可扩展的，但应用本身也可能无法扩展，如果很难增加容量，不管原因是什么，应用都是不可扩展的。之前我们从吞吐量方面来定义容量，但同样也需要从较高的层次来看待容量问题。从有利的角度来看，容量可以简单地认为是处理负载的能力，从不同的角度来考虑负载很有帮助。

**数据量**

应用所能累积的数据量是可扩展性最普遍的挑战，特别是对于现在的许多互联网应用而言，这些应用从不删除任何数据。例如社交网站，通常从不会删除老的消息或评论。

**用户量**

即使每个用户只有少量的数据，但在累计到一定数量的用户后，数据量也会开始不成比例地增长且速度快过用户数增长。更多的用户意味着要处理更多的事务，并且事务数可能和用户数不成比例。最后，大量用户（以及更多的数据）也意味着更多复杂的查询，特别是查询跟用户关系相关时（用户间的关联数可以用 M×（M-1）来计算，这里N表示用户数）。

**用户活跃度**

不是所有的用户活跃度都相同，并且用户活跃度也不总是不变的。如果用户突然变得活跃，例如由于增加了一个吸引人的新特性，那么负载可能会明显提升。用户活跃度不仅仅指页面浏览数，即使同样的页面浏览数，如果网站的某个需要执行大量工作的部分变得流行，也可能导致更多的工作。另外，某些用户也会比其他用户更活跃∶他们可能比一般人有更多的朋友、消息和照片。

**相关数据集的大小**

如果用户间存在关系，应用可能需要在整个相关联用户群体上执行查询和计算，这比处理一个一个的用户和用户数据要复杂得多。社交网站经常会遇到由那些人气很旺的用户组或朋友很多的用户所带来的挑战。

## 11.2 扩展MySQL

如果将应用所有的数据简单地放到单个MySQL服务器实例上，则无法很好地扩展，迟早会碰到性能瓶颈。对于许多类型的应用，传统的解决方法是购买更多强悍的机器，也就是常说的"垂直扩展"或者"向上扩展"。另外一个与之相反的方法是将任务分配到多台计算机上，这通常被称为"水平扩展"或者"向外扩展"。我们将讨论如何联合使用向上扩展和向外扩展的解决方案，以及如何使用集群方案来进行扩展。最后，大部分应用还会有一些很少或者从不需要的数据，这些数据可以被清理或归档。我们将这个方案称为"向内扩展"，这么取名是为了和其他策略相匹配。

### 11.2.1 规划可扩展性

人们通常只有在无法满足增加的负载时才会考虑到可扩展性，具体表现为工作负载从 CPU 密集型变成I/O 密集型，并发查询的竞争，以及不断增大的延迟。主要原因是查询的复杂度增加或者内存中驻留着一部分不再使用的数据或者索引。你可能看到一部分类型的查询发生改变，例如大的查询或者复杂查询常常比那些小的查询更影响系统。

如果是可扩展的应用，则可以简单地增加更多的服务器来分担负载，这样就没有性能问题了。但如果不是可扩展的，你会发现自己将遭遇到无穷无尽的问题。可以通过规划可扩展性来避免这个问题。

规划可扩展性最困难的部分是估算需要承担的负载到底有多少。这个值不一定非常精确，但必须在一定的数量级范围内。如果估计过高，会浪费开发资源。但如果低估了，则难以应付可能的负载。

### 11.2.2 为扩展赢得时间 

在深入 MySQL 扩展的细节前，以下是一些可以做的准备工作∶

**优化性能**

很多时候可以通过一个简单的改动来获得明显的性能提升，例如为表建立正确的索引或从 MyISAM切换到InnoDB 存储引擎。如果遇到了性能限制，可以打开查询日志进行分析，详情请参阅第 3 章。 在修复了大多数主要的问题后，会到达一个收益递减点，这时候提升性能会变得越来越困难。每个新的优化都可能耗费更多的精力但只有很小的提升，并会使应用更加复杂。

**购买性能更强的硬件**

升级或增加服务器在某些场景下行之有效，特别是对处于软件生命周期早期的应用，购买更多的服务器或者增加内存通常是个好办法。另一个选择是尽量在一台服务器上运行应用程序。比起修改应用的设计，购买更多的硬件可能是更实际的办法，特别是时间紧急并且缺乏开发者的时候。

如果应用很小或者被设计为便于利用更多的硬件，那么购买更多的硬件应该是行之有效的办法。对于新应用这是很普遍的，因为它们通常很小或者设计合理。但对于大型的旧应用，购买更多硬件可能没什么效果，或者代价太高。服务器从1台增加到3台或许算不了什么，但从100台增加到300台就是另外一回事了——代价非常昂贵。如果是这样，花一些时间和精力来尽可能地提升现有系统的性能就很划算。

### 11.2.3 向上扩展

向上扩展（有时也称为垂直扩展）意味着购买更多性能强悍的硬件，对很多应用来说这是唯一需要做的事情。这种策略有很多好处。例如，单台服务器比多台服务器更加容易维护和开发，能显著节约开销。在单台服务器上备份和恢复应用同样很简单，因为无须关心一致性或者哪个数据集是权威的。当然，还有一些别的原因。从复杂性的成本来说，向上扩展比向外扩展更简单。

向上扩展的策略能够顶一段时间，实际很多应用是不会达到天花板的。但是如果应用变得非常庞大准6，向上扩展可能就没有办法了。

最后，向上扩展不是无限制的，即使最强大的计算机也有限制。单服务器应用通常会首先达到读限制，特别是执行复杂的读查询时。类似这样的查询在MySQL内部是单线程的，因此只能使用一个 CPU，这种情况下花钱也无法提升多少性能。即使购买最快的 CPU也仅仅会是商用 CPU的几倍速度。增加更多的 CPU或 CPU核数并不能使慢查询执行得更快。当数据变得庞大以至于无法有效缓存时，内存也会成为瓶颈，这通常表现为很高的磁盘使用率，而磁盘是现代计算机中最慢的部分。

无法使用向上扩展最明显的场景是云计算。在大多数公有云中都无法获得性能非常强的服务器，如果应用肯定会变得非常庞大，就不能选择向上扩展的方式。在第 13 章我们会深入这个话题。

### 11.2.4 向外扩展

可以把向外扩展（有时也称为横向扩展或者水平扩展）策略划分为三个部分∶复制、拆分，以及数据分片（sharding）。

最简单也最常见的向外扩展的方法是通过复制将数据分发到多个服务器上，然后将备库用于读查询。这种技术对于以读为主的应用很有效。它也有一些缺点，例如重复缓存，但如果数据规模有限这就不是问题。关于这些问题我们在前一章已经讨论得足够多，后面会继续提到。

另外一个比较常见的向外扩展方法是将工作负载分布到多个"节点"。具体如何分布工作负载是一个复杂的话题。许多大型的 MySQL应用不能自动分布负载，就算有也没有做到完全的自动化。本节我们会讨论一些可能的分布负载的方案，并探讨它们的优点和缺点。

在 MySQL架构中，一个节点（node）就是一个功能部件。如果没有规划冗余和高可用性，那么一个节点可能就是一台服务器。如果设计的是能够故障转移的冗余系统，那么一个节点通常可能是下面的某一种 ∶

- 一个主一主复制双机结构，拥有一个主动服务器和被动服务器。
- 一个主库和多个备库。
- 一个主动服务器，并使用分布式复制块设备（DRBD）作为备用服务器。
- 一个基于存储区域网络（SAN）的"集群"。

大多数情况下，一个节点内的所有服务器应该拥有相同的数据。我们倾向于把主—主复制架构作为两台服务器的主动—被动节点。

#### 1．按功能拆分

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\按功能拆分.png" style="zoom:50%;" />

#### 2．数据分片

在目前用于扩展大型 MySQL应用的方案中，数据分片半'是最通用且最成功的方法。它把数据分割成一小片，或者说一块，然后存储到不同的节点中。

数据分片在和某些类型的按功能划分联合使用时非常有用。大多数分片系统也有一些"全局的"数据不会被分片（例如城市列表或者登录数据）。全局数据一般存储在单个节点上，并且通常保存在类似 memcached 这样的缓存里。

事实上，大多数应用只会对需要的数据做分片——通常是那些将会增长得非常庞大的数据。假设正在构建的博客服务，预计会有1000万用户，这时候就无须对注册用户进行分片，因为完全可以将所有的用户（或者其中的活跃用户）放到内存中。假如用户数达到5亿，那么就可能需要对用户数据分片。用户产生的内容，例如发表的文章和评论，几乎肯定需要进行数据分片，因为这些数据非常庞大，并且还会越来越多。

大型应用可能有多个逻辑数据集，并且处理方式也可以各不相同。可以将它们存储到不同的服务器组上，但这并不是必需的。还可以以多种方式对数据进行分片，这取决于如何使用它们。下文我们会举例说明。

分片技术和大多数应用的最初设计有着显著的差异，并且很难将应用从单一数据存储转换为分片架构。如果在应用设计初期就已经预计到分片，那实现起来就容易得多。

许多一开始没有建立分片架构的应用都会碰到规模扩大的情形。例如，可以使用复制来扩展博客服务的读查询，直到它不再奏效。然后可以把服务器划分为三个部分∶用户信息、文章，以及评论。可以将这些数据放到不同的服务器上（按功能划分），也许可以使用面向服务的架构，并在应用层执行联合查询。图 11-6显示了从单台服务器到按功能划分的演变。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\单实例功能划分.png" style="zoom:50%;" />

最后，可以通过用户ID来对文章和评论进行分片，而将用户信息保留在单个节点上。如果为全局节点配置一个主一备结构并为分片节点使用主—主结构，最终的数据存储可能如图 11-7 所示。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\按片划分.png" style="zoom:50%;" />

如果事先知道应用会扩大到很大的规模，并且清楚按功能划分的局限性，就可以跳过中间步骤，直接从单个节点升级为分片数据存储。事实上，这种前瞻性可以帮你避免由于粗糙的分片方案带来的挑战。 

采用分片的应用常会有一个数据库访问抽象层，用以降低应用和分片数据存储之间通信的复杂度，但无法完全隐藏分片。因为相比数据存储，应用通常更了解跟查询相关的一 些信息。太多的抽象会导致低效率，例如查询所有的节点，可实际上需要的数据只在单一节点上。

分片数据存储看起来像是优雅的解决方案，但很难实现。那为什么要选择这个架构呢?答案很简单∶如果想扩展写容量，就必须切分数据。如果只有单台主库，那么不管有多少备库，写容量都是无法扩展的。对于上述缺点而言，数据分片是我们首选的解决方案。

#### 3.选择分区键（partitioning key）

数据分片最大的挑战是查找和获取数据∶如何查找数据取决于如何进行分片。有很多方法，其中有一些方法会比另外一些更好。

我们的目标是对那些最重要并且频繁查询的数据减少分片（记住，可扩展性法则的其中一条就是要避免不同节点间的交互）。这其中最重要的是如何为数据选择一个或多个分区键。分区键决定了每一行分配到哪一个分片中。如果知道一个对象的分区键，就可以回答如下两个问题∶

- 应该在哪里存储数据?
- 应该从哪里取到希望得到的数据?

后面将展示多个选择和使用分区键的方法。先看一个例子。假设像 MySQL NDB Cluster那样来操作，并对每个表的主键使用哈希来将数据分割到各个分片中。这是一种非常简单的实现，但可扩展性不好，因为可能需要频繁检查所有分片来获得需要的数据。例如，如果想查看user3 的博客文章，可以从哪里找到呢?由于使用主键值而非用户名进行分 割，博客文章可能均匀分散在所有的数据分片中。使用主键值哈希简化了判断数据存储在何处的操作，但却可能增加获取数据的难度，具体取决于需要什么数据以及是否知道主键。

跨多个分片的查询比单个分片上的查询性能要差，但只要不涉及太多的分片，也不会太糟糕。最糟糕的情况是不知道需要的数据存储在哪里，这时候就需要扫描所有分片。

一个好的分区键常常是数据库中一个非常重要的实体的主键。这些键值决定了分片单元。例如，如果通过用户ID或客户端 ID 来分割数据，分片单元就是用户或者客户端。 

#### 4．多个分区键

复杂的数据模型会使数据分片更加困难。许多应用拥有多个分区键，特别是存在两个或更多个"维度"的时候。

需要多个分区键并不意味着需要去设计两个完全冗余的数据存储。我们来看看另一个例子∶一个社交网站下的读书俱乐部站点，该站点的所有用户都可以对书进行评论。该网站可以显示所有书籍的所有评论，也能显示某个用户已经读过或评论过的所有书籍。

假设为用户数据和书籍数据都设计了分片数据存储。而评论同时拥有用户ID和评论 ID，这样就跨越了两个分片的边界。实际上却无须冗余存储两份评论数据，替代方案是，将评论和用户数据一起存储，然后把每个评论的标题和ID与书籍数据存储在一起。这样在渲染大多数关于某本书的评论的视图时无须同时访问用户和书籍数据存储，如果需要显示完整的评论内容，可以从用户数据存储中获得。

#### 5．跨分片查询 

大多数分片应用多少都有一些查询需要对多个分片的数据进行聚合或关联操作。例如，一个读书俱乐部网站要显示最受欢迎或最活跃的用户，就必须访问每一个分片。如何让这类查询很好地执行，是实现数据分片的架构中最困难的部分。虽然从应用的角度来看，这是一条查询，但实际上需要拆分成多条并行执行的查询，每个分片上执行一条。一个设计良好的数据库抽象层能够减轻这个问题，但类似的查询仍然会比分片内查询要慢并且更加昂贵，所以通常会更加依赖缓存。

跨分片查询也可以借助汇总表来执行。可以遍历所有分片来生成汇总表并将结果在每个分片上冗余存储。如果在每个分片上存储重复数据太过浪费，也可以把汇总表放到另外一个数据存储中，这样就只需要存储一份了。

未分片的数据通常存储在全局节点中，可以使用缓存来分担负载。

如果数据的均衡分布非常重要，或者没有很好的分区键，一些应用会采用随机分片的方式。分布式检索应用就是个很好的例子。这种场景下，跨分片查询和聚合查询非常常见。

跨分片查询并不是数据分片面临的唯一难题。维护数据一致性同样困难。外键无法在分片间工作，因此需要由应用来检查参照一致性，或者只在分片内使用外键，因为分片内的内部一致性可能是最重要的。还可以使用XA事务，但由于开销太大，现实中使用很少。 

#### 6．分配数据、分片和节点

分片和节点不一定是一对一的关系，应该尽可能地让分片的大小比节点容量小很多，这样就可以在单个节点上存储多个分片。

保持分片足够小更容易管理。这将使数据的备份和恢复更加容易，如果表很小，那么像更改表结构这样的操作会更加容易。例如，假设有一个100GB的表，你可以直接存储，也可以将其划分为100个1GB的分片，并存储在单个节点上。现在假如要向表上增加一个索引，在单个100GB的表上的执行时间会比 100个1GB分片上执行的总时间更长，因为 1GB的分片更容易全部加载到内存中。并且在执行ALTER TABLE时还会导致数据不可用，阻塞 1GB 的数据比阻塞 100GB 的数据要好得多。

小一点的分片也便于转移。这有助于重新分配容量，平衡各个节点的分片。转移分片的 、效率一般都不高。通常需要先将受影响的分片设置为只读模式（这也是需要在应用中构建的特性），提取数据，然后转移到另外一个节点。这包括使用mysqldump获取数据然后使用mysql命令将其重新导入。如果使用的是Percona Server，可以通过XtraBackup在服务器间转移文件，这比转储和重新载入要高效得多。

除了在节点间移动分片，你可能还需要考虑在分片间移动数据，并尽量不中断整个应用提供服务。如果分片太大，就很难通过移动整个分片来平衡容量，这时候可能需要将一部分数据（例如一个用户）转移到其他分片。分片间转移数据比转移分片要更复杂，应该尽量避免这么做。这也是我们建议设置分片大小尽量易于管理的原因之一。

如果将分片设置得太小，会产生太多的表，这可能引发文件系统或 MySQL内部结构的问题。另外太小的分片还会导致跨分片查询增多。 

#### 7．在节点上部署分片

需要确定如何在节点上部署数据分片。以下是一些常用的办法 ∶

-  每个分片使用单一数据库，并且数据库名要相同。典型的应用场景是需要每个分片 都能镜像到原应用的结构。这在部署多个应用实例，并且每个实例对应一个分片时很有用。
- 将多个分片的表放到一个数据库中，在每个表名上包含分片号（例如 bookclub. comments_23）。这种配置下，单个数据库可以支持多个数据分片。
- 为每个分片使用一个数据库，并在数据库中包含所有应用需要的表。在数据库名中包含分片号（例如表名可能是 bookclub_23.comments或者 bookclub_23.users等），但表名不包括分片号。当应用连接到单个数据库并且不在查询中指定数据库名时，这种做法很常见。其优点是无须为每个分片专门编写查询，也便于对只使用单个数据库的应用进行分片。
-  每个分片使用一个数据库，并在数据库名和表名中包含分片号（例如表名可以是 bookclub_23. comments_23)。
- 在每个节点上运行多个 MySQL 实例，每个实例上有一个或多个分片，可以使用上 面提到的方式的任意组合来安排分片。 

#### 8．固定分配

将数据分配到分片中有两种主要的方法∶固定分配和动态分配。两种方法都需要一个分区函数，使用行的分区键值作为输入，返回存储该行的分片。

固定分配使用的分区函数仅仅依赖于分区键的值。哈希函数和取模运算就是很好的例子。这些函数按照每个分区键的值将数据分散到一定数量的"桶"中。

假设有100个桶，你希望弄清楚用户111该放到哪个桶里。如果使用的是对数字求模的方式，答案很简单∶111对 100取模的值为 11，所以应该将其放到第11个分片中。

固定分配的主要优点是简单，开销低，甚至可以在应用中直接硬编码。

但固定分配也有如下缺点∶

- 如果分片很大并且数量不多，就很难平衡不同分片间的负载。
- 固定分片的方式无法自定义数据放到哪个分片上，这一点对于那些在分片间负载不均衡的应用来说尤其重要。一些数据可能比其他的更加活跃，如果这些热点数据都分配到同一个分片中，固定分配的方式就无法通过热点数据转移的方式来平衡负载。（如果每个分片的数据量切分得比较小，这个问题就没那么严重，根据大数定律，这样做会更容易将热点数据平均分配到不同分片。）
- 修改分片策略通常比较困难，因为需要重新分配已有的数据。例如，如果通过模10的哈希函数来进行分片，就会有10个分片。如果应用增长使得分片变大，如果要拆分成 20个分片，就需要对所有数据重新哈希，这会导致更新大量数据，并在分片间转移数据。

#### 9．动态分配

另外一个选择是使用动态分配，将每个数据单元映射到一个分片。假设一个有两列的表，包括用户ID和分片ID。

```sql
CREATE TABLE user_to_shard (
    user_id INT NOT NULL, 
    shard_id INT NOT NULl, 
    PRIMARY KEY(user_id)
);
```

这个表本身就是分区函数。给定分区键（用户ID）的值就可以获得分片号。如果该行不存在，就从目标分片中找到并将其加入到表中。也可以推迟更新——这就是动态分配的含义。

动态分配增加了分区函数的开销，因为需要额外调用一次外部资源，例如目录服务器（存储映射关系的数据存储节点）。出于效率方面的考虑，这种架构常常需要更多的分层。例如，可以使用一个分布式缓存系统将目录服务器的数据加载到内存中，因为这些数据平时改动很小。或者更普遍地，你可以直接向 USERS表中增加一个shard_id列用于存储分片号。

动态分配的最大好处是可以对数据存储位置做细粒度的控制。这使得均衡分配数据到分片更加容易，并可提供适应未知改变的灵活性。 

动态映射可以在简单的键一分片（key-to-shard）映射的基础上建立多层次的分片策略。例如，可以建立一个双重映射，将每个分片单元指定到一个分组中（例如，读书俱乐部的用户组），然后尽可能将这些组保持在同一个分片中。这样可以利用分片亲和性，避免跨分片查询。

如果使用动态分配策略，可以生成不均衡的分片。如果服务器能力不相同，或者希望将其中一些分片用于特定目的（例如归档数据），这可能会有用。如果能够做到随时重新平衡分片，也可以为分片和节点间维持一一对应的映射关系，这不会浪费容量。也有些人喜欢简单的每个节点一个分片的方式。（但是请记住，保持分片尽可能小是有好处的。）

动态分配以及灵活地利用分片亲和性有助于减轻规模扩大而带来的跨分片查询问题。假设一个跨分片查询涉及四个节点，当使用固定分配时，任何给定的查询可能需要访问所有分片，但动态分配策略则可能只需要在其中的三个节点上运行同样的查询。这看起来没什么大区别，但考虑一下当数据存储增加到 400个分片时会发生什么?固定分配策略需要访问 400 个分片，而动态分配方式依然只需要访问 3 个。

#### 10．显式分配

第三种分配策略是在应用插入新的数据行时，显式地选择目标分片。这种策略在已有的数据上很难做到。所以在为应用增加分片时很少使用。但在某些情况下还是有用的。

#### 11.重新均衡分片数据 

如有必要，可以通过在分片间移动数据来达到负载均衡。举个例子，许多读者可能听一些大型图片分享网站或流行社区网站的开发者提到过用于分片间移动用户数据的工具。 

在分片间移动数据的好处很明显。例如，当需要升级硬件时，可以将用户数据从旧分片转移到新分片上，而无须暂停整个分片的服务或将其设置为只读。

然而，我们也应该尽量避免重新均衡分片数据，因为这可能会影响用户使用。在分片间转移数据也使得为应用增加新特性更加困难，因为新特性可能还需要包含针对重新均衡脚本的升级。如果分片足够小，就无须这么做;也可以经常移动整个分片来重新均衡负载，这比移动分片中的部分数据要容易得多（并且以每行数据开销来衡量的话，更有效率）。

一个较好的策略是使用动态分片策略，并将新数据随机分配到分片中。当一个分片快满时，可以设置一个标志位，告诉应用不要再往这里放数据了。如果未来需要向分片中放入更多数据，可以直接把标记位清除。

#### 12．生成全局唯一ID(参考分布式ID、雪花模型)

分布式ID企业解决方案见分布式文档

当希望把一个现有系统转换为分片数据存储时，经常会需要在多台机器上生成全局唯一 ID。单一数据存储时通常可以使用 AUTO_INCREMENT列来获取唯一ID。但涉及多台服务器时就不凑效了。以下几种方法可以解决这个问题 ∶

**使用 auto increment increment和 auto increment offset**

这两个服务器变量可以让 MySQL以期望的值和偏移量来增加 AUTO_INCREMENT列的值。举一个最简单的场景，只有两台服务器，可以配置这两台服务器自增幅度为2，其中一台的偏移量设置为1，另外一台为2（两个都不可以设置为0）。这样一台服务器总是包含偶数，另外一台则总是包含奇数。这种设置可以配置到服务器的每一个表里。

这种方法简单，并且不依赖于某个节点，因此是生成唯一ID 的比较普遍的方法。但这需要非常仔细地配置服务器。很容易因为配置错误生成重复数字，特别是当增加服务器需要改变其角色，或进行灾难恢复时。 

**全局节点中创建表**

在一个全局数据库节点中创建一个包含 AUTO_INCREMENT列的表，应用可以通过这个表来生成唯一数字。

**使用 memcached**

在memcached的 API中有一个incr（）函数，可以自动增长一个数字并返回结果。 另外也可以使用 Redis。

**批量分配数字**

应用可以从一个全局节点中请求一批数字，用完后再申请。

**使用复合值**

可以使用一个复合值来做唯一ID，例如分片号和自增数的组合。

**使用 GUID 值**

可以使用 UUID（）函数来生成全局唯一值。注意，尽管这个函数在基于语句的复制时不能正确复制，但可以先获得这个值，再存放到应用的内存中，然后作为数字在查询中使用。GUID的值很大并且不连续，因此不适合做InnoDB表的主键。具体参考"和 InnoDB主键一致地插入行"。在5.1及更新的版本中还有一个函数UUID_SHORT（），能够生成连续的值，并使用 64 位代替了之前的 128 位。

#### 13．分片工具

在设计数据分片应用时，首先要做的事情是编写能够查询多个数据源的代码。

如果没有任何抽象层，直接让应用访问多个数据源，那绝对是一个很差的设计，因为这会增加大量的编码复杂性。最好的办法是将数据源隐藏在抽象层中。这个抽象层主要完成以下任务∶

- 连接到正确的分片并执行查询。
- 分布式一致性校验。
- 跨分片结果集聚合。
- 跨分片关联操作。
- 锁和事务管理。
- 创建新的数据分片（或者至少在运行时找到新分片）并重新平衡分片（如果有时间实现）。

你可能不需要从头开始构建分片结构。有一些工具和系统可以提供一些必要的功能或专门设计用来实现分片架构。

##### 13.1 Hibernate Shards

Hibernate Shards（http∶/shards.hibernate.org）是一个支持分片的数据库抽象层，基于 Java 语言的开源的 Hibernate ORM库扩展，由谷歌提供。它在 Hibernate Core 接口上提供了分片感知功能，所以应用无须专门为分片设计;事实上，应用甚至无须知道它正在使用分片。Hibernate Shards 通过固定分配策略向分片分配数据。另外一个基于Java 的分片系统是 HiveDB （http∶//www.hivedb.org）。

##### 13.2 mycat大型数据库集群、分片中间件

### 11.2.5 通过多实例扩展

一个分片较多的架构可能会更有效地利用硬件。我们的研究和经验表明 MySQL并不能完全发挥现代硬件的性能。当扩展到超过24个CPU核心时，MySQL的性能开始趋于平缓，不再上升。当内存超过 128GB时也同样如此，MySQL甚至不能完全发挥诸如 Virident 或 Fusion-io 卡这样的高端 PCIe flash 设备的 I/O 性能。

不要在一台性能强悍的服务器上只运行一个服务器实例，我们还有别的选择。你可以让数据分片足够小，以使每台机器上都能放置多个分片（这也是我们一直提倡的），每台服务器上运行多个实例，然后划分服务器的硬件资源，将其分配给每个实例。

这样做尽管比较烦琐，但确实有效。这是一种向上扩展和向外扩展的组合方案。也可以用其他方法来实现——不一定需要分片——但分片对于在大型服务器上的联合扩展具有天然的适应性。 

一些人倾向于通过虚拟化技术来实现合并扩展，这有它的好处。但虚拟化技术本身有很大的性能损耗。具体损耗多少取决于具体的技术，但通常都比较明显，尤其是 I/O 非常快的时候损耗会非常惊人。另一种选择是运行多个MySQL实例，每个实例监听不同的网络端口，或绑定到不同的 IP 地址。

### 11.2.6 通过集群扩展

理想的扩展方案是单一逻辑数据库能够存储尽可能多的数据，处理尽可能多的查询，并如期望的那样增长。许多人的第一想法就是建立一个"集群"或者"网格"来无缝处理这些事情，这样应用就无须去做太多工作，也不需要知道数据到底存在哪台服务器上。随着云计算的流行，自动扩展——根据负载或数据大小变化动态地在集群中增加/移除服务器——变得越来越有趣。

许多关系型数据库集群的高性能设计正在被构建到系统的更低层，在NoSQL数据库中，特别是使用键—值存储时，这一点很明显。例如 NDB Cluster 并不是一个 SQL数据库;它是一个可扩展的数据库，使用其原生 API来控制，通常是使用NoSQL，但也可以通过在前端使用 MySQL存储引擎来支持SQL。它是一个完全分布式、非共享高性能、自动分片并且不存在单点故障的事务型数据库服务器。最近几年正变得更强大、更复杂，用途也更广泛。同时，NoSQL数据库也逐渐看起来越来越像关系型数据库。有些甚至还开发了类 SQL查询语言。未来典型的集群数据库可能更像是 SQL和NoSQL的混合体，有多种存取机制来满足不同的使用需求。所以，我们在从 NoSQL 中汲取优点，但 SQL 仍然会保留在集群数据库中。 

和 MySQL结合在一起的集群或分布式数据库技术大致包括∶NDB Cluster、Clustrix、Percona XtraDB Cluster、Galera、Schooner Active Cluster、 Continuent Tungsten、ScaleBase、ScaleArc、dbShards、Xeround、Akiban、VoltDB,以及 GenieDB。这些或多或少以MySQL为基础，或通过MySQL进行控制，或是和 MySQL相关。

在开始前，需要指出，可扩展性、高可用性、事务性等是数据库系统的不同特性。许多人会感到困惑并将这些当作是相同的东西，但事实上不是。本章我们主要集中讨论可扩展性。但事实上，可扩展的数据库并不一定非常优秀，除非它能保证高性能，谁愿意牺牲高可用性来进行扩展呢?这些特性的组合堪称数据库的必杀技，但这很难实现。当然这不是本章要讨论的内容。 

最后，除 NDB Cluster外，大多数 NewSQL 集群产品都是比较新的事物。 

#### 1.MySQL Cluster(NDB Cluster)

MySQL Cluster是两项技术的结合∶NDB数据库，以及作为SQL前端的MySQL存储引擎。 NDB 是一个分布式、具备容错性、非共享的数据库，提供同步复制以及节点间的数据自动分片。NDB Cluset存储引擎将SQL转换为NDBAPI调用，但遇到NDB不支持的操作时，就会在 MySQL服务器上执行（NDB是一个键—值数据存储，无法执行类似联接或聚合的复杂操作）。

NDB是一个非常复杂的数据库，和 MySQL几乎完全不同。在使用 NDB时甚至可以不需要 MySQL∶你可以把它作为一个独立的键—值数据库服务器。它的亮点包括非常高的写入和按键查询吞吐量。NDB可以基于键的哈希自动决定哪个节点应该存储给定的数据。当通过 MySQL 来控制 NDB 时，行的主键就是键，其他的列是值。

因为它基于一些新的技术，并且集群具有容错性和分布式特性，所以管理NDB需要非常专业和特殊的技能。有许多动态变化的部分，还有类似升级集群或增加节点的操作必须正确执行以防止意外的问题。NDB是一项开源技术。

#### 2.Clustrix

Clustrix（http∶/www.clustrix.com）是一个分布式数据库，支持MySQL协议，所以它可以直接替代 MySQL。除了协议外，它是一个全新的技术，并非建立在MySQL的基础之上。它是一个完全支持 ACID，支持 MVCC的事务型SQL数据库，主要用于OLTP 负载场景。 Clustrix 在节点间进行数据分片以满足容错性，并对查询进行分发，在节点上并发执行，而不是将所有节点上取得的数据集中起来执行。集群可以在线扩展节点来处理更多的数据或负载。在某些方面 Clustrix和 MySQL Cluster很像;关键的不同点是，Clustrix是完全分布式执行并且缺少顶层的"代理"或者集群前端的查询协调器（query coordinator）。 Clustrix本身能够理解 MySQL协议，所以无须MySQL来进行协议转换。相比较而言， MySQLcluster是由三个部分组成的∶MySQL，NDB集群存储引擎，以及 NDB。

#### 3.ScaleBase 

ScaleBase（http∶/www.scalebase.com）是一个软件代理，处于应用和多个后端MySQL服务器之间。它会把发起的查询进行分裂，并将其分发到后端服务器并发执行，然后汇集结果返回给应用。

### 11.2.7 向内扩展

处理不断增长的数据和负载最简单的办法是对不再需要的数据进行归档和清理。这种操作可能会带来显著的成效，具体取决于工作负载和数据特性。这种做法并不用来代替其他策略，但可以作为争取时间的短期策略，也可以作为处理大数据量的长期计划之一。

在设计归档和清理策略时需要考虑到如下几点。

**对应用的影响**

一个设计良好的归档系统能够在不影响事务处理的情况下，从一个高负载的 OLTP服务器上移除数据。这里的关键是能高效地找到要删除的行，然后一小块一小块地移除。通常需要平衡一次归档的行数和事务的大小，以找到一个锁竞争和事务负载量的平衡。还需要设计归档任务在必要的时候让步于事务处理。

**要归档的行**

当知道某些数据不再使用后，就可以立刻清理或归档它们。也可以设计应用去归档那些几乎不怎么使用的数据。可以把归档的数据置于核心表附近，通过视图来访问，或完全转移到别的服务器上。

**维护数据一致性**

当数据间存在联系时，会导致归档和清理工作更加复杂。一个设计良好的归档任务能够保证数据的逻辑一致性，或至少在应用需要时能够保证一致，而无须在大量事务中包含多个表。

当表之间存在关系时，哪个表首先归档是个问题。在归档时需要考虑孤立行的影响。可以选择违背外键约束（可以通过执行 SET FOREIGN KEY_CHECKS=0禁止InnoDB的外键约束）或暂时把"悬空指针"（dangling pointer）记录放到一边。如果应用层认为这些相关联的表具有层次关系，那么归档的顺序也应该和它一样。例如，如果应用总是先检查订单再检查发货单，就先归档订单。应用应该看不到孤立的发货单，因此接下来就可以将发货单归档。

**避免数据丢失**

如果是在服务器间归档，归档期间可能就无法做分布式事务处理，也有可能将数据归档到 MyISAM或其他非事务型的存储引擎中。因此，为了避免数据丢失，在从源表中删除时，要保证已经在目标机器上保存。将归档数据单独写到一个文件里也是个好主意。可以将归档任务设计为能够随时关闭或重启，并且不会引起不一致或索引冲突之类的错误。

**解除归档（unarchiving）**

可以通过一些解除归档策略来减少归档的数据量。它可以帮助你归档那些不确定是否需要的数据，并在以后可以通过选项进行回退。如果可以设置一些检查点让系统来检查是否有需要归档的数据，那么这应该是一个很容易实现的策略。例如，要对不活跃的用户进行归档，检查点就可以设置在登录验证时。如果因为用户不存在导致登录失败，可以去检查归档数据中是否存在该用户，如果有，则从中取出来并完成登录。

**保持活跃数据独立**

即使并不真的把老数据转移到别的服务器，许多应用也能受益于活跃数据和非活跃数据的隔离。这有助于高效利用缓存，并为活跃和不活跃的数据使用不同的硬件或应用架构。下面列举了几种做法∶

**1.将表划分为几个部分**

分表是一种比较明智的办法，特别是整张表无法完全加载到内存时。例如，可以把users表划分为active_users和inactive_users表。你可能认为这并不需要，因为数据库本身只缓存"热"数据，但事实上这取决于存储引擎。如果用的是 InnoDB，每次缓存一页，而一页能存储 100个用户，但只有10%是活跃的，那么这时候InnoDB可能认为所有的页都是"热"的——因此每个"热"页的90%将被浪费掉。将其拆成两个表可以明显改善内存利用率。

**2.MySQL 分区**

分区的功能能够帮助把最近的数据留在内存中。

**3.基于时间的数据分区**

如果应用不断有新数据进来，一般新数据总是比旧数据更加活跃。例如，我们知道博客服务的流量大多是最近七天发表的文章和评论。更新的大部分是相同的数据集。因此这些数据被完整地保留在内存中，使用复制来保证在主库失效时有一份可用的备份。其他数据则完全可以放到别的地方去。

我们也看到过这样一种设计，在两个节点的分片上存储用户数据。新数据总是进入"活跃"节点，该节点使用更大的内存和快速硬盘，另外一个节点存储旧数据，使用 非常大（但比较慢）的硬盘。应用假设不太会需要旧数据。对于很多应用而言这是合理的假设，依靠 10% 的最新数据能够满足 90% 或更多的请求。 

## 11.3 负载均衡

负载均衡的基本思路很简单∶在一个服务器集群中尽可能地平均负载量。通常的做法是在服务器前端设置一个负载均衡器（一般是专门的硬件设备）。然后负载均衡器将请求 .的连接路由到最空闲的可用服务器。图11-9显示了一个典型的大型网站负载均衡设置，其中一个负载均衡器用于HTTP 流量，另一个用于 MySQL 访问。

负载均衡有五个常见目的。

**可扩展性**

 负载均衡对某些扩展策略有所帮助，例如读写分离时从备库读数据。

**高效性**

负载均衡有助于更有效地使用资源，因为它能够控制请求被路由到何处。如果服务器处理能力各不相同，这就尤为重要∶你可以把更多的工作分配给性能更好的机器。

**可用性**

一个灵活的负载均衡解决方案能够使用时刻保持可用的服务器。

**透明性**

客户端无须知道是否存在负载均衡设置，也不需要关心在负载均衡器的背后有多少机器，它们的名字是什么。负载均衡器给客户端看到的只是一个虚拟的服务器。

**一致性**

如果应用是有状态的（数据库事务，网站会话等），那么负载均衡器就应将相关的查询指向同一个服务器，以防止状态丢失。应用无须去跟踪到底连接的是哪个服务器。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\读密集型网络负载均衡.png" style="zoom:50%;" />

在与 MySQL相关的领域里，负载均衡架构通常和数据分片及复制紧密相关。你可以把负载均衡和高可用性结合在一起，部署到应用的任一层次上。例如，可以在 MySQL Cluster 集群的多个SQL节点上做负载均衡，也可以在多个数据中心间做负载均衡，其中每个数据中心又可以使用数据分片架构，每个节点实际上是拥有多个备库的主—主复制对结构，这里又可以做负载均衡。对于高可用性策略也同样如此∶在一个架构里可以配置多层的故障转移机制。

负载均衡有许多微妙之处，举个例子，其中一个挑战就是管理读/写策略。有些负载均衡技术本身能够实现这一点，但其他的则需要应用自己知道哪些节点是可读的或可写的。 

### 11.3.1 如何实现负载均衡

在决定如何实现负载均衡时，应该考虑到这些因素。有许多负载均衡解决方案可以使用，从诸如 Wackamole（http∶/wwwbackhand.org/wackamole/）这样基于端点的（peer-based）实现，到 DNS、LVS（Linux Virtual Server，http∶/www.linuvirtualserver.org）、硬件负载均衡器、TCP 代理、MySQLProxy，以及在应用中管理负载均衡。在我们的客户中，最普遍的策略是使用硬件负载均衡器，大多是使用HAProxy（http/ haproxy.1wt.eu），它看起来很流行并且工作得很好。还有一些人使用TCP代理，例如 Pen （http∶/siag.nu/pen/）。但 MySQL Proxy 用得并不多。

### 11.3.2 直接连接

有些人认为负载均衡就是配置在应用和MySQL服务器之间的东西。但这并不是唯一的负载均衡方法。你可以在保持应用和MySQL连接的情况下使用负载均衡。事实上，集中化的负载均衡系统只有在存在一个对等置换的服务器池时才能很好工作。如果应用需要做一些决策，例如在备库上执行读操作是否安全，就需要直接连接到服务器。

除了可能出现的一些特定逻辑，应用为负载均衡做决策是非常高效的。例如，如果有两个完全相同的备库，你可以使用其中的一个来处理特定分片的数据查询，另一个处理其他的查询。这样能够有效利用备库的内存，因为每个备库只会缓存一部分数据。如果其中一个备库失效，另外一个备库拥有所有的数据，仍然能提供服务。

一下一些应用直连的常见方法，以及在评估每一个选项时的注意点。 

#### 1.复制上的读/写分离

MySQL复制产生了多个数据副本，你可以选择在备库还是主库上执行查询。由于备库复制是异步的，因此主要的难点是如何处理备库上的脏数据。应该将备库用作只读的，而主库可以同时处理读和写查询。

通常需要修改应用以适应这种分离需求。然后应用就可以使用主库来进行写操作，并将读操作分配到主库和备库上;如果不太关心数据是否是脏的，可以使用备库，而对需要即时数据的请求使用主库。我们将这称为读/写分离。

如果使用的是主动—被动模式的主一主复制对，同样也要考虑这个问题。使用这种配置时，只有主动服务器接受写操作。如果能够接受读到脏数据，可以将读分配给被动服务器。

最大的问题是如何避免由于读了脏数据引起的奇怪问题。一个典型的例子是当一个用户做了某些修改，例如增加了一条博客文章的评论，然后重新加载页面，但并没有看到更新，因为应用从备库读取到了脏的数据。

比较常见的读 / 写分离方法如下∶

**基于查询分离**

最简单的分离方法是将所有不能容忍脏数据的读和写查询分配到主动或主库服务器上。其他的读查询分配到备库或被动服务器上。该策略很容易实现，但事实上无法有效地使用备库，因为只有很少的查询能容忍脏数据。

**基于脏数据分离**

这是对基于查询分离方法的小改进。需要做一些额外的工作，让应用检查复制延迟，以确定备库数据是否太旧。许多报表类应用都使用这个策略∶只需要晚上加载的数据复制到备库即可，它们并不关心是不是100% 跟上了主库。

**基于会话分离**

另一个决定能否从备库读数据的稍微复杂一点的方法是判读用户自己是否修改了数据。用户不需要看到其他用户的最新数据，但需要看到自己的更新。

**基于版本分离**

这和基于会话的分离方法相似∶你可以跟踪对象的版本号以及/或者时间戳，通过从备库读取对象的版本或时间戳来判断数据是否足够新。如果备库的数据太旧，可以从主库获取最新的数据。

**基于全局版本/ 会话分离**

这个办法是基于版本分离和基于会话分离的变种。当应用执行写操作时，在提交事务后，执行一次 SHOW MASTER STATUS操作。然后在缓存中存储主库日志坐标，作为被修改对象以及/或者会话的版本号。当应用连接到备库时，执行 SHOW SLAVE STATUS并将备库上的坐标和缓存中的版本号相对比。如果备库相比记录点更新，就可以安全地读取备库数据。

#### 2．修改应用的配置 

还有一个分发负载的方法是重新配置应用。例如，你可以配置多个机器来分担生成大报表操作的负载。每台机器可以配置成连接到不同的 MySQL备库，并为第N个用户或网站生成报表。

这样的系统很容易实现，但如果需要修改一些代码——包括配置文件修改——会变得脆弱且难以处理。硬编码有着固有的限制，需要在每台服务器上修改硬编码，或者在一个中心服务器上修改，然后通过文件副本或代码控制更新命令"发布"到其他服务器上。如果将配置存储在服务器或缓存中，就可以避免这些麻烦。

#### 3. 修改 DNS 名

这是一个比较粗糙的负载均衡技术，但对于一些简单的应用，为不同的目的创建 DNS还是很实用的。你可以为不同的服务器指定一个合适的名字。最简单的方法是只读服务器拥有一个 DNS名，而给负责写操作的服务器起另外一个DNS名。如果备库能够跟上主库，那就把只读 DNS名指定给备库，当出现延迟时，再将该DNS名指定给主库。

这种DNS技术非常容易实现，但也有很多缺点。最大的问题是无法完全控制DNS。

- 修改 DNS并不是立刻生效的，也不是原子的。将DNS的变化传递到整个网络或在 网络间传播都需要比较长的时间。
- DNS 数据会在各个地方缓存下来，它的过期时间是建议性质的，而非强制的。
- 可能需要应用或服务器重启才能使修改后的 DNS 完全生效。
-  多个IP地址共用一个DNS名并依赖于轮询行为来均衡请求，这并不是一个好主意。因为轮询行为并不总是可预知的。
-  DBA 可能没有权限直接访问 DNS。

除非应用非常简单，否则依赖于不受控制的系统会非常危险。你可以通过修改/etc/hosts文件而非DNS来改善对系统的控制。当发布一个对该文件的更新时，会知道该变更已经生效。这比等待缓存的 DNS 失效要好得多。但这仍然不是理想的办法。

我们通常建议人们构建一个完全不依赖DNS的应用。即使应用很简单也适用，因为你无法预知应用会增长到多大规模。

#### 4．转移IP地址 

一些负载均衡解决方案依赖于在服务器间转移虚拟地址，一般能够很好地工作。这听起来和修改 DNS 很像，但完全是两码事。服务器不会根据 DNS 名去监听网络流量，而是根据指定的IP地址去监听流量，所以转移IP 地址允许 DNS名保持不变。你可以通过 ARP（地址解析协议）命令强制使 IP 地址的更改快速而且原子性地通知到网络上。

我们看过的使用最普遍的技术是 Pacemaker，这是Linux-HA项目的Heartbeat 工具的继承者。你可以使用单个IP地址，为其分配一个角色，例如read-only，当需要在机器间转移IP 地址时，它能够感知到。**其他类似的工具包括LVS 和 Wackamole。** 

一个比较方便的技术是为每个物理服务器分配一个固定的IP 地址。该IP 地址固定在服务器上，不再改变。然后可以为每个逻辑上的"服务"使用一个虚拟IP地址。它们能够很方便地在服务器间转移，这使得转移服务和应用实例无须再重新配置应用，因此更加容易。即使不怎么经常转移 IP 地址，这也是一个很好的特性。

**虚拟IP地址不是直接连接到任何特定的计算机或网络端口，而是"漂浮"在计算机之间。** 

### 11.3.3 引入中间件

迄今为止，我们所讨论的方案都假定应用跟 MySQL服务器是直接相连的。但是许多负载均衡解决方案都会引入一个中间件，作为网络通信的代理。它一边接受所有的通信请求，另一边将这些请求派发到指定的服务器上，然后把执行结果发送回请求的机器上。中间件可以是硬件设备或是软件注1。图11-10描述了这种架构。**这种解决方案通常能工作得很好，当然除非为负载均衡器本身增加冗余，这样才能避免单点故障引起的整个系统瘫痪。**从开源软件，如HAProxy，到许多广为人知的商业系统，有许多负载均衡器得到了成功的应用。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\中间件负载均衡.png)

#### 1．负载均衡器 

市场上有许多负载均衡硬件和软件，但很少有专门为 MySQL服务器设计的。Wel服务器通常更需要负载均衡，因此许多多用途的负载均衡设备都会支持HTTP，而对其他用途则只有一些很少的基本特性。MySQL连接都只是正常的TCP/IP连接，所以可以在 MySQL上使用多用途负载均衡器。但由于缺少MySQL专有的特性，因此会多一些限制。

- 除非负载均衡器知道 MySQL的真实负载，否则在分发请求时可能无法做到很好的负载均衡。不是所有的请求都是等同的，但多用途负载均衡器通常对所有的请求一视同仁。
- 许多负载均衡器知道如何检查一个HTTP请求并把会话"固定"到一个服务器上以保护在 Web服务器上的会话状态。MySQL连接也是有状态的，但负载均衡器可能并不知道如何把所有从单个HTTP会话发送的连接请求"固定"到一个 MySQL服务器上。这会损失一部分效率。（如果单个会话的请求都是发到同一个 MySQL服务器，服务器的缓存会更有效率。）
- 连接池和长连接可能会阻碍负载均衡器分发连接请求。例如，假如一个连接池打开了预先配置好的连接数，负载均衡器在已有的四个MySQL服务器上分发这些连接。现在增加了两个以上的 MySQL服务器。由于连接池不会请求新连接，因而新的服务器会一直空闲着。池中的连接会在服务器间不公平地分配负载，导致一些服务器超出负载，一些则几乎没有负载。可以在多个层面为连接设置失效时间来缓解这个问题，但这很复杂并且很难做到。连接池方案只有它们本身能够处理负载均衡时才能工作得很好。
- 许多多用途负载均衡器只会针对 HTTP服务器做健康和负载检查。一个简单的负载均衡器最少能够核实服务器在一个TCP端口上接受的连接数。更好的负载均衡器能够自动发起一个HTTP请求，并检查返回值以确定这个Web服务器是否正常运转。 MySQL并不接受到3306端口的HTTP请求，因此需要自己来构建健康检查方法。你可以在 MySQL服务器上安装一个HTTP 服务器软件，并将负载均衡器指向一个脚本，这个脚本检查 MySQL服务器的状态并返回一个对应的状态值该1。最重要的是检查操作系统负载（通过查看/proc/loadavg）、复制状态，以及 MySQL的连接数。

#### 2.负载均衡算法

有许多算法用来决定哪个服务器接受下一个连接。每个厂商都有各自不同的算法，下面这个清单列出了一些可用的方法∶ 

**随机**

负载均衡器随机地从可用的服务器池中选择一个服务器来处理请求。

**轮询**

负载均衡器以循环顺序发送请求到服务器，例如∶A，B，C，A，B，C。

**最少连接数**

下一个连接请求分配给拥有最少活跃连接的服务器。

**最快响应**

能够最快处理请求的服务器接受下一个连接。当服务器池里同时存在快速和慢速服务器时，这很有效。即使同样的查询在不同的场景下运行也会有不同的表现，例如当查询结果已经缓存在查询缓存中，或者服务器缓存中已经包含了所需要的数据时。

**哈希**

负载均衡器通过连接的源IP 地址进行哈希，将其映射到池中的同一个服务器上。每次从同一个IP 地址发起请求，负载均衡器都会将请求发送给同样的服务器。只有当池中服务器数目改变时这种绑定才会发生变化。

**权重**

负载均衡器能够结合使用上述几种算法。例如，你可能拥有单CPU和双CPU的机器。双CPU机器有接近两倍的性能，所以可以让负载均衡器分派两倍的请求给双CPU机器。

我们这里只描述了即时处理请求的算法，无须对连接请求排队。但有时候使用排队算法可能更有效。例如，一个算法可能只维护给定的数据库服务器并发数目，同一时刻只允许不超过 N个活跃事务。如果有太多的活跃事务，就将新的请求放到一个队列里，然后让可用服务器列表的第一个来处理它。有些连接池也支持队列算法。

#### 3．在服务器池中增加/移除服务器

增加一个服务器到池中并不是简单地插入进去，然后通知负载均衡器就可以了。你可能以为只要不是一下子涌进大量连接请求就可以了，但并不一定如此。有时候你会缓慢增加一台服务器的负载，但一些缓存还是"冷"的服务器可能会慢到在一段时间内都无法处理任何的用户请求。如果用户浏览一个页面需要30秒才能返回数据，即使流量很小，这个服务器也是不可用的。有一个方法可以避免这个问题，在通知负载均衡器有新服务器加入前，可以暂时把 SELECT查询映射到一台活跃服务器上。然后在新开启的服务器上读取和重放活跃服务器上的日志文件，或者捕捉生产服务器上的网络通信，并重放它的一部分查询。Percona Toolkit 中的pt-query-digest工具能够有所帮助。另一个有效的办法是使用 Percona Server 或 MySQL 5.6 的快速预热特性。

在配置连接池中的服务器时，要保证有足够多未使用的容量，以备在撤下服务器做维护时使用，或者当服务器失效时可以派上用场。每台服务器上都应该保留高于"足够"的容量。

要确保配置的限制值足够高，即使从池中撤出一些服务器也能够工作。举个例子，如果你发现每个MySQL服务器一般有100个连接，应该设置池中每个服务器的max_ connections 值为 200。这样就算一半的服务器失效，服务器池整体也能处理同样数量的请求。 

### 11.3.4 一主多备间的负载均衡

最常见的复制拓扑结构就是一个主库加多个备库。我们很难绕开这个架构。许多应用都假设只有一个目标机器用于所有的写操作，或者所有的数据都可以从单个服务器上获得。尽管这个架构不太具有很好的可扩展性，但可以通过一些办法结合负载均衡来获得很好的效果。本小节将讲述其中的一些技术。

**功能分区** 

正如之前讨论的，对于特定的目的可以通过配置备库或一组备库来极大地扩展容量。一些比较常见的功能包括报表、分析、数据仓库，以及全文检索。在第 10章有更多的细节。

**过滤和数据分区**

可以使用复制过滤技术在相似的备库上对数据进行分区（参考第 10章）。只要数据在主库上已经被隔离到不同的数据库或表中，这种方法就可以奏效。不幸的是，没有内建的办法在行级别上进行复制过滤。你需要使用一些独创性的技术来实现这一点，例如使用触发器和一组不同的表。

即使不把数据分区到各个备库上，也可以通过对读进行分区而不是随机分配来提高缓存效率。例如，可以把对以字母 A—M开头的用户名的读操作分配给一个给定的备库，把以N—Z 开头的分配给另外一个。这能够更好地利用每台机器的缓存，因为分离读更可能在缓存中找到相关的数据。最好的情况下，当没有写操作时，这样使用的缓存相当于两台服务器缓存的总和。相比之下，如果随机地在备库上分配读操作，每个机器的缓存本质上还是重复的数据，而总的有效缓存效率和一个备库缓存一样，不管你有多少台备库。

**将部分写操作转移到备库**

主库并不总是需要处理写操作中的所有工作。你可以分解写查询，并在备库上执行其中的一部分，从而显著减少主库的工作量。更多内容参见第 10 章。

**保证备库跟上主库**

如果要在备库执行某种操作，它需要即时知道数据处于哪个时间点——哪怕需要等待一会儿才能到达这个点——可以使用函数 MASTER_POS_WAIT（）阻塞直到备库赶上了设置的主库同步点。另一种替代方案是使用复制心跳来检查延迟情况;更多内容参见第 10章。 

**同步写操作**

也可以使用MASTER_POS_WAIT（）函数来确保写操作已经被同步到一个或多个备库上。如果应用需要模拟同步复制来保证数据安全性，就可以在多个备库上轮流执行 MASTER_POS_WAIT（）函数。这就类似创建了一个"同步屏障"，当任意一个备库出现复制延迟时，都可能花费很长时间完成，所以最好在确实需要的时候才使用这种方法。（如果你的目的只是确保某些备库拥有事件，可以只等待一台备库接收到事件。 MySQL 5.5 增加了半同步复制，能够支持这项技术。）

## 11.4 总结

在 MySQL扩展策略方面，典型的应用在增长到非常庞大时，通常先从单个服务器转移到向外扩展的拥有读备库的架构，再到数据分片和/或者按功能分区。我们并不同意那些提倡为每个应用"尽早分片，尽量分片"（shard early，shard often）的建议。这很复杂且代价昂贵，并且许多应用可能根本不需要。可以花一些时间去看看新的硬件和新版本的 MySQL有哪些变化，或者 MySQL Cluster有哪些新的进展，甚至去评估一些专门的系统，例如 Clustrix。毕竟数据分片是一个手工搭建的集群系统，如果没有必要，最好不要重复发明轮子。

当存在多个服务器时，可能出现跟一致性或原子性相关的问题。我们看到的最普遍的问题是缺少会话一致性（在网站上发表一篇评论，刷新页面，但找不到刚刚发布的评论），或者无法有效告诉应用哪些服务器是可写的，哪些是可读的。后一种可能更严重，如果将应用的写操作指向多个地方，就会不可避免地遭遇数据问题，需要花费大量时间而且很难解决。负载均衡器可以解决这个问题，但它本身也有一些问题，有时候还会使得原本希望解决的问题恶化。这也是我们在下一章要讲述高可用性的原因。

# 12. 高可用MySQL

**高可用性实际上意味着"更少的宕机时间"**。然而糟糕的是，高可用性经常和其他相关的概念混淆，例如冗余、保障数据不丢失，以及负载均衡。我们希望之前的两章已经为清楚地理解高可用性做了足够的铺垫。跟其他两章一样，这一章也不仅仅是关注高可用性的内容，一些相关的话题也会综合阐述。

## 12.1 什么是高可用

高可用性不是绝对的，只有相对更高的可用性。100%的可用性是不可能达到的。可用性的"9"规则是表示可用性目标最普遍的方法。你可能也知道，"5个9"表示 99.999%的正常可用时间。换句话说，每年只允许5分钟的宕机时间。对于大多数应用这已经是令人惊叹的数字，尽管还有一些人试图获得更多的"9""。

每个应用对可用性的需求各不相同。在设定一个可用时间的目标之前，先问问自己，是不是确实需要达到这个目标。可用性每提高一点，所花费的成本都会远超之前;可用性的效果和开销的比例并不是线性的。需要保证多少可用时间，取决于能够承担多少成本。高可用性实际上是在宕机造成的损失与降低宕机时间所花费的成本之间取一个平衡。幸运的是，建立 2 个9或3 个9的可用时间的目标可能并不困难，具体情况取决于应用。

有时候人们将可用性定义成**服务正在运行的时间段**。我们认为可用性的定义还应该包括应用**是否能以足够好的性能处理请求**。有许多方法可以让一个服务器保持运行，但服务并不是真正可用。对一个很大的服务器而言，重启MySQL之后，可能需要几个小时才能充分预热以保证查询请求的响应时间是可以接受的，即使服务器只接收了正常流量的一小部分也是如此。

另一个需要考虑的问题是，即使应用并没有停止服务，但**是否可能丢失了数据**。如果服务器遭遇灾难性故障，可能多少都会丢失一些数据，例如最近已经写入（最新丢失的）二进制日志但尚未传递到备库的中继日志中的事务。你能够容忍吗?大多数应用能够容忍;因为替代方案大多非常昂贵且复杂，或者有一些性能开销。例如，可以使用同步复制，或是将二进制日志放到一个通过DRBD进行复制的设备上，这样就算服务器完全失效也不用担心丢失数据。（但是整个数据中心也有可能会掉电。）

## 12.2 导致宕机的原因

我们首先对宕机事件按表现方式而非导致的原因进行分类。一般来说，"运行环境"是排名第一的宕机类别，大约35%的事件属于这一类。运行环境可以看作是支持数据库服务器运行的系统和资源集合，包括操作系统、硬盘以及网络等。性能问题紧随其后，也是约占35%;然后是复制，占20%;最后剩下的10%包含各种类型的数据丢失或损坏，以及其他问题。

我们对事件按类型进行分类后，确定了导致这些事件的原因。以下是一些需要注意的地方∶

- 在运行环境的问题中，最普遍的问题是磁盘空间耗尽。
- 在性能问题中，最普遍的宕机原因确实是运行很糟糕的SQL，但也不一定都是这个原因，比如也有很多问题是由于服务器 Bug 或错误的行为导致的。
- 糟糕的 Schema 和索引设计是第二大影响性能的问题。
- 复制问题通常由于主备数据不一致导致。
- 数据丢失问题通常由于 DROP TABLE的误操作导致，并总是伴随着缺少可用备份的问 题。

复制虽然常被人们用来改善可用时间，但却也可能导致宕机。这主要是由于不正确的使用导致的，即便如此，它也阐明了一个普遍的情况∶许多高可用性策略可能会产生反作用。 

现在我们已经知道了主要宕机类别，以及有什么需要注意，下面我们将专门介绍如何获得高可用性。

## 12.3 如何实现高可用性

可以通过同时进行以下两步来获得高可用性。首先，**可以尝试避免导致宕机的原因来减少宕机时间**。许多问题其实很容易避免，例如通过适当的配置、监控，以及规范或安全保障措施来避免人为错误。第二，**尽量保证在发生宕机时能够快速恢复**。最常见的策略是在系统中制造冗余，并且具备故障转移能力。这两个维度的高可用性可以通过两个相关的度量来确定∶平均失效时间（MTBF）和平均恢复时间（MTTR）。一些组织会非常仔细地追踪这些度量值。

### 12.3.1 提升平均失效时间（MTBF）

其实只要尽职尽责地做好一些应做的事情，就可以避免很多宕机。在分类整理宕机事件并追查导致宕机的根源时，我们还发现，很多宕机本来是有一些方法可以避免的。我们发现大部分宕机事件都可以通过全面的常识性系统管理办法来避免。以下是从我们的白皮书中摘录的指导性建议，在白皮书中有我们详细的分析结果。

- 测试恢复工具和流程，包括从备份中恢复数据。
- 遵从最小权限原则。
- 保持系统干净、整洁。
- 使用好的命名和组织约定来避免产生混乱，例如服务器是用于开发还是用于生产环境。
- 谨慎安排升级数据库服务器。
- 在升级前，使用诸如Percona Toolkit 中的pt-upgrade 之类的工具仔细检查系统。
- 使用 InnoDB 并进行适当的配置，确保 InnoDB是默认存储引擎。如果存储引擎被禁止，服务器就无法启动。
- 确认基本的服务器配置是正确的。
- 通过 skip_name_resolve禁止 DNS。
- 除非能证明有效，否则禁用查询缓存。
- 避免使用复杂的特性，例如复制过滤和触发器，除非确实需要。
- 监控重要的组件和功能，特别是像磁盘空间和RAID卷状态这样的关键项目，但也要避免误报，只有当确实发生问题时才发送告警。
- 尽量记录服务器的状态和性能指数，如果可能就尽量久地保存。
- 定期检查复制完整性。
- 将备库设置为只读，不要让复制自动启动。
- 定期进行查询语句审查。
- 归档并清理不需要的数据。
- 为文件系统保留一些空间。在 GNU/Linux中，可以使用-m选项来为文件系统本身保留空间。还可以在LVM卷组中留下一些空闲空间。或者，更简单的方法，仅仅创建一个巨大的空文件，在文件系统快满时，直接将其删除。
- 养成习惯，评估和管理系统的改变、状态以及性能信息。 

### 12.3.2 降低平均恢复时间（MTTR）

 之前提到，可以通过减少恢复时间来获得高可用性。事实上，一些人走得更远，只专注于减少恢复时间的某个方面∶通过在系统中建立冗余来避免系统完全失效，并避免单点失效问题。 

## 12.4 避免单点失效

找到并消除系统中的可能失效的单点，并结合切换到备用组件的机制，这是一种通过减少恢复时间（MTTR）来改善可用性的方法。如果你够聪明，有时候甚至能将实际的恢复时间降低至0，但总的来说这很困难。（即使一些非常引人注目的技术，例如昂贵的负载均衡器，在发现问题并进行反馈时也会导致一定的延迟。）

思考并梳理整个应用，尝试去定位任何可能失效的单点。是一个硬盘驱动器，一台服务器，一台交换或路由器，还是某个机架的电源?所有数据都在一个数据中心，或者冗余数据中心是由同一个公司提供的吗?系统中任何不冗余的部分都是一个可能失效的单点。其他比较普遍的单点失效依赖于一些服务，例如 DNS、单一网络提供商牢4、单个云"可用区域"，以及单个电力输送网，具体有哪些取决于你的关注点。

单点失效并不总是能够消除。增加冗余或许也无法做到，因为有些限制无法避开，例如地理位置，预算，或者时间限制等。试着去理解每一个影响可用性的部分，采取一种平衡的观点来看待风险，并首先解决其中影响最大的那个。一些人试图编写一个软件来处> 理所有的硬件失效，但软件本身导致的宕机时间可能比它节约的还要多。也有人想建立 一种"永不沉没"的系统，包括各种冗余，但他们忘记了数据中心可能掉电或失去连接。或许他们彻底忘记了恶意攻击者和程序错误的可能性，这些情况可能会删除或损坏数据——一个不小心执行的 DROP TABLE也会产生宕机时间。

可以采用两种方法来为系统增加冗余∶**增加空余容量和重复组件**。增加容量余量通常很简单——可以使用本章或前一章讨论的任何技术。一个提升可用性的方法是创建一个集群或服务器池，并使用负载均衡解决方案。如果一台服务器失效，其他服务器可以接管它的负载。有些人有意识地不使用组件的全部能力，这样可以保留一些"动态余量"来处理因为负载增加或组件失效导致的性能问题。

出于很多方面的考虑会需要冗余组件，并在**主要组件失效时能有一个备件来随时替换**。冗余组件可以是空闲的网卡、路由器或者硬盘驱动器——任何能想到的可能失效的东西。完全冗余MySQL服务器可能有点困难，因为一个服务器在没有数据时毫无用处。这意味着你必须确保备用服务器能够获得主服务器上的数据。共享或复制存储是一个比较流行的办法，但这真的是一个高可用性架构吗?让我们深入其中看看。

### 12.4.1 共享存储或磁盘复制 

**1.共享存储能够为数据库服务器和存储解耦合，通常使用的是SAN**。使用共享存储时，服务器能够正常挂载文件系统并进行操作。如果服务器挂了，备用服务器可以挂载相同的文件系统，执行需要的恢复操作，并在失效服务器的数据上启动MySQL。这个过程在逻辑上跟修复那台故障的服务器没什么两样，不过更快速，因为备用服务器已经启动，随时可以运行。当开始故障转移时，检查文件系统、恢复InnoDB 以及预热注5是最有可能遇到延迟的地方，但检测失效本身在许多设置中也会花费很长时间。 

**共享存储有两个优点**∶可以避免除存储外的其他任何组件失效所引起的数据丢失，并为非存储组件建立冗余提供可能。因此它有助于减少系统一些部分的可用性需求，这样就可以集中精力关注一小部分组件来获得高可用性。不过，共享存储本身仍是可能失效的单点。如果共享存储失效了，那整个系统也失效了，尽管SAN通常设计良好，但也可能失效，有时候需要特别关注。就算 SAN 本身拥有冗余也会失效。

共享存储本身也有风险，如果 MySQL崩溃等故障导致数据文件损坏，可能会导致备用服务器无法恢复。我们强烈建议在使用共享存储策略时选择InnoDB存储引擎或其他稳定的 ACID 存储引擎。一次崩溃几乎肯定会损坏 MyISAM表，需要花费很长时间来修复，并且会丢失数据。我们也强烈建议使用日志型文件系统。我们见过比较严重的情况是，使用非日志型文件系统和SAN（这是文件系统的问题，跟SAN无关）导致数据损坏无法恢复。

**2. 磁盘复制技术**是另外一个获得跟 SAN类似效果的方法。MySQL中最普遍使用的**磁盘复制技术是 DRBD**（http∶/www.drbd.org），并结合Linux-HA项目中的工具使用（后面会介绍到）。

**DRBD是一个以Linux 内核模块方式实现的块级别同步复制技术。**它通过网卡将主服务器的每个块复制到另外一个服务器的块设备上（备用设备），并在主设备提交块之前记录下来。由于在备用 DRBD 设备上的写入必须要在主设备上的写入完成之前，因此备用设备的性能至少要和主设备一样，否则就会限制主设备的写入性能。同样，如果正在使用 DRBD 磁盘复制技术以保证在主设备失效时有一个可随时替换的备用设备，备用服务器的硬件应该跟主服务器的相匹配。带电池写缓存的RAID控制器对DRBD而言几乎是必需的，因为在没有这样的控制器时性能可能会很差。

如果主服务器失效，可以把备用设备提升为主设备。因为DRBD是在磁盘块层进行复制，而文件系统也可能会不一致。这意味着最好是使用日志型文件系统来做快速恢复。一旦设备恢复完成，MySQL还需要运行自身的恢复。原故障服务器恢复后，会与新的主设备进行同步，并假定自身角色为备用设备。

从如何实际地实现故障转移的角度来看，DRBD和SAN 很相似∶有一个热备机器，开始提供服务时会使用和故障机器相同的数据。最大的不同是，DRBD是复制存储——不是共享存储——所以当使用 DRBD时，获得的是一份复制的数据，而 SAN则是使用与故障机器同一物理设备上的相同数据副本。换句话说，磁盘复制技术的数据是冗余的，所以存储和数据本身都不会存在单点失效问题。这两种情况下，当启动备用机器时， MySQL服务器的缓存都是空的。相比之下，备库的缓存至少是部分预热的。

DRBD 有一些很好的特性和功能，可以防止集群软件普遍会遇到的一些问题。一个典型的例子是"脑裂综合征"，在两个节点同时提升自己为主服务器时会发生这种问题。可以通过配置 DRBD来防止这种事件发生。但是 DRBD也不是一个能满足所有需求的完美解决方案。我们来看看它有哪些缺点 ∶ 

- DRBD的故障转移无法做到秒级以内。它通常至少需要几秒钟时间来将备用设备提升成主设备，这还不包括任何必要的文件系统恢复和 MySQL恢复。
- 它很昂贵，因为必须在主动一被动模式下运行。热备服务器的复制设备因为处于被动模式，无法用于其他任务。当然这是不是缺点取决于看问题的角度。如果你希望获得真正的高可用性并且在发生故障时不能容忍服务降级，就不应该在一台机器上运行两台服务器的负载量，因为如果这么做了，当其中一台发生故障时，就无法处理这些负载了。可以用这些备用服务器做一些其他用途，例如用作备库，但还是会有一些资源浪费。
- 对于 MyISAM表实际上用处不大，因为 MyISAM表崩溃后需要花费很长时间来检查和修复。对任何期望获得高可用性的系统而言，MyISAM都不是一个好选择;请使用 InnoDB 或其他支持快速、安全恢复的存储引擎来代替 MyISAM。
- DRBD无法代替备份。如果磁盘由于蓄意的破坏、误操作、Bug或者其他硬件故障导致数据损坏，DRBD 将无济于事。此时复制的数据只是被损坏数据的完美副本。你需要使用备份（或 MySQL 延时复制）来避免这些问题。
- 对写操作而言增加了负担。

我们倾向于只使用 DRBD 复制存放二进制日志的设备。如果主动节点失效，可以在被动节点上开启一个日志服务器，然后对失效主库的所有备库应用这些二进制日志。接下来可以选择其中一个备库提升为主库，以代替失效的系统。

说到底，共享存储和磁盘复制与其说是高可用性（低宕机时间）解决方案，不如说是一种保证数据安全的方法。只要拥有数据，就可以从故障中恢复，并且比无法恢复的情况的 MTTR更低。（即使是很长的恢复时间也比不能恢复要快。）但是相比于备用服务器启动并一直运行的架构，大多数共享存储或磁盘复制架构会增加 MTTR。有两种启用备用设备并运行的方法∶我们在第 10 章讨论的标准的 MySQL复制，以及接下来会讨论的同步复制。

### 12.4.2 MySQL 同步复制（主备容灾）

当使用同步复制时，主库上的事务只有在至少一个备库上提交后才能认为其执行完成。这实现了两个目标∶当服务器崩溃时没有提交的事务会丢失，并且至少有一个备库拥有实时的数据副本。大多数同步复制架构运行在主动-主动模式。这意味着每个服务器在任何时候都是故障转移的候选者，这使得通过冗余获得高可用性更加容易。

#### 1.MySQL Cluster

MySQL中的同步复制首先出现在 MySQL Cluster（NDB Cluster）。它在所有节点上进行同步的主-主复制。这意味着可以在任何节点上写入，这些节点拥有等同的读写能力。每一行都是冗余存储的，这样即使丢失了一个节点，也不会丢失数据，并且集群仍然能提供服务。尽管MySQL Cluster还不是适用于所有应用的完美解决方案，但正如我们在前一章提到的，在最近的版本中它做了非常快速的改进，现在已经拥有大量的新特性和功能∶非索引数据的磁盘存储、增加数据节点能够在线扩展、使用ndbinfo表来管理集群、配置和管理集群的脚本、多线程操作、下推（push-down）的关联操作（现在称为自适应查询本地化）、能够处理 BLOB列和很多列的表、集中式的用户管理，以及通过像 memcached协议一样的NDB API来实现 NoSQL访问。在下一个版本中将包含最终一致运行模式，包括为跨数据中心的主动-主动复制提供事务冲突检测和跨WAN解决方案。简而言之，MySQL Cluster 是一项引人注目的技术。

如果需要很强的可用性保证，就需要诸如 MySQL Cluster、Percona XtraDB Cluster，或者 Clustrix 这样的集群产品。如果能容忍在故障转移过程中稍微慢一些，标准的 MySQL复制也是个很好的选择。要谨慎使用自动化故障转移机制;如果没有按照正确的方式工作，它们可能会破坏数据。

#### 2.Percona XtraDB Cluster 

略

### 12.4.3 基于复制的冗余

复制管理器是使用标准 MySQL复制来创建冗余的工具。尽管可以通过复制来改善可用性，但也有一些"玻璃天花板"会阻止 MySQL当前版本的异步复制和半同步复制获得和真正的同步复制相同的结果。复制无法保证实时的故障转移和数据零丢失，也无法将所有节点等同对待。

复制管理器通常监控和管理三件事∶应用和MySQL间的通信、MySQL服务器的健康度，以及 MySQL服务器间的复制关系。它们既可以修改负载均衡的配置，也可以在必要的时候转移虚拟IP地址以使应用连接到合适的服务器上，还能够在一个伪集群中操纵复制以选择一个服务器作为写入节点。大体上操作并不复杂∶只需要确定写入不会发送到一个还没有准备好提供写服务的服务器上，并保证当需要提升一台备库为主库时记录下正确的复制坐标。

## 12.5 故障转移和故障恢复

冗余是很好的技术，但实际上只有在遇到故障需要恢复时才会用到。（见鬼，这可以用备份来实现）。冗余一点儿也不会增加可用性或减少宕机。在故障转移的过程中，高可用性是建立在冗余的基础上。当有一个组件失效，但存在冗余时，可以停止使用发生故障的组件，而使用冗余备件。冗余和故障转移结合可以帮助更快地恢复，如你所知，MTTR的减少将降低宕机时间并改善可用性。

**由于负载均衡和故障转移两者联系较紧密**，有些硬件和软件是同时为这两个目的设计的，因此我们建议所选择的任何负载均衡技术应该都提供故障转移功能。这也是我们建议避免使用 DNS 和修改代码来做负载均衡的真实原因。如果为负载均衡采用了这些策略，就需要做一些额外的工作∶当需要高可用性时，不得不重写受影响的代码。

以下小节讨论了一些比较普遍的故障转移技术。可以手动执行或使用工具来实现。

### 12.5.1 提升备库或切换角色

提升一台备库为主库，或者在一个主一主复制结构中调换主动和被动角色，这些都是许多MySQL故障转移策略很重要的一部分。具体细节参见第10章。正如本章之前提到的，我们不能认定自动化工具总能在所有的情况下做正确的事情——或者至少以我们的名誉担保没有这样的工具。

你不应该假定在发生故障时能够立刻切换到被动备库，这要看具体的工作负载。备库会重放主库的写入，但如果不用来提供读操作，就无法进行预热来为生产环境负载提供服务。如果希望有一个随时能承担读负载的备库，就要不断地"训练"它，既可以将其用于分担工作负载，也可以将生产环境的读查询镜像到备库上。我们有时候通过监听TCP流量，截取出其中的 SELECT查询，然后在备库上重放来实现这个目的。Percona Toolkit中有一些工具可以做到这一点。

### 12.5.2 虚拟 IP地址或 IP 接管

可以为需要提供特定服务的MySQL实例指定一个逻辑IP地址。当MySQL实例失效时，可以将IP地址转移到另一台MySQL服务器上。这和我们在前一章提到的思想本质上是相同的，唯一的不同是现在是用于故障转移，而不是负载均衡。 这种方法的好处是对应用透明。它会中断已有的连接，但不要求修改配置。有时候还可以原子地转移IP地址，保证所有的应用在同一时间看到这一变更。当服务器在可用和不可用状态间"摇摆"时，这一点尤其重要。

以下是它的一些不足之处∶ 

- 需要把所有的 IP 地址定义在同一网段，或者使用网络桥接。
- 改变IP 地址需要系统 root 权限。
- 有时候还需要更新 ARP缓存。有些网络设备可能会把ARP信息保存太久，以致无法即时将一个IP地址切换到另一个MAC地址上。
- 我们看到过很多网络设备或其他组件不配合切换的例子，结果系统的许多部分可能无法确定 IP 地址到底在哪里。
- 需要确定网络硬件支持快速 IP 接管。有些硬件需要克隆 MAC地址后才能工作。
- 有些服务器即使完全丧失功能也会保持持有IP地址，所以可能需要从物理上关闭或断开网络连接。这就是为人所熟知的"击中其他节点的头部"（shoot the other node in the head，简称STONITH）。它还有一个更加微妙并且比较官方的名字∶击剑(fencing)。

浮动IP地址和IP接管能够很好地应付彼此临近（也就是在同一子网内）的机器之间的故障转移。但是最后需要提醒的是，这种策略并不总是万无一失，还取决于网络硬件等因素。

**等待更新扩散**

经常有这种情况，在某一层定义了一个冗余后，需要等待低层执行一些改变。在本章前面的篇幅里，我们指出通过DNS 修改服务器是一个很脆弱的解决方案，因为 DNS的更新扩散速度很慢，改变IP 地址可给予你更多的控制，但在一个LAN中的 IP 地址同样依赖于更低层——ARP——来扩散更新。 

### 12.5.3 中间件解决方案

可以使用代理、端口转发、网络地址转换（NAT）或者硬件负载均衡来实现故障转移和故障恢复。这些都是很好的解决方案，不像其他方法可能会引入一些不确定性（所有系统组件认同哪一个是主库吗?它能够及时并原子地更改吗?），它们是控制应用和服务器间连接的中枢。但是，它们自身也引入了单点失效，需要准备冗余来避免这个问题。

使用这样的解决方案，你可以将一个远程数据中心设置成看起来好像和应用在同一个网络里。这样就可以使用诸如浮动IP地址这样的技术让应用和一个完全不同的数据中心开始通信。你可以配置每个数据中心的每台应用服务器，通过它自己的中间件连接，将流量路由到活跃数据中心的机器上。图 12-1描述了这种配置。

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\中间件解决数据库故障迁移.png" style="zoom:50%;" />

如果活跃数据中心安装的MySQL彻底崩溃了，中间件可以路由流量到另外一个数据中心的服务器池中，应用无须知道这个变化。

这种配置方法的主要缺点是在一个数据中心的 Apache服务器和另外一个数据中心的 MySQL服务器之间的延迟比较大。为了缓和这个问题，可以把Web服务器设置为重定向模式。这样通信都会被重定向到放置活跃 MySQL服务器的数据中心。还可以使用 HTTP 代理来实现这一目标。

图 12-1显示了如何使用代理来连接 MySQL服务器，也可以将这个方法和许多别的中间件架构结合在一起，例如 LVS 和硬件负载均衡器。

### 12.5.4 在应用中处理故障转移

有时候让应用来处理故障转移会更简单或者更加灵活。例如，如果应用遇到一个错误，这个错误外部观察者正常情况下是无法察觉的，例如关于数据库损坏的错误日志信息，那么应用可以自己来处理故障转移过程。

虽然把故障转移处理过程整合到应用中看起来比较吸引人，但可能没有想象中那么有效。大多数应用有许多组件，例如cron任务、配置文件，以及用不同语言编写的脚本。将故障转移整合到应用中可能导致应用变得太过笨拙，尤其是当应用增大并变得更加复杂时。但是将监控构建到应用中是一个好主意，当需要时，能够立刻开始故障转移过程。应用应该也能够管理用户体验，例如提供降级功能，并显示给用户合适的信息。 

## 12.6 总结

可以通过减少宕机来获得高可用性，这需要从以下两个方面来思考∶增加两次故障之间的正常运行时间（MTBF），或者减少从故障中恢复的时间（MTTR）。

要增加两次故障之间的正常运行时间，就要尝试去防止故障发生。悲剧的是，在预防故障发生时，它仍然会觉得你做的不够多，所以预防故障的努力经常会被忽视掉。我们已经着重提到了如何在 MySQL系统中预防宕机;

缩短恢复时间可能更复杂并且代价很高。从简单和容易的方面来说，可以通过监控来更快地发现问题，并记录大量的度量值以帮助诊断问题。作为回报，有时候可以在发生宕机前就发现问题。监控并有选择地报警以避免无用的信息，但也要及时记录状态和性能度量值。

另外一个减少恢复时间的策略是为系统建立冗余，并使系统具备故障转移能力，这样当故障发生时，可以在冗余组件间进行切换。不幸的是，冗余会让系统变得相当复杂。现在应用不再是集中化的，而是分布式的，这意味着协调、同步、CAP定理、拜占庭将军问题，以及所有其他各种杂乱的东西。这也是像 NDB Cluster这样的系统很难创建并且很难提供足够的通用性来为所有的工作负载提供服务的原因。但这种情况正在改善，也许到本书第四版的时候我们就可以称赞一个或多个集群数据库了。 

或者也可以将应用放到云中。为什么不呢?这样难道不是能够立刻获得高可用性和无限扩展能力吗?下一章将继续探讨这个问题。 

# 补充：系统的高扩展高可用的实践方案

系统的高扩展高可用与数据库高扩展高可用有所不同，参考高并发文件夹

# 13. 云端MySQL

为了便于讨论 MySQL 在云中的应用，可以将其粗略分为两类。

**IaaS（基础设施即服务）**

laas 是用于托管自有的 MySQL服务器的云端基础架构。可以在云端购买虚拟的服务器资源来安装运行 MySQL实例。也可以根据需求随意配置MySQL和操作系统，但没有权限也无法看到处于底层的物理硬件设备。

 **DBaaS（数据库即服务）**

MySQL本身作为由云端管理的资源。用户需要先收到MySQL服务器的访问许可（通常是一个连接串）才能访问。也可以配置一些 MySQL选项，但没有权限去控制或查看底层的操作系统或虚拟服务器实例。例如 Amazon运行 MySQL的RDS。其中一些服务器并非真的使用 MySQL，但它们能兼容 MySQL协议和查询语言。

我们讨论的重点主要集中在第一类∶云托管平台，例如AWS、Rackspace Cloud以及 Joyent注'。有许多很好的资源介绍如何部署和管理 MySQL及其运行所需要的资源，并且也有非常多的平台来完全满足这样的需求，所以我们不会展示代码样例或讨论具体的操作技术。因此，本章关注的重点是，在云端运行 MySQL还是在传统服务器上部署 MySQL，它们在最终经济上和性能特性上的关键区别是什么。我们假定你对云计算很熟悉。这里不是对云计算概念的简单介绍，我们的目的只是帮助那些还不熟悉在云端部署MySQL 的用户在使用时避免一些可能遇到的陷阱。

一般来说，MySQL 能够在云中很好地运行。在云中运行 MySQL并不比在其他平台困难，但有一些非常重要的差别。你需要注意这些差别并据此设计应用和架构来获得好的效果。某些场景下在云端托管 MySQL并不是非常适合，有时候则很适合，但大多数时候云仅仅是另外一个部署平台而已。

云是一个部署平台，而不是一种架构，理解这一点很重要。架构会受平台的影响，但平台和架构明显不同。如果你把架构和平台搞混了，就可能会做出不合适的选择而给以后带来麻烦。这也正是我们要花时间讨论云端的 MySQL 到底有什么不同的原因。

## 13.1 云的优点、缺点和相关误解

云计算有许多优点，但很少是为MySQL特别设计。有一些书籍已经介绍了相关的话题注2，这里我们不再赘述。不过我们会列出一些比较重要的条目供参考，因为接下来会讨论到云计算的缺点，我们不希望你认为我们是在过分苛求云计算。

- 云是一种将基础设施外包出去无须自己管理的方法。你不需要寻找供应商购买硬件，也不需要维护和供应商之间的关系，更无须替换失效的硬盘驱动器等。
- 云一般是按照即用即付的方式支付，可以把前期的大量资本支出转换为持续的运营成本。
- 随着供应商发布新的服务和成本降低，云提供的价值越来越大。你自己无须做任何事情（例如升级服务器），就可以从这些提升中获益;随着时间推移你会很容易地获得更多更好的选择并且费用更低。
- 云能够帮助你轻松地准备好服务器和其他资源，在用完后直接将其关闭，而无须关注怎么处理它们，或者怎么卖掉它们收回成本。
- 云代表了对基础设施的另一种思考方式——作为通过 API来定义和控制的资源——支持更多的自动化操作。从"私有云"中也可以获得这些好处。

当然，不是所有跟云相关的东西都是好的。这里有一些缺点可能会构成挑战（在本章稍后部分我们会列出 MySQL 特有的缺点）。

- 资源是共享并且不可预测的，实际上你可以获得比你支付的更多的资源。这听起来 很不错，但却导致容量规划很难做。如果你在不知情的情况下获得了比理应享受到的更多的计算资源，那么就存在这样的风险∶别人也许会索要他们应得的资源，这会使你的应用性能退化到应有的水平。一般来说，很难确切地知道本来应该得到多少（资源），大多数云托管服务提供商不会对此给出确切的答案。
- 无法保证容量和可用性。你可能以为还可以获得新实例，但如果供应商已经超额销售了呢?这在有很多共享资源的情况下会发生，同样也会发生在云中。
- 虚拟的共享资源导致排查故障更加困难，特别是在无法访问底层物理硬件的情况下无法检查并弄清到底发生了什么。例如，我们曾经看到过一些系统的iostat 显示的 I/O 很正常或者 vmstat 显示的 CPU很正常，而当实际衡量完成一个任务需要的时间时，资源却被系统上的其他东西严重占用了。如果在云平台上出现了性能问题，尤其需要去仔细地分析检测。如果对此并不擅长，可能就无法确认到底是底层系统性能差，还是你做了什么事情导致应用出现不合理的资源需求。

总的来说，云平台上对性能、可用性和容量的透明性和控制力都有所下降。最后，还有一些对云的误解需要记住。

**云天生具备更好的可扩展性**

应用、云的架构，以及管理云服务的组织是不是都是可扩展的。云并不是天生可扩展的，云也仅仅是云而已，选择一个可扩展的平台并不能自动使应用变得可扩展。的确，如果云托管提供商没有超售，那么你可以根据需求来购买资源，但在需要时能够获得资源仅仅是扩展性的一个方面而已。

**云可以自动改善甚至保证可用时间**

一般来说，个别在云端托管的服务器比那些经过良好设计的专用基础设施更容易发生故障或运行中断。但是许多人并没有意识到这一点。例如，有人这样写道∶"我们将基础设施升级到基于云构建的系统以保证 100%的可用时间和可扩展性"。而就在这之前 AWS遭受了两次大规模的运行中断故障，导致很大一部分用户受影响。好的架构能够用不可靠的组件设计出可靠的系统，但通常更可靠的基础设施可以获得更高的可用性。（当然不可能有 100% 的可用时间的系统。）

另一方面，购买云计算服务，实际上是购买一个由专家构建的平台。他们已经考虑了许多底层的东西，这意味着你可以更专注于上层工作。如果构建自己的平台而对其中的那些细枝末节并不精通，就可能犯一些初学者的错误，早晚会导致一些宕机时间。从这一点来说，云计算能够帮助改善可用时间。

**云是唯一能提供【 这里填入任意的优点】 的东西**

事实上，许多云的优点是继承自构建云平台所用到的技术，即使不使用云也可以获得注3。例如，通过管理得当的虚拟化和容量规划，可以像任何一个云平台那样简单快速地启动（spin up）一台新的机器。完全没必要专门使用云来做到这一点。

**云是一个"银弹"（silver bullet）**

虽然大部分人会认为这很荒谬，但确实有人会这么认为。实际上完全没有这回事。无可否认，云计算提供了独特的优点，随着时间的推移，关于云计算是什么，以及它们在什么情况下会有帮助，我们会获得更多的共识。但有一点非常肯定∶它是全新的，我们现在所做的任何预测都未必经得起时间的考验。我们会在本书讨论相对安全的部分，而将剩下的部分留给读者讨论。

## 13.2 MySQL在云端的经济价值

在一些场景下云托管比传统的服务器部署方式更经济。以我们的经验来看，云托管比较适合尚处于初级阶段的企业，或者那些持续接触新概念并且本质上是以适用为主的企业，例如移动应用开发者或游戏开发者。这些技术的市场随着移动计算的扩张出现了爆炸式增长，并且仍然是快速发展的领域。在许多情况下，成功的因素并不为开发者所控制，例如口口相传的推荐或者恰逢重要国际事件的时机。

我们已经帮助很多公司在云中构建移动应用、社交网络以及游戏应用。其中一个他们大量使用的策略是尽可能又快又便宜地开发和发布应用。如果一个应用碰巧变得流行了，公司将投入资源扩大其规模;否则就会很快终结这些应用。一些公司构建并发布的应用的生命周期甚至只有几个星期，在这样的环境下，可以毫不犹豫地选择云托管。

如果是一个小规模的公司，可能无法提供足够的硬件来自建数据中心以满足一个非常流行的Facebook应用的发展曲线。我们也协助过一些大型的Facebook应用进行扩展，它们能够以今人惊讶的速度增长——有时甚至会快到让一个主机托管公司耗尽资源。更为严重的是，这些应用的增长是完全无法预测的;它们可能只有极少量的用户（也可能突然有了爆炸性的用户数量增长）。我们在数据中心和云中都遇到过这样的应用。如果是一个小公司，云可以帮你避免前期快速注入大量的资金来获得更快更大规模的风险。

云的另一种潜在的大用途是运行不是很重要的基础设施，例如集成环境、开发测试平台，以及评估环境。假设部署周期是两个星期。你会每天每个小时都测试部署一次，还是只 在项目最后的冲刺时测试?许多用户只是偶尔需要筹划和部署测试环境。在这种场景下，云可以帮助节约不少钱。

以下是我们使用云的两种方式。第一个是作为我们对技术职员面试的一部分，我们会询问如何解决一些实际的问题。我们使用 AMI（Amazon MachineImages）来模拟一些被"破坏"的机器，然后让求职者登录并在服务器上执行一系列任务。我们不必开放他们到内部网络的授权，这种方案显然要方便得多。另一个是作为新项目的工作平台和开发服务器。有一个这样的项目已经在一台云端开发服务器上运行了数个月，而花费不足一美元!这在我们自己的基础设施上是不可能做到的。单是发送一封邮件给系统管理员申请开发服务器的时间价值就不止一美元。

但是另一方面，云托管对于长期项目而言可能会更加昂贵。如果打算长远地使用云，就需要花时间来计算一下（它是否划算）。除了猜想未来的创新能给云计算和商用硬件带来什么，还需要做基准测试以及一个完整的总体持有成本（TCO）账单。为了理清事情的本质并考虑全面所有相关的细节，你需要把所有的事情最终归结为一个数字∶每美元的业务交易数。事情变化得太快，所以我们将这个留给读者思考。

## 13.3 云中的 MySQL 的可扩展性和高可用性

正如我们之前提到的，MySQL并不会在云端自动变得更具扩展性。事实上，如果机器的性能较差，会导致过早使用横向扩展策略。况且云托管服务器相比专用的硬件可靠性和可预测性要更差些，所以想在云端获得高可用性需要更多的创新。

但是总的来说，在云端中扩展 MySQL和在其他地方扩展没有太多的差别。最大的不同就是按需提供服务器的能力。但是也有某些限制会导致扩展和高可用实现起来有点麻烦，至少在有些云环境中是这样的。例如，在 AWS云平台中，无法使用类似虚拟IP地址的功能来完成快速原子故障转移。像这种对资源的有限控制意味着你需要使用其他办法，例如代理。（ScaleBase 也值得去看看。）

云另外一个迷惑人的地方是梦想中的自动扩展——就是根据需求的增加或减少来启动或关闭实例。尽管对于诸如 Web服务器这样的无状态部分是可行的，但对于数据库服务器而言则很难做到，因为它是有状态的。对于一些特定的场景，例如以读为主的应用，可以通过增加备库的方式来获得有限的自动扩展年4，但这并不是一个通用的解决方案。实际上，虽然许多应用在 Web 层使用了自动扩展，但MySQL并不具备在一个无共享（Shared Nothing）集群中的对等角色服务器之间迁移的能力。你可以通过分片架构来自动重新分片并自动增长或收缩*5，但 MySQL 本身是无法自动扩展的。

事实上，因为数据库通常是一个应用系统中主要或唯一的有状态并且持久化的组件，所以把应用服务迁移到云端是很普遍的事情，因为除数据库之外的所有部分都可以从云中收益——Web服务器、工作队列服务器、缓存等——而 MySQL 只需要处理剩下的东西。

毕竟，数据库并非世界的中心。如果应用系统其他部分获得的好处，超过了让 MySQL运行得足够好而投入的额外开销和必需的工作量，那这不是一个是否会发生的问题，而 是怎么发生的问题。要回答这个问题，最好先了解你在云中可能碰到的额外的挑战。这些通常围绕着数据库服务器的可用资源。 

## 13.4 四种基础资源

MySQL需要四种基础资源来完成工作∶CPU周期、内存、I/O，以及网络。这四种资源的特性和重要程度在不同的云平台上各不相同。可以通过了解它们的不同之处和对 MySQL 的影响，以决定是否选择在云中托管 MySQL。

-  CPU通常很少且慢。在写作本书时最大的标准EC2实例提供8个虚拟CPU核心。 EC2 提供的虚拟CPU比高端 CPU的速度明显要慢很多（可以查看本章稍后的基准测试结果）。虽然可能略有不同，但很可能在大多数云托管平台中这都是一种普遍现象。EC2提供使用多个 CPU资源的实例，但它们的最大可用内存却更低。在写作本书时商用服务器能提供几十个 CPU核心——甚至更多，如果按硬件线程算的话。

- 内存大小受限制。最大的EC2 实例当前能提供68.4GB的内存。与此相比，商用服 务器能提供 512GB～ 1TB 的内存。

-  I/O 的吞吐量、延迟以及一致性受到限制。在 AWS 云中有两个存储选项

  第一个选择是使用EBS卷，这有点类似云中的 SAN。AWS的最佳实践是在用EBS组建的RAID10卷上建立服务器。但是EBS是一个共享资源，就像EC2服务器和 EBS 服务器之间的网络连接。延迟可能会很高并且不可预测，即使是在适量的吞吐量需求下也是如此。我们已经测得EBS设备的I/O延迟可以达到十几分之一秒。相比之下，直接插在本机的商用硬盘驱动器只需几个毫秒，而闪存设备比硬盘驱动器的速度又要高出几个数量级。但另一方面，EBS卷也有许多很好的特性，例如和其他 AWS 服务、快照等结合起来使用。 

  第二个选择是实例的本地存储。每个EC2服务器有一定数量的本地存储，实际安装在底层服务器上。它能够比EBS提供更多的一致性性能注7，但如果实例停止了就无法做到持久化。正是由于这样的特性导致其不适合大多数的数据库服务器场景。 

- 尽管网络通常是一个变化多端的共享资源，但是性能通常比较好。虽然使用商用硬件可以获得更快更持续的网络性能，但 CPU、RAM和I/O更容易成为主要的性能瓶颈，在 AWS 云中我们还没有遇到过网络性能问题。

正如你所看到的，四种基础资源中有三种在 AWS云中是受限的，在某些场景下尤其明显。总的来说，这些基础资源并没有商业硬件那样的性能。下一节我们会讨论这些确切的结论。

## 13.5 MySQL 在云主机上的性能

通常，由于较差的 CPU、内存以及 I/O性能，在类似AWS这样的云托管平台上MySQL所表现出来的性能并不如在其他地方好。这些情况在不同的云平台之间略有不同，但这依然是普遍的事实注8。然而对于你的需求而言，云主机可能仍然是一个性能足够高的平台，在某些需求上云平台可能比另外的解决方案要好。

如果使用更糟糕的硬件来运行 MySQL，无法让 MySQL性能比托管在云平台上更高，这并不奇怪。真正让人感到困惑的是在相似规格的物理硬件条件下却无法获得同样的运行速度。例如，如果有一台服务器拥有8个 CPU核心，16GB内存以及一个中等的RAID阵列，你可能认为能够获得和一个拥有8个EC2计算单元、15GB 内存以及少量EBS卷的EC2实例相同的性能，但这是无法保证的。EC2实例的性能可能比你的物理硬件更加多变，特别是它不是一个超大实例时，可以推测它跟其他实例共享了同样的硬件资源。

稳定性确实非常重要。MySQL和InnoDB尤其不喜欢不稳定的性能——特别是不稳定的I/O性能。I/O操作会请求服务器内部的互斥锁，当持续时间太长时，就会显著地导致很多"阻塞"进程堆积起来，出现令人难以理解的长时间运行的查询语句，以及例如 Threads_running 或 Threads_connected 这样的状态变量产生毛刺。

实际应用中前后不一致或者无法预测的性能导致的结果就是排队变得越来越严重。排队是响应时间和到达间隔时间多变自然会导致的结果，并且有个完整的数学分支专门致力于排队的研究。所有的计算机都是队列系统的网络，当需要请求的资源（CPU、I/O，网络，等等）繁忙时，请求必须等待。当资源性能更加多变时，请求更容易堆叠，会出现更多的排队现象。因此，在大多数云计算平台上很难获得高并发或者稳定的低响应时间。我们有很多次在EC2平台上遭受到这个限制的经验。以我们的经验来看，即便在最大的实例上运行的 MySQL，在典型的 Web OLTP工作负载上，你能够期待的最高并发度也就是 Threads_running值为8～12。根据经验，当超过这个值时，性能会越来越不可接受。

注意我们所说的"典型的 Web OLTP工作负载"，并非所有的工作负载都以相同的方式反映云平台的限制。确实有一些工作负载在云中表现得很好，而有一些则受到严重影响，让我们看看到底有哪些。

- 正如我们刚讨论的，需要高并发的工作负载并不是非常适合云计算。对于那些要求非常快的响应时间的应用同样如此。原因可以归结于虚拟 CPU 的数目和速度方面的限制。每个 MySQL查询运行在一个单独的 CPU上，所以查询响应时间实际上是由 CPU的原始速度决定的。如果期望得到更快的响应时间，就需要更快的 CPU。为了支持更高的并发度，你需要更多的CPU。MySQL和InnoDB不会因为运行在大量 CPU核心上而提供爆炸式的改进，但目前通常能在至少24个核心上获得比较好的横向扩展，这通常比在云中能够获得的核心数更多。
- 那些需要大量I/O的工作负载在云中并不总是表现很好。当I/O很慢并且不稳定时，工作会很快中断。但另一方面，如果你的工作负载不需要太多的I/O，不管是吞吐量（每秒的执行量）还是带宽（每秒字节数），MySQL 就可以运行得很好。

之前的几点是根据云端的 CPU和I/O 资源的缺点得出的。那么关于这些你可以做点什么呢?对于CPU限制你做不了太多，不够就是不够。但是I/O 则不同。I/O实际上是两种存储器的交换∶非永久存储器（RAM）和持久化存储器（磁盘、EBS，或者其他你所拥有的）。因此 MySQL的I/O需求会受系统内存大小的影响。当有足够的内存时，可以从缓存中读取数据，从而减少读和写操作的I/O。写入同样可以缓存在内存里，多个对相同内存比特位的写入可以合并成单个 I/O 操作。

内存的限制就出现了。当拥有足够的内存来存放工作数据集时注9，某些工作负载的I/O 需求可以明显减少。更大的 EC2 实例也会提供更好的网络性能，更有利于EBS卷的I/O。但如果工作集太大，无法装入可用的最大实例，则I/O 需求会逐渐上升，并开始阻塞甚至停止服务，正如我们之前讨论的那样。EC2 中内存最大的实例能够很好地为许多工作负载提供足够的内存。但是你需要意识到，预热时间可能会很长;关于这一话题本节后面会有更多的讨论。

哪种类型的工作负载无法通过增加更多的内存来解决呢?除了缓存外，一些写入很大的工作负载需要的I/O比你能从多数云计算平台上获得的要多。例如，如果每秒执行事务数很多，那么每秒就需要执行更多的I/O 操作以保证持久性。你只能从诸如EBS这样的系统中获得这么多的吞吐量。同样地，如果你正在将大量数据写入到数据库中，可能会超过可用的带宽。

你可能认为通过RAID来为EBS卷进行条带（striping）和镜像可以改善I/O性能。在某种程度上确实有帮助。问题是，当增加更多的EBS卷时，在我们需要某个EBS卷的任意时间点都增加了它性能变差的可能性，而根据InnoDB内部I/O 工作的方式，最差的一环通常是整个系统的瓶颈。实际上，我们已经尝试过10和20个EBS卷的RAID10集合， 20卷的RAID比10卷的遭遇了更多的停顿（stall）问题。当我们测量底层块设备的I/O性能时，很明显只有一或两个 EBS 卷表现得很慢，但是却已经影响了整个系统。

你也可以改变应用和服务器来减少I/O 需求，考虑周到的逻辑和物理数据库设计（Schema和索引）对于减少I/O 请求大有帮助，应用程序优化和查询优化也一样。这是减少I/O最有效的手段。例如插入量很大的工作负载，明智地使用分区，将I/O集中到索引能完全加载到内存中的单个分区上，就会有所帮助。你也可以通过设置 innodb_fLush_Logs_ at_trx_commit=2 和sync_binlog=0来降低持久性，或者将InnoDB事务日志和二进制日志从EBS卷中转移到一个本地驱动器上（尽管这有风险）。但是你从服务器上压榨一点额外的性能越困难，就越不可避免地要引入更大的复杂性（以及它们的成本）。

此外还可以升级 MySQL服务器软件。新版本的 MySQL和InnoDB（最新的使用 InnoDB Plugin的MySQL5.1，或者 MySQL5.5 及更新的版本）能够提供更好的I/O性能以及更少的内部瓶颈，并且相比 5.1 及之前的版本遭受的停顿和堆积会少很多。 Percona Server在某些工作负载下能够提供更多的好处。例如，Percona Server的快速预热缓冲池特性在服务器重启后能够帮助备用服务器快速运行起来，特别是I/O性能不是很好并且服务器依赖于内存时。这也是我们讨论能在云中获得好的性能的候选场景，这里服务器比备用硬件更容易发生故障。Percona Server能够将预热时间从几个小时甚至几天减少到几分钟。在写作本书时，类似的预热特性在 MySQL5.6 的开发里程碑版本里已经可用了。

尽管最终一个增长的应用总会达到一个顶点，届时你不得不对数据库进行拆分以保证数据能够存放到云中。我们倾向于尽量不拆分，但如果你只有这么点马力，当达到某个点时，就不得不去其他地方（离开这个云），或者将其拆分为多份，使每份数据需要的资源不超过虚拟硬件能提供的。通常当工作集无法适应内存大小时就得要进行分片了，这意味着在最大的EC2实例上的工作集大小为50GB～60GB。与之相对，我们已经有很多在物理硬件上运行几个TB大小级别数据库的经验。在云中你需要更早进行分片。  

## 13.6 MySQL 数据库即服务（DBaaS）

在云端服务器上安装 MySQL并不是在云中使用MySQL的唯一方法。已经有越来越多的公司开始将数据库本身作为云资源，称之为数据库即服务（DBaas，有时候也叫 DaaS），这意味着你可以在一个地方使用云中的数据库，而在另外的地方运行真正的服务。虽然我们在本章花很多时间解释了IaaS，但 laasS市场正在快速商品化，我们期望未来重点会转到 DBaaS。在写作本书时已经有以下几个 DBaaS 服务提供商。

### 13.6.1 Amazon RDS

我们发现在Amazon的关系数据库（RDS）上进行的开发比其他任何一个DBaaS提供商都要多很多。Amazon RDS不仅仅是一个兼容MySQL的服务;它事实上就是 MySQL，所以能够完全兼容你所拥有的MySQL服务器洼1并能作为替代品提供服务。我们不是很确定，但如大多数人一样，我们相信RDS是托管在使用EBS卷的EC2机器上——Amazon并没有公布底层的技术，但当你足够了解RDS时，这看起来很明显就是 MySQL、EC2 以及 EBS。

系统管理职责完全由 Amazon来承担。你没有访问EC2机器的权限;只有登入MySQL的访问凭证。你可以创建数据库、插入数据等。你并没有被控制住，如果有需要，可以将数据导出来转移到其他地方，也可以创建卷快照并挂载到其他机器上。

为了防止你检查或干涉Amazon对服务器或主机实例的管理，RDS做了一些限制。例如一些权限限制。你不能利用 SELECT INTO OUTFILE、FTLE（）、LOAD DATA INFTLE或其他方法来通过 MySQL访问服务器的文件系统。你不能做任何和复制相关的事情，也不能为自己赋予更高的权限。Amazon通过诸如在系统表上设置触发器等方法来进行阻止。并且作为服务条款的一部分，你要同意不会试图绕过这些限制。

安装的 MySQL版本做了轻微的修改以阻止用户干涉服务器，其他部分看起来和原版 MySQL一样。我们对RDS、EBS和EC2做了基准测试，并没有从该平台上发现超出我们预期的变化。也就是说，看起来 Amazon 并没有对服务器做任何性能增强。

RDS 可以提供一些比较吸引人的好处，这取决于你的具体情况。

- 你可以将系统管理甚至许多数据库管理的工作留给 Amazon。例如，他们会为你进行复制并保证你不会把事情搞砸。
- RDS 相比其他选择而言可能更便宜，这取决于你的成本结构和人力资源。
-  RDS中的限制也许是件好事∶Amazon拿走了那把子弹上膛的枪，防止你用它自残。

但是，它也有一些潜在的缺点。

- 由于无法控制服务器，也就无法弄清操作系统中到底发生了什么。例如，你无法衡量 I/O 响应时间和 CPU利用率。Amazon通过另一个服务 CloudWatch提供了这一功能。它给出了足够的指标用于排查许多性能问题，但有时候你需要原始数据以知道到底发生了什么。（也无法使用类似FTLE（）这样的函数来访问 /proc/diskstats。）
- 无法获得完整的慢查询日志文件。你可以指定 MySQL将慢查询记录到一个 CSV日志表中，但这并不是很好。它会消耗很多服务器资源，并且不会给出精确的查询响应时间。这使得很难去分析和排除 SQL 故障。
- 如果你希望得到最新最好的，或者一些性能上的增强，例如那些你可以从Percon Server 上获得的提升，那就不走运了，RDS 并不提供这些。
- 你必须依赖 Amazon的支持团队来解决一些问题，而这些问题可能本来是你自己可以解决的。例如，假设查询挂起了，或者服务器由于数据损坏崩溃了。你既可以等待 Amazon来解决，也可以自己解决。如果是后者你就需要把数据转移到别的地方。你无法通过访问实例本身来解决。如果想这么做，你不得不额外花一些时间并支付额外的资源。这不只是理论上的推测;我们已经接到过许多技术支持请求，这些请求通常需要系统权限以进行故障排查，因此对于RDS 用户而言是无法真正解决的。

正如我们所说，在性能方面，RDS 跟一个大型大内存的使用EBS存储和原始MySQL的 EC2实例相似。如果直接使用EC2和EBS并安装一个高性能版本的 MySQL（例如 Percona Server），你可以从 AWS云中压榨出一点更高的性能，但这不会是一个数量级上的区别。考虑到这一点，有理由根据你的商业需求而非性能需求来决定是否使用RDS。如果确实非常要求高性能，那你根本就不应该使用 AWS 云。

## 13.7 总结

在云端使用 MySQL至少有两种主流的方法∶在云服务器上安装 MySQL，或者使用 DBaaS 服务。MySQL能够在云主机上运行得很好，但云环境中的限制常常会导致更早需要进行数据拆分。并且尽管云服务器看起来和你的物理硬件很相似，但可能性能和服务质量要更低。

有时候似乎有人会说"云就是答案，有什么问题吗?"这是一个极端，但那些认为云是一个银弹的狂热信众，也有类似的问题。数据库所需要的四种基础资源中的三种（CPU、内存和磁盘）在云中明显更差并且/或者效率更低，会直接影响到 MySQL的性能。

但是对于很多工作负载而言，MySQL能够在云中运行得很好。通常来说，如果能将工作集加载到内存中，并且产生的写入负载不超过云能支撑的I/O量，那么就可以获得很好的效果。通过严谨的设计和架构，选择正确的 MySQL版本并做合适的配置，可以使你的数据库工作负载和容量能适应云的长处。但是 MySQL并不是天生的云数据库;也就是说，它无法完全使用云计算理论上能提供的优点，例如自动扩展。但是一些可替代的技术（例如 Xeround）正在尝试解决这些缺点。

我们已经讨论了很多跟云相关的缺点，这也许会给你一个我们反对云计算的印象。并非如此。这只是因为我们只集中在 MySQL上，而不是讨论云计算所有的优点，这可能跟你从其他地方阅读到的非常不一样。我们在试着指出在云端运行 MySQL有哪些不同，以及哪些是你需要知道的。

我们看到在云中最大的成功是由于商业原因做出的决策。即使长期来看每个商业交易的开销在云中会更高，但其他方面的因素，诸如增加了弹性、减少了前期成本、减少了推向市场的时间，以及降低了风险，这可能更重要。并且你的应用中其他和MySQL无关的部分所获得的好处要远远大于（在云端）使用 MySQL 带来的弊端。

# 14 . 应用层优化

## 缓存

## Mysql替代品

redis：数据量小，速度要求快的热点数据

Hadoop：数据量大的离线数据，历史数据

流计算：数据量大的实时数据

大数据之流处理和批处理https://blog.csdn.net/qq_41373246/article/details/99819017

# 15. 备份与恢复

# 16.OLAP vs OLAP vs HTAP

## 16.1 数据库发展历程

<img src="C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\数据库发展历程.jpg" style="zoom:50%;" />



## **16.2 OLAP、OLTP的介绍**

 **联机事务处理OLTP**

**（On-Line Transaction Processing）**

OLTP是事件驱动、面向应用的，也称为面向交易的处理过程。其基本特征是前台接收的用户数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果，是对用户操作的快速响应。例如银行类、电子商务类的交易系统就是典型的OLTP系统。其具备以下特点：

- 直接面向应用，数据在系统中产生。
- 基于交易的处理系统。
- 每次交易牵涉的数据量很小；对响应时间要求非常高。
- 用户数量非常庞大，其用户是操作人员，并发度很高。
- 数据库的各种操作主要基于索引进行。
- 以SQL作为交互载体。
- 总体数据量相对较小。

**2).OLAP**

  **联机实时分析OLAP**

**（On-Line Analytical Processing）**

OLAP是面向数据分析的，也称为面向信息分析处理过程。它使分析人员能够迅速、一致、交互地从各个方面观察信息，以达到深入理解数据的目的。其特征是应对海量数据，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。例如数据仓库是其典型的OLAP系统。其具备以下特点：

- 本身不产生数据，其基础数据来源于生产系统中的操作数据
- 基于查询的分析系统；复杂查询经常使用多表联结、全表扫描等，牵涉的数量往往十分庞大
- 每次查询设计的数据量很大，响应时间与具体查询有很大关系
- 用户数量相对较小，其用户主要是业务人员与管理人员
- 由于业务问题不固定，数据库的各种操作不能完全基于索引进行
- 以SQL为主要载体，也支持语言类交互
- 总体数据量相对较大

**3).OTHER**

除了传统的OLTP、OLAP类，近些年来针对数据的使用又有些新特点，我将其归入了“其他”类。

- **多模** 随着业务“互联网化”和“智能化”的发展以及架构 “微服务”和“云化”的发展，应用系统对数据的存储管理提出了新的标准和要求，数据的多样性成为突出的问题。早期数据库主要面对结构化数据的处理场景。后面随着业务的发展，逐渐产生了对非结构化数据的处理需求。包括结构化数据、半结构化(JSON、XML等)数据、文本数据、地理空间数据、图数据、音视频数据等。多模，正是指单一数据库支持多种类型数据的存储与处理。
- **流式** 流式处理(实时计算)，是来源于对数据加工时效性的需求。数据的业务价值随着时间的流失而迅速降低，因此在数据发生后必须尽快对其进行计算和处理。传统基于周期类的处理方式，显然无法满足需求。随着移动互联网、物联网和传感器的发展导致大量的流式数据产生。相应地出现了专有的流式数据处理平台，如Storm、Kafka等。近些年来，很多数据库开始支持流式数据处理，例如MemSQL、PipelineDB。有些专有流式数据处理平台开始提供SQL接口，例如KSQL基于Kafka提供了流式SQL处理引擎。
- **高阶** 随着对数据使用的深入，数据的使用不再仅仅以简单的增删改查或分组聚合类操作，而对于其更为高阶的使用也逐步引起大家的重视。例如使用机器学习、统计分析和模式识别等算法，对数据进行分析等。

## 16.3 OLAP、OLTP的比较

 数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）。OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 

**OLTP** 系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作；
**OLAP** 系统则强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等。 

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\OLTP、OLAP.jpg)

## **16.4 数据处理模式**

面对上述复杂多变的应用场景，数据应用的多种类别，是由单一平台处理，还是由不同平台来处理呢？一般来说，专有系统的性能将比通用系统性能高一到两个数量级，因而不同的业务应采用不同的系统。但正如古人说“天下大势、分久必合、合久必分”，在数据处理领域也有一种趋势，由单一平台来处理。这里选择的核心在于如何来辩证看待需求和技术。它们是一对矛盾体，当这对矛盾缓和时，数据处理领域将更趋向于整合；而当这对矛盾尖锐时，数据处理领域将趋于分散。就软硬件技术发展现状和当前需求来看，未来整合的趋势更为明显。集成数据平台将能满足绝大多数用户的场景，只有极少数企业需要使用专有系统来实现其特殊的需求。

### **16.4.1 分散式（专有平台）**

目前比较常规的方式，是采用多个专有平台，来针对不同场景进行数据处理。因此是跨平台的，因此是有个数据传输的过程。这之中会带来两个问题：数据同步、数据冗余。数据同步的核心是数据时效性问题，过期的数据往往会丧失价值。常见的做法如下:

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\分散式数据变化过程.png)

OLTP系统中的数据变化，通过日志的形式暴露出来；通过消息队列解耦传输；后端的ETL消费拉取，将数据同步到OLAP中。整个链条较长，对于时效性要求较高的场景是个考验。此外，数据在链条中流动，是存在多份的数据冗余保存。在常规的高可用环境下，数据会进一步保存多份。因此这里面隐藏了比较大的技术、人力成本以及数据同步成本。而且横跨如此之多的技术栈、数据库产品，每个技术栈背后又需要单独的团队支持和维护，如DBA、大数据、基础架构等。这些都蕴含着巨大的人力、技术、时间、运维成本。正是出于在满足各种业务需求的同时，提高时效性，减低数据冗余、缩短链条等，收敛技术栈就变得很重要。这也是通用类平台解决方案，诞生的出发点。

### 16.4.2 集中式（通用平台）

用户厌倦了为不同的数据处理采用不同的数据处理系统，更倾向于采用集成数据处理平台来处理企业的各种数据类型。对于融合了联机事务处理和联机实时分析的场景，也就是下面所谈到的HTAP。此类通用平台方案具备下面优点：

- 通过数据整合避免信息孤岛，便于共享和统一数据管理。
- 基于SQL的数据集成平台可提供良好的数据独立性，使应用能专注于业务逻辑，不用关心数据的底层操作细节。
- 集成数据平台能提供更好的实时性和更全的数据，为业务提供更快更准的分析和决策。
- 能够避免各种系统之间的胶合，企业总体技术架构简单，不需要复杂的数据导入/导出等，易于管理和维护。
- 便于人才培养和知识共享，无须为各种专有系统培养开发、运维和管理人才。

## **16.5 HTAP**

HTAP数据库（Hybrid Transaction and Analytical Process，混合事务和分析处理）。2014年Gartner的一份报告中使用混合事务分析处理(HTAP)一词描述新型的应用程序框架，以打破OLTP和OLAP之间的隔阂，既可以应用于事务型数据库场景，亦可以应用于分析型数据库场景。实现实时业务决策。这种架构具有显而易见的优势：不但避免了繁琐且昂贵的ETL（数据抽取、转化、加载）操作，而且可以更快地对最新数据进行分析。这种快速分析数据的能力将成为未来企业的核心竞争力之一。

例如：TiDB

### **16.5.1 技术要点**

- 底层数据要么只有一份，要么可快速复制，并且同时满足高并发的实时更新。
- 要满足海量数据的容量问题，在存储、计算都具有很好的线性扩展能力。
- 具有很好的优化器，可满足事务类、分析类的语句需求。
- 具备标准的SQL，并支持诸如二级索引、分区、列式存储、向量化计算等技术。

### **16.5.2 重点技术 – 行列存储**

**行存储（Row-based）：**对于传统的[关系型数据库](https://cloud.tencent.com/product/cdb-overview?from=10680)，比如甲骨文的OracleDB和[MySQL](https://cloud.tencent.com/product/cdb?from=10680)，IBM的DB2、微软的[SQL Server](https://cloud.tencent.com/product/sqlserver?from=10680)等，一般都是采用行存储（Row-based）行。在基于行式存储的数据库中，数据是按照行数据为基础逻辑存储单元进行存储的，一行中的数据在存储介质中以连续存储形式存在。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\行存储.png)

**列式存储（Column-based）**是相对于行式存储来说的，新兴的Hbase、HP Vertica、EMC Greenplum 等分布式数据库均采用列式存储。在基于列式存储的数据库中，数据是按照列为基础逻辑存储单元进行存储的，一列中的数据在存储介质中以连续存储形式存在。

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\列存储.png)

传统的行式数据库，是按照行存储的，维护大量的索引和物化视图无论是在时间（处理）还是空间（存储）面成本都很高。而列式数据库恰恰相反，列式数据库的数据是按照列存储，每一列单独存放，数据即是索引。只访问查询涉及的列，大大降低了系统I/O，每一列由一个线来处理，而且由于数据类型一致，数据特征相似，极大方便压缩。

### **16.5.3 重点技术 – MPP**

MPP (Massively Parallel Processing)，即大规模并行处理，在数据库非共享集群中，每个节点都有独立的磁盘存储系统和内存系统，业务数据根据数据库模型和应用特点划分到各个节点上，每台数据节点通过专用网络或者商业通用网络互相连接，彼此协同计算，作为整体提供数据库服务。非共享数据库集群有完全的可伸缩性、高可用、高性能、优秀的性价比、资源共享等优势。简单来说，MPP是将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果。下面以典型的MPP产品Greenplum架构为例。

### **16.5.4 重点技术 – 资源隔离**

OLTP、OLAP类两者对资源的使用特点不同，需要在资源层面做好隔离工作，避免相互影响。常见的通过定义资源队列的方式，指定用户分配队列，起到资源隔离的作用。

### **16.5.5 HTAP产品**

![](C:\Users\felixsfan\Desktop\办公机备份\学习\数据库\images\HTAP产品.png)

## 16.6 DDL和DML

DDL：数据定义

DML：数据操作

# 面试题

> https://mp.weixin.qq.com/s/eQ9dsFji_8wveU_6JB5RpQ
>
> https://mp.weixin.qq.com/s/mXTLt53s5iv0YNPOq4Y6uQ

# sql语句

## SQL语句执行步骤和底层原理

https://www.cnblogs.com/jindp/p/10744707.html
https://blog.csdn.net/HBL6016/article/details/104446794/

##  join，leftjoin.rightjoin,fulljoin

https://www.cnblogs.com/yixianyixian/p/9336840.html

## Inner join 和left join 性能不同，inner join反而慢是为什么?

left join 时系统做的逻辑运算量大于inner join，是因为inner join 只需选出能匹配的记录，left join 不仅需要选出能匹配的，而且还要返回左表不能匹配的，所以多出了这一部分逻辑运算